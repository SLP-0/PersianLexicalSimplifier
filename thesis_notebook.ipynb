{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-jUytSueK9o"
      },
      "source": [
        "# Extracting textual data from miras and wiki making a df of words and their frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbCu9kdSeI9d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from hazm import *\n",
        "import math\n",
        "from math import ceil\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\"\"\"\n",
        "preprocess step include: 1. Normalizing using Hazm, 2. removing non farsi characters including\n",
        "numerical characters, 3. tokenize using Hazm 4. get lemma using hazm lemmatizer and out put a list of lemmas\n",
        "5. defining a pipline for preprocess that normalize,\n",
        "tokenize, remove non farsi charactersand use hazm token_spacing methode\n",
        "5. two function to actuly prepare the tokens: prepare(text, pipeline) and prepare_data_frame(df)\n",
        "last one output is a df consist of tokens\n",
        "***we keep \\u200c character!\n",
        "\"\"\"\n",
        "\n",
        "normalizer = Normalizer()\n",
        "\n",
        "def remove_non_farsi_char(tokens):\n",
        "    token_list = []\n",
        "    for token in tokens:\n",
        "        token = re.sub('[^\\u200c\\u0621-\\u0628\\u062A-\\u063A\\u0641-\\u0642\\u0644-\\u0648\\u064E-\\u0651\\u0655\\u067E\\u0686\\u0698\\u06A9\\u06AF\\u06BE\\u06CC\\s]', '', token)\n",
        "        if len(token) != 0:\n",
        "            token_list.append(token)\n",
        "    return (token_list)\n",
        "\n",
        "\n",
        "tokenizer = WordTokenizer(replace_links= True, replace_hashtags= True)\n",
        "\n",
        "\n",
        "\n",
        "pipeline = [normalizer.normalize, tokenizer.tokenize,  remove_non_farsi_char,\n",
        "            normalizer.token_spacing,]\n",
        "\n",
        "def prepare(text, pipeline):\n",
        "    tokens = text\n",
        "    for transform in pipeline:\n",
        "        tokens = transform(tokens)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def prepare_data_frame(df):\n",
        "    # tokens coulmn consist of words\n",
        "    df['tokens'] = df['Text'].apply(prepare, pipeline=pipeline)\n",
        "    return df\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Labling process:\n",
        "label complexity base on frequency and word length. frequency threshold is 900 and length threshold\n",
        "is 5, any word with frequency less or equall to 900 and with a length of 5 or more consider complex\n",
        "and get 1 rest of the words labeled as 0 means simple\n",
        "\"\"\"\n",
        "\n",
        "def get_label(row, size):\n",
        "    freq_threshold = 900\n",
        "    length_threshold = 5\n",
        "    VC_threshhold = 0.70\n",
        "    # and row.word_length >= length_threshold\n",
        "    if (row.freq <= freq_threshold and row.word_length >= length_threshold and\n",
        "    row.VC > VC_threshhold) :\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Getting frequency  using a counter,\n",
        "also after counting removing characters that consider too or not much frequent we assume that words\n",
        "that are too frequent (maxm = 2000000) are words that are not needed and words that are not too\n",
        "frequent (minm = 100) are words mostly with misspronouncition.\n",
        "So we remove them from dataset1.\n",
        "\"\"\"\n",
        "\n",
        "counter = Counter()\n",
        "useless_words_index_list = []\n",
        "\n",
        "\n",
        "# remove too frequent words, freq>= 2m\n",
        "def prepare_remove_index_list(row):\n",
        "    maxm = 2000000\n",
        "    minm = 100\n",
        "    if (row.freq <= minm) or (row.freq > maxm):\n",
        "        i = row.name\n",
        "        useless_words_index_list.append(i)\n",
        "\n",
        "\n",
        "\n",
        "def prepare_counter(df_name, column=\"tokens\"):\n",
        "    df = pd.read_json(df_name, lines=True)\n",
        "    df = prepare_data_frame(df)\n",
        "\n",
        "\n",
        "    # process tokens and update counter\n",
        "\n",
        "    def update(doc):\n",
        "        tokens = doc\n",
        "        counter.update(tokens)\n",
        "\n",
        "    # create counter and run through all data\n",
        "    df[column].map(update)\n",
        "\n",
        "\"\"\" making necessary dataframes,\n",
        "applying functions to raw data.\n",
        "\"\"\"\n",
        "def count_words(counter):\n",
        "\n",
        "    # transform counter into a new DataFrame AKA freq_df\n",
        "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
        "    freq_df = freq_df.sort_values('freq', ascending=False)\n",
        "    # building lentgh and token coulmns:\n",
        "    freq_df = freq_df.reset_index()\n",
        "    freq_df = freq_df.rename(columns={'index': 'word'})\n",
        "    # freq_df['word_length'] = freq_df['word'].apply(len)\n",
        "    # label coulmn\n",
        "    # freq_df.apply(prepare_remove_index_list, axis=1)\n",
        "    # freq_df = freq_df.drop(useless_words_index_list, axis=0)\n",
        "    # freq_df = freq_df.reset_index()\n",
        "    # freq_df['labels'] = freq_df.apply(lambda x: get_label(x, len(freq_df)), axis=1)\n",
        "\n",
        "\n",
        "    return freq_df.sort_values('freq', ascending=False)\n",
        "\n",
        "\n",
        "\"\"\" Running step \"\"\"\n",
        "\n",
        "# file name include files of farsi wikipedia and Miras for example\n",
        "# put in the file names you want to use\n",
        "files_names = []\n",
        "\n",
        "def prepare_file(files, output_name) :\n",
        "    for file in files:\n",
        "        # freq_df, consist of tokens, frequency, lentgh and label as coulmns\n",
        "        prepare_counter(file)\n",
        "\n",
        "    final_df = count_words(counter)\n",
        "    # print(final_df.sample(2))\n",
        "    final_df.to_csv(\n",
        "        output_name, columns=['word', 'freq',]) #'word_length', 'labels'])\n",
        "# change the output name to your liking\n",
        "prepare_file(files_names, 'output.csv')\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "processing_time = end_time - start_time\n",
        "\n",
        "print(f\"Processing time: {processing_time:.6f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGRfcjzjgjlc"
      },
      "source": [
        "# get sentences for random 5k selected words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f1a2xV1iHIE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from hazm import *\n",
        "import math\n",
        "from math import ceil\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "import json\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "w_tokenizer = WordTokenizer()\n",
        "s_tokenizer = SentenceTokenizer()\n",
        "normalizer = Normalizer()\n",
        "\n",
        "def remove_non_farsi_char(text):\n",
        "\n",
        "      text = re.sub('[^\\u200c\\u0621-\\u0628\\u062A-\\u063A\\u0641-\\u0642\\u0644-\\u0648\\u064E-\\u0651\\u0655\\u067E\\u0686\\u0698\\u06A9\\u06AF\\u06BE\\u06CC\\u06F0-\\u06F9\\u060C\\u061B\\u061F\\u0640\\u066A\\u066B\\u066C:\\!\\.\\n\\s]', '', text)\n",
        "      # regex:u200c + persian_alpha_codepoints + persian_num_codepoints + punctuation_marks_codepoints + \\s\n",
        "      # \\u0020-\\u002F\\u0030-\\u003F\\u0039\\u003A-\\u0040\\u0041-\\u005A\\u005B-\\u0060\\u0061-\\u007A\\u007B-\\u007E\n",
        "      # text = re.sub('[^A-z]', '', text)\n",
        "      # common english punctuation and letters (capital and small)\n",
        "      return text\n",
        "\n",
        "pipeline = [normalizer.normalize, remove_non_farsi_char, s_tokenizer.tokenize]\n",
        "\n",
        "def prepare_words_list():\n",
        "    word_sentence = []\n",
        "    # put in one of the anotated word samples file name to extract the list of words \n",
        "    words = pd.read_csv('p1-sample.csv')\n",
        "    def get_words(row):\n",
        "        word_sentence.append(row.word)\n",
        "    words.apply(get_words, axis=1)\n",
        "    return word_sentence\n",
        "\n",
        "def prepare(text, pipeline):\n",
        "    tokens = text\n",
        "    for transform in pipeline:\n",
        "        tokens = transform(tokens)\n",
        "    return tokens\n",
        "\n",
        "def prepare_data_frame(df):\n",
        "    # tokens coulmn consist of sentences\n",
        "    df['tokens'] = df['Text'].apply(prepare, pipeline=pipeline)\n",
        "    return df\n",
        "\n",
        "\n",
        "def read_file(df_name, column=\"tokens\"):\n",
        "    df = pd.read_json(df_name, lines=True)\n",
        "    df = prepare_data_frame(df)\n",
        "\n",
        "    sent_df = df[['tokens']]\n",
        "\n",
        "    return sent_df\n",
        "\n",
        "# put in the name of chosen 5k sample words\n",
        "with open('5000_words.txt', 'r', encoding='utf8') as f:\n",
        "    json_data = json.load(f)\n",
        "word_sentence = json_data\n",
        "words_dict = {}\n",
        "\n",
        "# fills words_dict with key: sample_word, value: list of senteces containing the word\n",
        "def find_sentence(row):\n",
        "    for sent in row.tokens:\n",
        "        if len(w_tokenizer.tokenize(sent)) < 221:\n",
        "            for word in word_sentence:\n",
        "                if re.search(r'\\b {} \\b'.format(word), sent) != None:\n",
        "                    words_dict[word] = [sent]\n",
        "                    word_sentence.remove(word)\n",
        "\n",
        "# for every file calls find_sentence\n",
        "def get_output(file) :\n",
        "    if len(word_sentence) > 0:\n",
        "        print(len(word_sentence), datetime.datetime.now())\n",
        "        df = read_file(file)\n",
        "        df.apply(find_sentence, axis=1)\n",
        "\n",
        "# file name include files of farsi wikipedia and Miras for example\n",
        "# put in the file names you want to use\n",
        "files_names = []\n",
        "\n",
        "# get_output('test.json', 'sentences_output/test_sents.csv')\n",
        "for file_name in files_names:\n",
        "    get_output('data/' + file_name)\n",
        "# saves the final data into a csv\n",
        "# change the name to your liking\n",
        "final_df = pd.DataFrame.from_dict(words_dict, orient='index', columns=[\"sentences\"]).to_csv('final_words_sentences.csv')\n",
        "end_time = time.time()\n",
        "\n",
        "processing_time = end_time - start_time\n",
        "\n",
        "print(f\"Processing time: {processing_time:.6f} seconds\")\n",
        "\n",
        "# if there's still words left in word_sentence it gets saved in a text file\n",
        "# change the name to your liking\n",
        "with open('remaining_words.txt', 'w', encoding='utf8') as filehandle:\n",
        "    json.dump(word_sentence, filehandle)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-J5R30_is2F"
      },
      "source": [
        "# using word-freq df in first step, lemmatize and calculate freq for each lemma and then map a list of sentences having target lemma to that lemma\n",
        "final output is save as final_words_sentences.csv\n",
        "\n",
        "also lemma-freq df is saved in lemma_freq.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwdfLuNkkO0i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "lemmatizer = Lemmatizer()\n",
        "def get_lemma(csv_file_path):\n",
        "  \"\"\"\n",
        "  input = csv_file_path, the csv must have only 2 coulmns one name word and the other freq\n",
        "  output = a dictionary, key = each word lemmas, value = frequency of that lemma\n",
        "\n",
        "  ** the lemma frequency calculate by considering original word frequency and lemma freq\n",
        "  \"\"\"\n",
        "\n",
        "  result_dict = csv_to_dict(csv_file_path)\n",
        "\n",
        "  lemma_dict = {}\n",
        "  for word in result_dict.keys():\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "\n",
        "    lemma_dict[lemma] = lemma_dict.get(lemma, 0) + result_dict[word]\n",
        "\n",
        "  return lemma_dict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwAWDwLOltdT"
      },
      "outputs": [],
      "source": [
        "\"\"\" **prepare 5k random sentences**\n",
        " steps: 1. generate 5k random numbers in range 0, 5,856,193 (total lines we have is 5,856,193 and we want 5k random lines) = random indices\n",
        "        2. find this proportion: the line number(indices) // 100,000 this will give us which document and which line\n",
        "        3. add that line to a df, each row contains one line\n",
        "        4. (preprocess and) tokenize base on sentences, a list of sentences as a coulmn for each row\n",
        "        5. make a list for that final 5k sentences, calculate len of sentences, add untill choosing 5k sentences andadding to that list.\n",
        "\"\"\"\n",
        "# done\n",
        "\n",
        "import random\n",
        "\n",
        "indices = [random.randint(0, 3996090) for _ in range(5000)]\n",
        "\n",
        "print(min(indices), max(indices))\n",
        "\n",
        "\n",
        "useless_words_index_list = []\n",
        "# remove too frequent words, freq>= 2m\n",
        "def prepare_remove_index_list(row):\n",
        "    maxm = 2000000\n",
        "    minm = 100\n",
        "    if (row.freq <= minm) or (row.freq > maxm):\n",
        "        i = row.name\n",
        "        useless_words_index_list.append(i)\n",
        "\n",
        "\n",
        "def get_labeld_df(lemma_dict):\n",
        "\n",
        "  # transform lemma_dict into a new DataFrame AKA freq_df\n",
        "  freq_df = pd.DataFrame.from_dict(lemma_dict, orient='index', columns=['freq'])\n",
        "  # freq_df = freq_df.sort_values(ascending=False)\n",
        "  freq_df = freq_df.reset_index()\n",
        "  freq_df = freq_df.rename(columns={'index': 'word'})\n",
        "  # label coulmn\n",
        "  freq_df.apply(prepare_remove_index_list, axis=1)\n",
        "  freq_df = freq_df.drop(useless_words_index_list, axis=0)\n",
        "  freq_df = freq_df.reset_index()\n",
        "  # freq_df['labels'] = freq_df.apply(lambda x: get_label(x, len(freq_df)), axis=1)\n",
        "\n",
        "  return freq_df\n",
        "\n",
        "\n",
        "\n",
        "def prepare_file(file_path, output_name) :\n",
        "\n",
        "    # freq_df, consist of tokens, frequency, and label as coulmns\n",
        "    lemma_dict = get_lemma(file_path)\n",
        "\n",
        "    final_df = get_labeld_df(lemma_dict)\n",
        "    final_df.to_csv(\n",
        "        output_name, columns=['word', 'freq',]) #'labels'])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE_sx-k0om14"
      },
      "outputs": [],
      "source": [
        "def get_df_lemma_sent(lemmas_list, mega_list):\n",
        "  # mega list is a list of list of sentences like this: mega_list = [[s1, s2,..], [s], [...],...]\n",
        "  lemma_s_dict = {}\n",
        "\n",
        "  for original_lemma in lemmas_list:\n",
        "    lemma = original_lemma.split('#')\n",
        "    if len(lemma) > 1 and lemma[0] == '':\n",
        "      lemma = [lemma[1]]\n",
        "    else:\n",
        "      lemma = lemma\n",
        "\n",
        "    sents_list = []\n",
        "\n",
        "    for l in mega_list:\n",
        "      for sentence in l:\n",
        "        for lem in lemma:\n",
        "          if re.search(r'\\b {} \\b'.format(lem), sentence) != None:\n",
        "          # if lem in sentence:\n",
        "            sents_list.append(sentence)\n",
        "          lemma_s_dict[original_lemma] = [sents_list]\n",
        "          # print(sents_list, original_lemma)\n",
        "\n",
        "  df = pd.DataFrame.from_dict(lemma_s_dict, orient=\"index\", columns=[\"sentences\"])\n",
        "  df.to_csv('save path', idex=False)\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adof6LIymWsR"
      },
      "source": [
        "# complexity features extraction from lemma_freq.csv\n",
        "'''source: morpho_syntactic_features.ipynb'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBQy-HkYmdXf"
      },
      "outputs": [],
      "source": [
        "# In this feature set we consider a set of consonats and vowels in farsi in this order:\n",
        "#  its from this source: https://github.com/de-mh/persian_phonemizer/blob/main/dataset/IPA_dicts.py\n",
        "\n",
        "consonants = {\n",
        "\t\"ب\" : \"b\",\n",
        "\t\"پ\" : \"pʰ\",\n",
        "\t\"ت\" : \"tʰ\",\n",
        "\t\"ث\" : \"s\",\n",
        "\t\"ج\" : \"dʒ\",\n",
        "\t\"چ\" : \"tʃʰ\",\n",
        "\t\"ح\" : \"h\",\n",
        "\t\"خ\" : \"x\",\n",
        "\t\"د\" : \"d\",\n",
        "\t\"ذ\" : \"z\",\n",
        "\t\"ر\" : \"ɾ\",\n",
        "\t\"ز\" : \"z\",\n",
        "\t\"ژ\" : \"ʒ\",\n",
        "\t\"س\" : \"s\",\n",
        "\t\"ش\" : \"ʃ\",\n",
        "\t\"ص\" : \"s\",\n",
        "\t\"ض\" : \"z\",\n",
        "\t\"ط\" : \"tʰ\",\n",
        "\t\"ظ\" : \"z\",\n",
        "\t\"ع\" : \"ʔ\",\n",
        "\t\"غ\" : \"q\",\n",
        "\t\"ف\" : \"f\",\n",
        "\t\"ق\" : \"q\",\n",
        "\t\"ک\" : \"kʰ\",\n",
        "\t\"گ\" : \"ɡ\",\n",
        "\t\"ل\" : \"l\",\n",
        "\t\"م\" : \"m\",\n",
        "\t\"ن\" : \"n\",\n",
        "\t\"و\" : \"v\",\n",
        "\t\"ه\" : \"h\",\n",
        "\t\"ی\" : \"j\",\n",
        "\t\"ء\" : \"ʔ\",\n",
        "\t\"ئ\" : \"ʔ\",\n",
        "\t\"ا\" : \"ʔ\",\n",
        "\t\"آ\" : \"ʔɒː\"\n",
        "}\n",
        "\n",
        "\n",
        "vowels = {\n",
        "\t\"َ\" : \"æ\",\n",
        "\t\"ِ\" : \"e\",\n",
        "\t\"ُ\" : \"o\",\n",
        "\t\"آ\" : \"ɒː\",\n",
        "\t\"ا\" : \"ɒː\",\n",
        "\t\"ی\" : \"iː\",\n",
        "\t\"و\" : \"uː\",\n",
        "\t\"ْ\" : \"\"\n",
        "}\n",
        "\n",
        "\n",
        "consonants_ipa = ['b', 'd', 'dʒ', 'f', 'h', 'j', 'kʰ', 'l', 'm', 'n', 'pʰ', 'q', 's', 'tʃʰ', 'tʰ', 'v', 'x', 'z', 'ɡ', 'ɾ', 'ʃ', 'ʒ', 'ʔ']\n",
        "vowels_ipa = ['æ', 'e', 'o', 'ɒː', 'iː', 'uː']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sflJcNM8phLt"
      },
      "outputs": [],
      "source": [
        "def get_LenChar(row):\n",
        "  \"\"\"\n",
        "  input: df row\n",
        "  output: mean lemma length\n",
        "  \"\"\"\n",
        "  lemma = row['word']\n",
        "  lemmas = lemma.split('#')\n",
        "  lemma_length = 0\n",
        "\n",
        "  for lemma in lemmas:\n",
        "    lemma_length = len(lemma) + lemma_length\n",
        "\n",
        "  output = lemma_length / len(lemmas)\n",
        "  return round(output, 2)\n",
        "\n",
        "\n",
        "def get_NumSyl(row,):\n",
        "  \"\"\"\n",
        "  input: df row, a list of specified vowels which in farsi we consider vowels_ipa = ['æ', 'e', 'o', 'ɒː', 'ɒː', 'iː', 'uː', '']\n",
        "  output: number of vowels ocured in lemma  AKA number of sylables\n",
        "  \"\"\"\n",
        "  vowels_list = ['æ', 'e', 'o', 'ɒː', 'iː', 'uː']\n",
        "\n",
        "  phonemized_list = row['phonemize_lemma']\n",
        "  if len(phonemized_list) == 0:\n",
        "    return 0\n",
        "  vowels_count = 0\n",
        "\n",
        "  for phonemized in phonemized_list:\n",
        "    phonemized_word = phonemized\n",
        "    for vowel in vowels_list:\n",
        "      vowels_count = phonemized_word.count(vowel) + vowels_count\n",
        "\n",
        "  return round(vowels_count/len(phonemized_list), 2)\n",
        "\n",
        "def get_consonants_count(row,):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  consonants_list = ['b', 'd', 'dʒ', 'f', 'h', 'j', 'kʰ', 'l', 'm', 'n', 'pʰ', 'q', 's', 'tʃʰ', 'tʰ', 'v', 'x', 'z', 'ɡ', 'ɾ', 'ʃ', 'ʒ', 'ʔ']\n",
        "\n",
        "  phonemized_list = row['phonemize_lemma']\n",
        "  if len(phonemized_list) == 0:\n",
        "    return 0\n",
        "\n",
        "  consonants_count = 0\n",
        "\n",
        "  for phonemized in phonemized_list:\n",
        "    phonemized_word = phonemized\n",
        "    for consonant in consonants_list:\n",
        "      consonants_count = phonemized_word.count(consonant) + consonants_count\n",
        "  return round(consonants_count/len(phonemized_list), 2)\n",
        "\n",
        "def get_VowConRatio(row,):\n",
        "  \"\"\"\n",
        "  input: row\n",
        "  output: vowel/consonant ratioa in a lemma\n",
        "  \"\"\"\n",
        "  consonants_list = ['b', 'd', 'dʒ', 'f', 'h', 'j', 'kʰ', 'l', 'm', 'n', 'pʰ', 'q', 's', 'tʃʰ', 'tʰ', 'v', 'x', 'z', 'ɡ', 'ɾ', 'ʃ', 'ʒ', 'ʔ']\n",
        "  vowels_list = ['æ', 'e', 'o', 'ɒː', 'iː', 'uː']\n",
        "\n",
        "  phonemized = row['phonemize_lemma']\n",
        "\n",
        "  vowels_count = row['NumSyl']\n",
        "  consonants_count = row['consonants_count']\n",
        "  if consonants_count == 0:\n",
        "    return 0\n",
        "\n",
        "  ratio = vowels_count/consonants_count\n",
        "\n",
        "  return round(ratio, 2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8WDZyaRpwFf"
      },
      "outputs": [],
      "source": [
        "lemma_df = pd.read_csv('path to lemma csv file saved earlier',\n",
        "                            usecols=['word'])\n",
        "\n",
        "def get_phonemize_lemma(row):\n",
        "    lemmas = row['word'].split('#')\n",
        "    phonemized_lemmas = []\n",
        "    for lemma in lemmas:\n",
        "      try:\n",
        "        result = phonemizer.phonemize(lemma)\n",
        "        phonemized_lemmas.append(result)\n",
        "      except:\n",
        "        print(lemma)\n",
        "    return phonemized_lemmas\n",
        "\n",
        "\n",
        "lemma_df['phonemize_lemma'] = lemma_df.apply(get_phonemize_lemma, axis=1)\n",
        "\n",
        "lemma_df['LenChar'] = lemma_df.apply(get_LenChar, axis=1)\n",
        "lemma_df['NumSyl'] = lemma_df.apply(get_NumSyl, axis=1)\n",
        "lemma_df['consonants_count'] = lemma_df.apply(get_consonants_count, axis=1)\n",
        "lemma_df['VowConRatio'] = lemma_df.apply(get_VowConRatio, axis=1)\n",
        "lemma_df\n",
        "\n",
        "\"\"\"\n",
        "\n",
        " \tword \tphonemize_lemma \tLenChar \tNumSyl \tconsonants_count \tVowConRatio\n",
        "\n",
        "0 \tداد \t[dɒːd] \t3.0 \t1.0 \t2.0 \t0.50\n",
        "1 \tهزار \t[hezɒːɾ] \t4.0 \t2.0 \t3.0 \t0.67\n",
        "2 \tعنوان \t[ʔonuːɒːn] \t5.0 \t3.0 \t3.0 \t1.00\n",
        "3 \tکند \t[kʰond] \t3.0 \t1.0 \t3.0 \t0.33\n",
        "4 \tمردم \t[mæɾdom] \t4.0 \t2.0 \t4.0 \t0.50\n",
        "... \t... \t... \t... \t... \t... \t...\n",
        "80622 \tرگبرگ \t[ɾæbɡæɾɡ] \t5.0 \t2.0 \t5.0 \t0.40\n",
        "80623 \tپاگشا \t[pʰɒːɡoʃɒː] \t5.0 \t3.0 \t3.0 \t1.00\n",
        "80624 \tشایعه‌پرداز \t[ʃɒːjæʔæædʒɒːzdd] \t11.0 \t5.0 \t9.0 \t0.56\n",
        "80625 \tباوراند#باوران \t[bɒːvæɾɒːnd, bɒːvæɾɒːn] \t6.5 \t3.0 \t4.5 \t0.67\n",
        "80626 \tدولت‌گرا \t[dovletʰɡoɾɒːɾ] \t8.0 \t4.0 \t7.0 \t0.57\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gOsO12DqNpD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRGdFWQpqqHS"
      },
      "outputs": [],
      "source": [
        "# concat with freq-lemma ds\n",
        "result = pd.concat([lemma_freq_df, lemma_df['LenChar'], lemma_df['VowConRatio'], lemma_df['phonemize_lemma']], axis=1)\n",
        "\n",
        "\"\"\"\n",
        "word \tfreq \tLenChar \tVowConRatio \tphonemize_lemma\n",
        "0 \tداد \t1961610 \t3.0 \t0.50 \t[dɒːd]\n",
        "1 \tهزار \t1990168 \t4.0 \t0.67 \t[hezɒːɾ]\n",
        "2 \tعنوان \t1927106 \t5.0 \t1.00 \t[ʔonuːɒːn]\n",
        "3 \tکند \t1913349 \t3.0 \t0.33 \t[kʰond]\n",
        "4 \tمردم \t1846398 \t4.0 \t0.50 \t[mæɾdom]\n",
        "... \t... \t... \t... \t... \t...\n",
        "80622 \tرگبرگ \t131 \t5.0 \t0.40 \t[ɾæbɡæɾɡ]\n",
        "80623 \tپاگشا \t118 \t5.0 \t1.00 \t[pʰɒːɡoʃɒː]\n",
        "80624 \tشایعه‌پرداز \t107 \t11.0 \t0.56 \t[ʃɒːjæʔæædʒɒːzdd]\n",
        "80625 \tباوراند#باوران \t185 \t6.5 \t0.67 \t[bɒːvæɾɒːnd, bɒːvæɾɒːn]\n",
        "80626 \tدولت‌گرا \t102 \t8.0 \t0.57 \t[dovletʰɡoɾɒːɾ]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlP1FYpptiFa"
      },
      "source": [
        "# labling\n",
        "''' source: labling.ipynb'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KRD5Cuotk6J"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Labling process:\n",
        "label complexity base on frequency and word length. frequency threshold is 900 and length threshold\n",
        "is 5, any word with frequency less or equall to 900 and with a length of 5 or more consider complex\n",
        "and get 1 rest of the words labeled as 0 means simple\n",
        "\"\"\"\n",
        "\n",
        "def get_label(row):\n",
        "    freq_threshold = 900\n",
        "    length_threshold = 5\n",
        "    VC_threshhold = 0.67\n",
        "    if (row.freq <= freq_threshold and row.LenChar >= length_threshold and\n",
        "    row.VowConRatio < VC_threshhold) :\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['label'] = df.apply(get_label, axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXt5DL3kuTuO"
      },
      "outputs": [],
      "source": [
        "# extract 6k words from ds (containg 80626 words) with label == 1\n",
        "lemma_1 = df[df[\"label\"] == 1]\n",
        "sample_1 = lemma_1.sample(6000)\n",
        "\n",
        "lemma_0 = df.loc[df[\"label\"] == 0]\n",
        "sample_0 = lemma_0.sample(6000)\n",
        "\n",
        "# after this, manualy I cleaned data (meaningless, missspeled) for both of them and then concat to form a 5k list of words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9Cs-eNAvwX2"
      },
      "source": [
        "# 1. majority voting 2. Analysing manual labeled 5k words and automaticly labled 3. get complexity percentage 4. extracting sentencefrom list of sentences for each of 5k words (that where extracted before) 5. finding end and start index of each word in sentence\n",
        "''' sorce: data_analysis.ipynb '''\n",
        "\n",
        "\n",
        "'''lemma sents are from final_words_sentences.csv'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYt1dlby0qQq"
      },
      "source": [
        "majority voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EthATBt9xEch"
      },
      "outputs": [],
      "source": [
        "# merge\n",
        "merge_df = pd.DataFrame()\n",
        "\n",
        "merge_df['word']= doc1_df['word']\n",
        "\n",
        "merge_df['p1'] = doc1_df['label']\n",
        "merge_df['p2'] = doc2_df['label']\n",
        "merge_df['p3'] = doc3_df['label']\n",
        "merge_df['p4'] = doc4_df['label']\n",
        "merge_df['p5'] = doc5_df['label']\n",
        "\n",
        "merge_df\n",
        "\n",
        "\"\"\"\n",
        "\n",
        " \tword \tp1 \tp2 \tp3 \tp4 \tp5\n",
        "0 \tنژادپرستانه \t1 \t0 \t1 \t0 \t0\n",
        "1 \tحالشون \t0 \t0 \t0 \t1 \t0\n",
        "2 \tلرزه‌نگاری \t1 \t1 \t1 \t0 \t1\n",
        "3 \tلپ \t0 \t0 \t0 \t1 \t0\n",
        "4 \tتقبیح \t1 \t0 \t1 \t1 \t1\n",
        "... \t... \t... \t... \t... \t... \t...\n",
        "4995 \tروزمزد \t0 \t0 \t1 \t0 \t0\n",
        "4996 \tفرشتگانی \t0 \t0 \t0 \t0 \t0\n",
        "4997 \tشدهبود \t0 \t1 \t0 \t1 \t1\n",
        "4998 \tاستطلاع \t1 \t1 \t1 \t1 \t1\n",
        "4999 \tسید \t0 \t1 \t0 \t0 \t0\n",
        "\n",
        "\"\"\"\n",
        "merge_df['majority'] = merge_df.mode(axis=1, numeric_only=True)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        " \tword \tp1 \tp2 \tp3 \tp4 \tp5 \tmajority\n",
        "0 \tنژادپرستانه \t1 \t0 \t1 \t0 \t0 \t0\n",
        "1 \tحالشون \t0 \t0 \t0 \t1 \t0 \t0\n",
        "2 \tلرزه‌نگاری \t1 \t1 \t1 \t0 \t1 \t1\n",
        "3 \tلپ \t0 \t0 \t0 \t1 \t0 \t0\n",
        "4 \tتقبیح \t1 \t0 \t1 \t1 \t1 \t1\n",
        "... \t... \t... \t... \t... \t... \t... \t...\n",
        "4995 \tروزمزد \t0 \t0 \t1 \t0 \t0 \t0\n",
        "4996 \tفرشتگانی \t0 \t0 \t0 \t0 \t0 \t0\n",
        "4997 \tشدهبود \t0 \t1 \t0 \t1 \t1 \t1\n",
        "4998 \tاستطلاع \t1 \t1 \t1 \t1 \t1 \t1\n",
        "4999 \tسید \t0 \t1 \t0 \t0 \t0 \t0\n",
        "\n",
        "5000 rows × 7 columns\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7iJnvZj0oVl"
      },
      "source": [
        "Analysing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UcKuuwbuuwR"
      },
      "outputs": [],
      "source": [
        "def get_predicted_df(words_list):\n",
        "  \"\"\"\n",
        "  input: words list contains 5k words\n",
        "  output: a df of chosen words AKA the same with 5k words consist of automated labels\n",
        "  \"\"\"\n",
        "  df = pd.DataFrame()\n",
        "  for word in words_list:\n",
        "    new_row = original_doc_df.loc[original_doc_df['word'] == word]\n",
        "    df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "predicted_df = get_predicted_df(words)\n",
        "\n",
        "def get_actual_labels(doc_path, label_coulmn_name):\n",
        "  doc_df =  pd.read_csv(doc_path)\n",
        "  actual_labels = doc_df[label_coulmn_name]\n",
        "  return actual_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tg1hRXKwclv"
      },
      "outputs": [],
      "source": [
        "def get_metrics(actual, predicted):\n",
        "  Accuracy = round(metrics.accuracy_score(actual, predicted),2)\n",
        "  Precision = round(metrics.precision_score(actual, predicted),2)\n",
        "  Sensitivity_recall = round(metrics.recall_score(actual, predicted),2)\n",
        "  F1_score = round(metrics.f1_score(actual, predicted),2)\n",
        "\n",
        "  return {\"Accuracy\":Accuracy,\"Precision\":Precision,\"Sensitivity_recall\":Sensitivity_recall,\"F1_score\":F1_score}\n",
        "doc1_metrics = get_metrics(actual_labels_doc1, predicted_labels)\n",
        "doc1_metrics\n",
        "def get_confusion_mx (actual, predicted):\n",
        "  confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "  cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
        "  cm_display.plot()\n",
        "\n",
        "  return plt.show()\n",
        "\n",
        "majority_doc_conf_mx = get_confusion_mx(actual_labels_majority, predicted_labels)\n",
        "majority_metrics = get_metrics(actual_labels_majority, predicted_labels)\n",
        "\n",
        "doc1_conf_mx\n",
        "# {'Accuracy': 0.54, 'Precision': 0.28, 'Sensitivity_recall': 0.45, 'F1_score': 0.35}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSymvJBFwhT_"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_k_2u1cwn_U"
      },
      "outputs": [],
      "source": [
        "# calculate percentage\n",
        "def get_complex_percentage(row, participants_count):\n",
        "  numerator = 0\n",
        "\n",
        "  for i in range (participants_count):\n",
        "    coulmn_name = 'p' + str(i + 1)\n",
        "    if row[coulmn_name] == 1:\n",
        "      numerator = numerator + 1\n",
        "\n",
        "  output = round((numerator / participants_count) * 100, 2)\n",
        "  return output\n",
        "\n",
        "\n",
        "df['complex_percentage'] = df.apply(get_complex_percentage, participants_count=5, axis=1)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        " \tword \tp1 \tp2 \tp3 \tp4 \tp5 \tmajority \tcomplex_percentage\n",
        "0 \tنژادپرستانه \t1 \t0 \t1 \t0 \t0 \t0 \t40.0\n",
        "1 \tحالشون \t0 \t0 \t0 \t1 \t0 \t0 \t20.0\n",
        "2 \tلرزه‌نگاری \t1 \t1 \t1 \t0 \t1 \t1 \t80.0\n",
        "3 \tلپ \t0 \t0 \t0 \t1 \t0 \t0 \t20.0\n",
        "4 \tتقبیح \t1 \t0 \t1 \t1 \t1 \t1 \t80.0\n",
        "... \t... \t... \t... \t... \t... \t... \t... \t...\n",
        "4995 \tروزمزد \t0 \t0 \t1 \t0 \t0 \t0 \t20.0\n",
        "4996 \tفرشتگانی \t0 \t0 \t0 \t0 \t0 \t0 \t0.0\n",
        "4997 \tشدهبود \t0 \t1 \t0 \t1 \t1 \t1 \t60.0\n",
        "4998 \tاستطلاع \t1 \t1 \t1 \t1 \t1 \t1 \t100.0\n",
        "4999 \tسید \t0 \t1 \t0 \t0 \t0 \t0 \t20.0\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_OSVr13Hk0b"
      },
      "source": [
        "\n",
        "adding a sentence containing the lemma. for each lemma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXdcN6jgy0oh"
      },
      "outputs": [],
      "source": [
        "word_sents_df = pd.read_csv(word_sents_path)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "word \tsentences\n",
        "0 \tسطح \tخصوصیات وینیولا ۲۲ کیلومترمربع مساحت و ۲۵، ۰۸۴...\n",
        "1 \tواقع \tوینیولا به ایتالیایی: یک کومونه در ایتالیا اس...\n",
        "2 \tسن \tاما ابراهیم علیپور، یکی دیگر از پا به سن گذاشت...\n",
        "3 \tبزرگ \tکنوود هاوس یک خانه بزرگ در شمال غربی لندن است...\n",
        "4 \tموزه \tنقاشان صاحب اثر در باغ موزه، یوهانس فرمیر، رام...\n",
        "... \t... \t...\n",
        "4995 \tپرسید \tوقتی خدا بازگشت، آدم و زن پنهان شدند زیرا می‌د...\n",
        "4996 \tبانگید#بانگ \tآنکه به شکار رفته بود هیاج بن عبدالرحمن ازدی ب...\n",
        "4997 \tخوابید#خواب \tروزنامه‌نگاری که تسلا با او دوست شده بود، تأیی...\n",
        "4998 \tپاگشا \tپاگشا مراسمی است که اقوام عروس و داماد در ایرا...\n",
        "4999 \tاما خرده گیران چپ بر او شوریدند که چرا این فیل... \tاما خرده گیران چپ بر او شوریدند که چرا این فیل...\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGKLRfrlzEYB"
      },
      "outputs": [],
      "source": [
        "def get_ds(sent_df, words, label_df):\n",
        "  ds = pd.DataFrame()\n",
        "  for word in words:\n",
        "    selected_row = sent_df.loc[sent_df['word'] == word ]\n",
        "    ds = pd.concat([ds, selected_row], ignore_index=True )\n",
        "\n",
        "  return ds\n",
        "\n",
        "gold_ds = get_ds(word_sents_df, word_list, words_label_prob_df)\n",
        "selected_coulmns = words_label_prob_df[['majority', 'complex_percentage']]\n",
        "gold_ds = gold_ds.join(selected_coulmns)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        " \tword \tsentences \tmajority \tcomplex_percentage\n",
        "0 \tنژادپرستانه \tمصاحبه فیلم لغو شده اکشن کمدی ساخته کشور آمریک... \t0 \t40\n",
        "1 \tحالشون \tخوبه از بچه‌ها بخوام بهم کمک کنند آخه اونا هم ... \t0 \t20\n",
        "2 \tلرزه‌نگاری \tپیمان منع جامع آزمایش‌های هسته‌ای در ۲۰ شهریور... \t1 \t80\n",
        "3 \tلپ \tمرداب آب بندان لپو زاغمرز در نزدیکی دریای خزر،... \t0 \t20\n",
        "4 \tتقبیح \tسید علی غیوری زاده ۱۳۰۹، درگذشت ۲۷ آذر ۱۳۹۳ نم... \t1 \t80\n",
        "... \t... \t... \t... \t...\n",
        "4991 \tروزمزد \tرضا عطارپور مجرد رضا عطارپور مجرد نام مستعار: ... \t0 \t20\n",
        "4992 \tفرشتگانی \tبراساس احادیث اسلامی، عذاب قبر یا عذاب برزخ سخ... \t0 \t0\n",
        "4993 \tشدهبود \tتفریحات لوکس اما رایگان می‌م و پ، یکی از زوجها... \t0 \t0\n",
        "4994 \tاستطلاع \tفلا تنس هذه النصیح السبت ۱۷ ینایر ۲۰۱۵ ۱۰:۰۷... \t0 \t20\n",
        "4995 \tسید \tکمال‌الدین حسین الحسینی معروف به اخلاطی بن علی... \t0 \t20\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-midbLmZzVWW"
      },
      "source": [
        "finding end and start index of each word in sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AXQmhhgzgOJ"
      },
      "outputs": [],
      "source": [
        "def get_indc(row):\n",
        "  sent = row['sentences']\n",
        "  word = row['word']\n",
        "  indc_list = (0,0)\n",
        "  if '#' not in word:\n",
        "    try:\n",
        "      indc_list = [sent.index(word), sent.index(word)+len(word)-1]\n",
        "    except:\n",
        "      print(word)\n",
        "  else:\n",
        "    for w in word.split('#'):\n",
        "      match = re.search(r'\\b({})\\b'.format(w), sent)\n",
        "      if match:\n",
        "        indc_list = (match.start(), match.end())\n",
        "\n",
        "  return indc_list\n",
        "\n",
        "coulmns = gold_ds.apply(get_indc, axis = 1, result_type ='expand')\n",
        "selected_coulmns = coulmns[[0, 1]]\n",
        "gold_ds = gold_ds.join(selected_coulmns)\n",
        "\n",
        "gold_ds = gold_ds.rename(columns={0: \"str_idx\", 1: \"end_idx\"})\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "word \tsentences \tmajority \tcomplex_percentage \tstr_idx \tend_idx\n",
        "0 \tنژادپرستانه \tمصاحبه فیلم لغو شده اکشن کمدی ساخته کشور آمریک... \t0 \t40 \t2777 \t2787\n",
        "1 \tحالشون \tخوبه از بچه‌ها بخوام بهم کمک کنند آخه اونا هم ... \t0 \t20 \t46 \t51\n",
        "2 \tلرزه‌نگاری \tپیمان منع جامع آزمایش‌های هسته‌ای در ۲۰ شهریور... \t1 \t80 \t397 \t406\n",
        "3 \tلپ \tمرداب آب بندان لپو زاغمرز در نزدیکی دریای خزر،... \t0 \t20 \t15 \t16\n",
        "4 \tتقبیح \tسید علی غیوری زاده ۱۳۰۹، درگذشت ۲۷ آذر ۱۳۹۳ نم... \t1 \t80 \t3843 \t3847\n",
        "... \t... \t... \t... \t... \t... \t...\n",
        "4991 \tروزمزد \tرضا عطارپور مجرد رضا عطارپور مجرد نام مستعار: ... \t0 \t20 \t206 \t211\n",
        "4992 \tفرشتگانی \tبراساس احادیث اسلامی، عذاب قبر یا عذاب برزخ سخ... \t0 \t0 \t1532 \t1539\n",
        "4993 \tشدهبود \tتفریحات لوکس اما رایگان می‌م و پ، یکی از زوجها... \t0 \t0 \t3365 \t3370\n",
        "4994 \tاستطلاع \tفلا تنس هذه النصیح السبت ۱۷ ینایر ۲۰۱۵ ۱۰:۰۷... \t0 \t20 \t183 \t189\n",
        "4995 \tسید \tکمال‌الدین حسین الحسینی معروف به اخلاطی بن علی... \t0 \t20 \t658 \t660\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqNzku5l2wrH"
      },
      "source": [
        "# CWI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqTuJkPK3r2F"
      },
      "source": [
        "# Prepare Data: tokenize  phrases (for each word) and label target words: 1 and other 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24vc6ZmQ2wDa"
      },
      "outputs": [],
      "source": [
        "# path to gold_ds dataset created earlier\n",
        "MAIN_PATH_DATASET = '/content/drive/MyDrive/recourses/ds/modified_ds.csv'\n",
        "columns = ['target', 'sentence', \"binary\", \"prob\", \"start\", \"end\"]\n",
        "\n",
        "def load_df(path):\n",
        "    df = pd.read_csv(path,)\n",
        "    df.columns = columns\n",
        "    return df\n",
        "\n",
        "dataset = load_df(MAIN_PATH_DATASET)\n",
        "\n",
        "# extract 50 sentences randomly for furher evaluation using SARI\n",
        "\n",
        "random_samples= dataset.sample(n=50, random_state=42)\n",
        "random_samples.to_csv('/content/drive/MyDrive/SARI_samples.csv', index=False)\n",
        "\n",
        "# dataset:\n",
        "\"\"\"\n",
        "\n",
        " \ttarget \tsentence \tbinary \tprob \tstart \tend\n",
        "0 \tاحتراق \tسوخت مایع مولکول‌های قابل احتراق یا تولیدکنند... \t0 \t40 \t27 \t32\n",
        "1 \tنقل \tسوخت‌های مایع در مجموع نقش مهمی در حوزه‌های حم... \t0 \t20 \t50 \t52\n",
        "2 \tبزرگ \tجایزه بزرگ ژاپن یکی از مسابقات قهرمانی جهان فر... \t1 \t80 \t6 \t9\n",
        "3 \tبرنامه \tسومین مسابقه قرار بود در آوریل ۱۹۷۸ برگزار شود... \t0 \t20 \t67 \t72\n",
        "4 \tتمام \tاین مسابقه با پیروزی ریکاردو پاترسه تمام شد. \t1 \t80 \t36 \t39\n",
        "... \t... \t... \t... \t... \t... \t...\n",
        "4995 \tکانی‌شناس \tفرانتسیوزف مولر فون رایشنشتین، زاده ۱ ژوئیه ۱۷... \t0 \t20 \t96 \t104\n",
        "4996 \tسنگ‌شناس \tهمه گوته آلمانی را بیش‌تر به‌عنوان شاعر می‌شنا... \t0 \t0 \t69 \t76\n",
        "4997 \tخواهیدآورد \tاگر توانایی انجام خدماتی را برای سایر کسب و کا... \t1 \t60 \t351 \t360\n",
        "4998 \tمونوکلینیک \tسیلیکات با از مجموعه کانی هاست و سفید محلول در... \t1 \t100 \t267 \t276\n",
        "4999 \tراه‌نما \tعلم مواد معمولا ویژگی‌های شیمیایی یک ماده را ب... \t0 \t20 \t57 \t63\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "tokenizer = WordTokenizer()\n",
        "\n",
        "def get_max_len(row):\n",
        "  seq = row['sentence']\n",
        "  output = len(tokenizer.tokenize(seq))\n",
        "  print(tokenizer.tokenize(seq))\n",
        "  return output\n",
        "\n",
        "dataset['seq_length'] = dataset.apply(get_max_len, axis=1)\n",
        "dataset['seq_length'].max()\n",
        "\n",
        "normalizer = Normalizer()\n",
        "tokenizer = WordTokenizer(join_verb_parts=False)\n",
        "\n",
        "#  identifying and categorizing punctuation characters. as tbl for a dictionary\n",
        "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
        "                      if unicodedata.category(chr(i)).startswith('P'))\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(tbl)\n",
        "\n",
        "def all_tokens_with_index(context):\n",
        "  \"\"\"\n",
        "  return tokens of context + its index (in context) + token current position in context\n",
        "  \"\"\"\n",
        "  targets = []\n",
        "  # normalize, no repetetive white space\n",
        "  context = normalizer.normalize(context)\n",
        "  context = normalizer.correct_spacing(context)\n",
        "  # tokenize\n",
        "  tokens = tokenizer.tokenize(context)\n",
        "  for index, token in enumerate(tokens, 1):\n",
        "    match = re.search(r'\\b({})\\b'.format(re.escape(token)), context)\n",
        "\n",
        "    if match != None:\n",
        "      curr_pos = match.start()\n",
        "      end_pos = match.end()\n",
        "    else:\n",
        "      curr_pos = context.index(token)\n",
        "      end_pos = context.index(token) + len(token)\n",
        "\n",
        "    targets.append((token, index, curr_pos, end_pos))\n",
        "\n",
        "  return [val for val in targets if val[0] != '\"']\n",
        "\n",
        "  def forward_transformation(dataframe, filter_punc = True,):\n",
        "  \"\"\"\n",
        "  input: dataframe\n",
        "  process: preprocess context: , remove_punct, tokenize and index using prior function\n",
        "  output: a list of a  dictionary. key: sentence, seq. value:'sent', [(prob, bibnary, end, start, token),...,()], list name is sentences\n",
        "  ***** consider that this methode is making a list of unique sentences so the length might be differnt but if n sentences were same it would merge and as tag bring n target words, like this: 'tags': [('بدهکار', 19729, 19734, 1, 80), ('برآمده', 5698, 5703, 0, 40)]\n",
        "\n",
        "  \"\"\"\n",
        "  grouped = dataframe.groupby('sentence').apply(lambda row :\n",
        "                      {\n",
        "                        'sentence' : list(set(row['sentence']))[0],\n",
        "                        'tags': [tag for tag in zip(row['target'],\n",
        "                          row['start'], row['end'], row['binary'], row['prob'])]})\n",
        "  sentences = []\n",
        "  for vals in grouped:\n",
        "      sentence = vals['sentence']\n",
        "      tags = vals['tags']\n",
        "      tags_without_labels = [(word, start, end) for word, start, end, binary, prob in tags]\n",
        "      all_tokens = all_tokens_with_index(sentence)\n",
        "\n",
        "      sent_repr = []\n",
        "      for word, index, start, end in all_tokens:\n",
        "\n",
        "          for (w, s, e) in tags_without_labels:\n",
        "            if word == w:\n",
        "              sent_repr.append((\n",
        "                  w, s, e,\n",
        "                  tags[tags_without_labels.index((w, s, e))][3],\n",
        "                  tags[tags_without_labels.index((w, s, e))][4]\n",
        "              ))\n",
        "            else:\n",
        "              sent_repr.append((word, start, end, 0, 0.0))\n",
        "\n",
        "      if filter_punc:\n",
        "          sent_repr = list(filter(lambda vals : remove_punctuation(vals[0]), sent_repr))\n",
        "\n",
        "      sentences.append({'sentence' : sentence, 'seq' : sent_repr})\n",
        "  return sentences\n",
        "\n",
        "def split_sentence_seqs(sentences):\n",
        "  words, start_end, binary, prob = [], [], [] ,[]\n",
        "  for sent in sentences:\n",
        "      sequence = sent['seq']\n",
        "      curr_w, curr_se, curr_b, curr_p = map(list, zip(*[(vals[0],\n",
        "          (vals[1], vals[2]), vals[3], vals[4]) for vals in sequence]))\n",
        "      words.append(curr_w)\n",
        "      start_end.append(curr_se)\n",
        "      binary.append(curr_b)\n",
        "      prob.append(curr_p)\n",
        "  return words, start_end, binary, prob\n",
        "\n",
        "sentences = forward_transformation(dataset)\n",
        "\n",
        "\n",
        "words, start_end, binary, prob = split_sentence_seqs(sentences)\n",
        "\n",
        "def get_data_dic(words, start_end, binary, prob):\n",
        "  train_dic = {}\n",
        "  id_list = []\n",
        "\n",
        "  for i in range(0, len(words)):\n",
        "    id_list.append(i)\n",
        "\n",
        "  train_dic['id'] = id_list\n",
        "  train_dic['tokens'] = words\n",
        "  train_dic['start_end'] = start_end\n",
        "  train_dic['label'] = binary\n",
        "  train_dic['complex_prob'] = prob\n",
        "\n",
        "  return train_dic\n",
        "\n",
        "\n",
        "dataset_dict = get_data_dic(words, start_end, binary, prob)\n",
        "\n",
        "from datasets import Dataset\n",
        "ds = Dataset.from_dict(dataset_dict)\n",
        "ds\n",
        "\n",
        "\"\"\"\n",
        "Dataset({\n",
        "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob'],\n",
        "    num_rows: 4974\n",
        "})\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from datasets import DatasetDict\n",
        "# 90% train, 10% test + validation\n",
        "train_testvalid = ds.train_test_split(test_size=0.1)\n",
        "# Split the 10% test + valid in half test, half valid\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
        "# gather everyone if you want to have a single DatasetDict\n",
        "train_test_valid_dataset = DatasetDict({\n",
        "    'train': train_testvalid['train'],\n",
        "    'test': test_valid['test'],\n",
        "    'valid': test_valid['train']})\n",
        "\n",
        "train_test_valid_dataset\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "DatasetDict({\n",
        "    train: Dataset({\n",
        "        features: ['id', 'tokens', 'start_end', 'label', 'complex_prob'],\n",
        "        num_rows: 4476\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ['id', 'tokens', 'start_end', 'label', 'complex_prob'],\n",
        "        num_rows: 249\n",
        "    })\n",
        "    valid: Dataset({\n",
        "        features: ['id', 'tokens', 'start_end', 'label', 'complex_prob'],\n",
        "        num_rows: 249\n",
        "    })\n",
        "})\n",
        "\n",
        "longest length of a sequence in sentence coulmn is 219 tokens, and shortest length is 3 tokens\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqwr5EVi494c"
      },
      "source": [
        "#prepare data2: tokenization using ParsBERT Also aligning labels with subwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL8dp65l5e3o"
      },
      "outputs": [],
      "source": [
        "trial_tokenizer =  AutoTokenizer.from_pretrained('HooshvareLab/bert-base-parsbert-armanner-uncased')\n",
        "trial_model = AutoModelForTokenClassification.from_pretrained('HooshvareLab/bert-base-parsbert-armanner-uncased')\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    max_length = 219\n",
        "    tokenized_inputs = trial_tokenizer(examples['tokens'], truncation=True, is_split_into_words=True, padding= 'max_length', max_length=max_length,\n",
        "                                   add_special_tokens=True # Add special tokens CLS and SEP)\n",
        "    )\n",
        "\n",
        "    L_dic ={}\n",
        "    # P_dic = {}\n",
        "    # start_end_dic = {}\n",
        "\n",
        "    label_ids = []\n",
        "    # prob_ids = []\n",
        "    # start_end_ids = []\n",
        "\n",
        "    for i, label in enumerate(examples['label']):   #batch_data['label']\n",
        "        word_ids = tokenized_inputs.word_ids()  # Map tokens to their respective word.\n",
        "        previous_word_idx = None\n",
        "        L_dic[i] = label    #key is word_index and value is label of that word_index\n",
        "\n",
        "    # for i, prob in enumerate(example['complex_prob']):\n",
        "    #     P_dic[i] = prob    #key is word_index and value is label of that word_index\n",
        "\n",
        "    # for i, s_e_idx in enumerate(example['start_end']):\n",
        "    #     start_end_dic[i] = s_e_idx    #key is word_index and value is label of that word_index\n",
        "\n",
        "\n",
        "    for word_idx in word_ids:  # Set the special tokens to -100.\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "            # prob_ids.append(-100)\n",
        "            # start_end_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
        "            label_ids.append(L_dic[word_idx])\n",
        "            # prob_ids.append(P_dic[word_idx])\n",
        "            # start_end_ids.append(start_end_dic[word_idx])\n",
        "        else:\n",
        "            label_ids.append(-100)\n",
        "            # prob_ids.append(-100)\n",
        "            # start_end_ids.append(-100)\n",
        "\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    tokenized_inputs[\"aligned_labels\"] = label_ids\n",
        "    # tokenized_inputs[\"c_prob\"] = prob_ids\n",
        "    # tokenized_inputs[\"s_e_idx\"] = start_end_ids\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_data_train = train_test_valid_dataset['train'].map(tokenize_and_align_labels,)\n",
        "tokenized_data_test = train_test_valid_dataset['test'].map(tokenize_and_align_labels,)\n",
        "tokenized_data_val = train_test_valid_dataset['valid'].map(tokenize_and_align_labels,)\n",
        "\n",
        "tensor_train_dataset = tokenized_data_train.with_format(\"torch\")\n",
        "tensor_test_dataset = tokenized_data_test.with_format(\"torch\")\n",
        "tensor_val_dataset = tokenized_data_val.with_format(\"torch\")\n",
        "\n",
        "tensor_dataset = concatenate_datasets([tensor_train_dataset, tensor_test_dataset, tensor_test_dataset])\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "DatasetDict({\n",
        "    train: Dataset({\n",
        "        features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'aligned_labels'],\n",
        "        num_rows: 4476\n",
        "    })\n",
        "    test: Dataset({\n",
        "        features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'aligned_labels'],\n",
        "        num_rows: 249\n",
        "    })\n",
        "    valid: Dataset({\n",
        "        features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'aligned_labels'],\n",
        "        num_rows: 249\n",
        "    })\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4pwCrE4oFYY"
      },
      "outputs": [],
      "source": [
        "# # save tokenized dataset in torch tensor style in save_path:\n",
        "save_path = '/content/drive/MyDrive/recourses/ds'\n",
        "tokenized_data.save_to_disk(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78Kr_-YatE_a"
      },
      "outputs": [],
      "source": [
        "# load presaved_tokenized + embeddings dataset in tensor format\n",
        "\n",
        "ds_train = load_from_disk(\"/content/drive/MyDrive/with_embds_1/train\")\n",
        "ds_test = load_from_disk(\"/content/drive/MyDrive/with_embds_1/test\")\n",
        "ds_val = load_from_disk(\"/content/drive/MyDrive/with_embds_1/valid\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Dataset({\n",
        "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'aligned_labels', 'embedding'],\n",
        "    num_rows: 4476\n",
        "})\n",
        "Dataset({\n",
        "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'aligned_labels', 'embedding'],\n",
        "    num_rows: 249\n",
        "})\n",
        "Dataset({\n",
        "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'aligned_labels', 'embedding'],\n",
        "    num_rows: 249\n",
        "})\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqAg6Qvb6pd9"
      },
      "source": [
        "# extract embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCRdoZ08ESxr"
      },
      "source": [
        "A. in get_emb_ver4 we extract embeddings for all words in input sequence. this embedding is going to use in my implementation for complex word identification, using MLP and BiLSTM networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N36X7ybH6oy6"
      },
      "outputs": [],
      "source": [
        "def get_emb_ver4(ds):\n",
        "    trial_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden_states = trial_model(ds['input_ids'].unsqueeze(0), ds['attention_mask'].unsqueeze(0), output_hidden_states=True)['hidden_states']\n",
        "\n",
        "    token_embeddings = torch.stack(hidden_states[-4:], dim=0).squeeze(1).permute(1, 0, 2)\n",
        "    token_vecs_sum = torch.stack([torch.sum(token[-4:], dim=0) for token in token_embeddings])\n",
        "\n",
        "\n",
        "    return {'embedding': token_vecs_sum}\n",
        "\n",
        "train_ds_embd = tensor_train_dataset.map(get_emb_ver4)\n",
        "test_ds_emb = tensor_test_dataset.map(get_emb_ver4)\n",
        "val_ds_emb = tensor_val_dataset.map(get_emb_ver4)\n",
        "\n",
        "# save embeddings\n",
        "\n",
        "path = '/content/drive/MyDrive/pars_bert_withemb'\n",
        "train_path = path + '/train'\n",
        "test_path = path + '/test'\n",
        "val_path = path + '/val'\n",
        "\n",
        "train_ds_embd.save_to_disk(train_path)\n",
        "test_ds_emb.save_to_disk(test_path)\n",
        "val_ds_emb.save_to_disk(val_path)\n",
        "\n",
        "# retain it\n",
        "ds_train = load_from_disk(\"/content/drive/MyDrive/pars_bert_withemb/train\")\n",
        "ds_test = load_from_disk(\"/content/drive/MyDrive/pars_bert_withemb/test\")\n",
        "ds_val = load_from_disk(\"/content/drive/MyDrive/pars_bert_withemb/val\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Dataset({\n",
        "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'token_type_ids', 'attention_mask', 'aligned_labels', 'embedding'],\n",
        "    num_rows: 4476\n",
        "})\n",
        "Dataset({\n",
        "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'token_type_ids', 'attention_mask', 'aligned_labels', 'embedding'],\n",
        "    num_rows: 249\n",
        "})\n",
        "Dataset({\n",
        "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'token_type_ids', 'attention_mask', 'aligned_labels', 'embedding'],\n",
        "    num_rows: 249\n",
        "})\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7U0j6CHHUfI"
      },
      "source": [
        "B. in get_emb_ver4 we extract embeddings for only target words (the 5k words that were extracted initialy). this is done by extracting embeding for each word in a sequence and then extracting only the target word embedding.\n",
        "\n",
        "this is going to use in complex word identification models base on SVM and Balance Random Forest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELrjJaHGub0v"
      },
      "outputs": [],
      "source": [
        "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
        "                      if unicodedata.category(chr(i)).startswith('P'))\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(tbl)\n",
        "\n",
        "def get_target_idx(tokens_list, target_word, ):\n",
        "  target_idx = -1\n",
        "  try:\n",
        "    if '#' in target_word:\n",
        "      target_word_list = target_word.split('#')\n",
        "      for word in target_word_list:\n",
        "        if word in tokens_list:\n",
        "          target_idx = tokens_list.index(word)\n",
        "    else:\n",
        "      target_idx = tokens_list.index(target_word)\n",
        "  except:\n",
        "    print(target_word)\n",
        "  return target_idx\n",
        "\n",
        "def get_word_embedding(ds, tokenizer=R_tokenizer, model=R_model):\n",
        "\n",
        "  text = ds['sentences']\n",
        "  target_word = ds['tokens']\n",
        "  text = remove_punctuation(text=text)\n",
        "  tokens_list = text.split()\n",
        "\n",
        "  encoded = R_tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "  target_idx = get_target_idx(tokens_list, target_word)\n",
        "\n",
        "  token_ids_word = np.where(np.array(encoded.word_ids()) == target_idx)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      hidden_states =  model(encoded['input_ids'], encoded['attention_mask'], output_hidden_states=True)['hidden_states']\n",
        "\n",
        "  token_embeddings = torch.stack(hidden_states[-4:], dim=0).squeeze(1).permute(1, 0, 2)\n",
        "  token_vecs_sum = torch.stack([torch.sum(token[-4:], dim=0) for token in token_embeddings])\n",
        "\n",
        "  word_tokens_output = token_vecs_sum[token_ids_word]\n",
        "\n",
        "\n",
        "  return {'embedding': word_tokens_output.mean(dim=0)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIkC4XO_7w0R"
      },
      "source": [
        "# retrive data and Final Prepration!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IAVl6COCFcF"
      },
      "source": [
        "retrive dtast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFJksds4CKCT"
      },
      "outputs": [],
      "source": [
        "ds_train = load_from_disk(\"/content/drive/MyDrive/pars_bert_withemb/train\")\n",
        "ds_test = load_from_disk(\"/content/drive/MyDrive/pars_bert_withemb/test\")\n",
        "ds_val = load_from_disk(\"/content/drive/MyDrive/pars_bert_withemb/val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH7Dy25F8Bvb"
      },
      "outputs": [],
      "source": [
        "train_dataset = ds_train.remove_columns(['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'token_type_ids'])\n",
        "test_dataset = ds_test.remove_columns(['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'token_type_ids'])\n",
        "val_dataset = ds_val.remove_columns(['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'token_type_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VId891Bg8EMv"
      },
      "source": [
        "**weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed1geJT88F7A"
      },
      "outputs": [],
      "source": [
        "labels = train_dataset['aligned_labels']\n",
        "mask = (labels != -100)\n",
        "masked_labels = labels[mask]\n",
        "\n",
        "classes = np.unique(masked_labels)\n",
        "print(classes)\n",
        "weights = compute_class_weight(class_weight=\"balanced\", classes= classes, y= masked_labels.numpy())\n",
        "# weights:\n",
        "\"\"\"[0 1]\n",
        "\n",
        "array([ 0.50350712, 71.7834891 ])\"\"\"\n",
        "\n",
        "weights = torch.tensor([ 0.50350712, 71.7834891 ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE3H43O18WHj"
      },
      "source": [
        "device, plot function and time function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBz6xmFP8VgG"
      },
      "outputs": [],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veSjQMstZrzO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curve(train_losses, val_losses):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KppqByKDZI4p"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "455ktCnUeRZq"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI0MFesquJS4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# from torchmetrics.classification import BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKONWFv-eTyk"
      },
      "outputs": [],
      "source": [
        "class BiLSTMTagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                        ):\n",
        "\n",
        "        super(BiLSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers = n_layers,\n",
        "                            bidirectional = bidirectional,\n",
        "                            dropout = dropout if n_layers > 1 else 0,\n",
        "                            batch_first =True,)\n",
        "\n",
        "        # self.batch_norm = nn.BatchNorm1d(2 * hidden_dim)\n",
        "\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(2*hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, embedded_text):\n",
        "\n",
        "        outputs, _ = self.lstm(embedded_text)\n",
        "\n",
        "        # outputs = self.batch_norm(outputs.permute(0, 2, 1))\n",
        "\n",
        "        # logits = self.dropout(self.fc(self.dropout(outputs.permute(0, 2, 1))))\n",
        "        logits = self.dropout(self.fc(self.dropout(outputs)))\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIRaexbBkU0B"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = 768\n",
        "HIDDEN_DIM = 32\n",
        "OUTPUT_DIM = 2\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.6\n",
        "\n",
        "bilstm_model = BiLSTMTagger(INPUT_DIM,\n",
        "                        HIDDEN_DIM,\n",
        "                        OUTPUT_DIM,\n",
        "                        N_LAYERS,\n",
        "                        BIDIRECTIONAL,\n",
        "                        DROPOUT,\n",
        "                        )\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-100, weight=weights)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer = optim.NAdam(bilstm_model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE1SghHraNn3",
        "outputId": "6c0d28dd-2ec4-49f2-f948-4b93302b079c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BiLSTMTagger(\n",
              "  (lstm): LSTM(768, 32, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
        "\n",
        "bilstm_model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EphtwKNask2"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "from torchmetrics.classification import MulticlassF1Score\n",
        "from torchmetrics.classification import MulticlassPrecision\n",
        "from torchmetrics.classification import MulticlassRecall\n",
        "\n",
        "acc_metric = MulticlassAccuracy(num_classes=2, ignore_index=-100)\n",
        "F1_metric = MulticlassF1Score(num_classes=2, ignore_index=-100)\n",
        "percision_metric = MulticlassPrecision(num_classes=2, ignore_index=-100)\n",
        "recall_metric = MulticlassF1Score(num_classes=2, ignore_index=-100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6sUNKtvwKf5"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        embeds = batch['embedding'].to(device)\n",
        "        tags = batch['aligned_labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        predictions = model(embeds)\n",
        "\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "\n",
        "        loss = criterion(predictions, tags)\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    acc = 0.0\n",
        "    F1 = 0.0\n",
        "    recall = 0.0\n",
        "    perc = 0.0\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "            i = i + 1\n",
        "            embds = batch['embedding'].to(device)\n",
        "            tags = batch['aligned_labels'].to(device)\n",
        "\n",
        "            outputs = model(embds)\n",
        "\n",
        "            outputs = outputs.view(-1, outputs.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "\n",
        "\n",
        "            loss = criterion(outputs, tags)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # calculate metrics using ignit\n",
        "            acc += acc_metric(outputs, tags)\n",
        "            F1 += F1_metric(outputs, tags)\n",
        "            perc += percision_metric(outputs, tags)\n",
        "            recall += recall_metric(outputs, tags)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    precision = perc/i\n",
        "    recall = recall/i\n",
        "    F1 = F1/i\n",
        "    accuracy = acc/i\n",
        "\n",
        "    g1 = (2*(accuracy * recall)) / (accuracy + recall)\n",
        "\n",
        "\n",
        "\n",
        "    print('\\n -----------------------------')\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {F1:.4f}\")\n",
        "    print(f\"accuracy: {accuracy:.4f}\")\n",
        "    print(f\"G1 Score: {g1:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    avr_test_loss = epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "\n",
        "    return avr_test_loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d7jkciZJLcH"
      },
      "outputs": [],
      "source": [
        "train_iterator = torch.utils.data.DataLoader(train_dataset, batch_size=30, shuffle=True, num_workers=2)\n",
        "valid_iterator = torch.utils.data.DataLoader(val_dataset, batch_size=30, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFO7Kc2dxkZa"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "\n",
        "\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print('Train Loss: ', train_loss)\n",
        "    train_losses.append(train_loss)\n",
        "    print('Val. Loss: ', valid_loss)\n",
        "    val_losses.append(valid_loss)\n",
        "\n",
        "# Val. Acc: {valid_acc*100:.2f}\n",
        "#  Train Acc: {train_acc*100:.2f}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9TBrTn6kxYA"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "print(train_losses, '\\n', val_losses)\n",
        "plot_loss_curve(train_losses, val_losses)\n",
        "torch.save(model, '/content/drive/MyDrive/bilstm_2.pth')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1mlH1YN93CC"
      },
      "source": [
        "\n",
        "```\n",
        "Precision: 0.5199\n",
        "Recall: 0.5101\n",
        "F1 Score: 0.5101\n",
        "accuracy: 0.8024\n",
        "G1 Score: 0.6237\n",
        "Epoch: 01 | Epoch Time: 5m 33s\n",
        "Train Loss:  0.4470985011259715\n",
        "Val. Loss:  0.3810286687480079\n",
        "—------------------------------\n",
        "Precision: 0.5115\n",
        "Recall: 0.4627\n",
        "F1 Score: 0.4627\n",
        "accuracy: 0.7969\n",
        "G1 Score: 0.5855\n",
        "Epoch: 02 | Epoch Time: 5m 7s\n",
        "Train Loss:  0.4373612477382024\n",
        "Val. Loss:  0.39831074078877765\n",
        "—------------------------------\n",
        "Precision: 0.5190\n",
        "Recall: 0.4997\n",
        "F1 Score: 0.4997\n",
        "accuracy: 0.8457\n",
        "G1 Score: 0.6282\n",
        "Epoch: 03 | Epoch Time: 5m 29s\n",
        "Train Loss:  0.42501645763715107\n",
        "Val. Loss:  0.3604854775799645\n",
        "—------------------------------\n",
        "Precision: 0.5223\n",
        "Recall: 0.5158\n",
        "F1 Score: 0.5158\n",
        "accuracy: 0.8185\n",
        "G1 Score: 0.6328\n",
        "Epoch: 04 | Epoch Time: 5m 24s\n",
        "Train Loss:  0.4198496466875076\n",
        "Val. Loss:  0.3671598931153615\n",
        "—------------------------------\n",
        "Precision: 0.5233\n",
        "Recall: 0.5184\n",
        "F1 Score: 0.5184\n",
        "accuracy: 0.8073\n",
        "G1 Score: 0.6313\n",
        "Epoch: 05 | Epoch Time: 5m 35s\n",
        "Train Loss:  0.4186057557662328\n",
        "Val. Loss:  0.41698815259668565\n",
        "—------------------------------\n",
        "Precision: 0.5242\n",
        "Recall: 0.5245\n",
        "F1 Score: 0.5245\n",
        "accuracy: 0.7658\n",
        "G1 Score: 0.6226\n",
        "Epoch: 06 | Epoch Time: 5m 22s\n",
        "Train Loss:  0.41700501372416815\n",
        "Val. Loss:  0.4227830618619919\n",
        "—------------------------------\n",
        "Precision: 0.5197\n",
        "Recall: 0.5070\n",
        "F1 Score: 0.5070\n",
        "accuracy: 0.8024\n",
        "G1 Score: 0.6213\n",
        "Epoch: 07 | Epoch Time: 5m 36s\n",
        "Train Loss:  0.3977813877662023\n",
        "Val. Loss:  0.39078015089035034\n",
        "—------------------------------\n",
        "Precision: 0.5212\n",
        "Recall: 0.5196\n",
        "F1 Score: 0.5196\n",
        "accuracy: 0.7694\n",
        "G1 Score: 0.6203\n",
        "Epoch: 08 | Epoch Time: 5m 29s\n",
        "Train Loss:  0.39468146314223607\n",
        "Val. Loss:  0.46729664338959587\n",
        "—------------------------------\n",
        "Precision: 0.5202\n",
        "Recall: 0.5138\n",
        "F1 Score: 0.5138\n",
        "accuracy: 0.7715\n",
        "G1 Score: 0.6168\n",
        "Epoch: 09 | Epoch Time: 5m 58s\n",
        "Train Loss:  0.3985196859637896\n",
        "Val. Loss:  0.38831304841571385\n",
        "—------------------------------\n",
        "Precision: 0.5219\n",
        "Recall: 0.5207\n",
        "F1 Score: 0.5207\n",
        "accuracy: 0.7836\n",
        "G1 Score: 0.6256\n",
        "Epoch: 10 | Epoch Time: 5m 51s\n",
        "Train Loss:  0.3918690818548203\n",
        "Val. Loss:  0.4304463068644206\n",
        "—------------------------------\n",
        "Precision: 0.5255\n",
        "Recall: 0.5274\n",
        "F1 Score: 0.5274\n",
        "accuracy: 0.7614\n",
        "G1 Score: 0.6231\n",
        "Epoch: 11 | Epoch Time: 5m 44s\n",
        "Train Loss:  0.3821021800239881\n",
        "Val. Loss:  0.4549918870131175\n",
        "—------------------------------\n",
        "Precision: 0.5194\n",
        "Recall: 0.5112\n",
        "F1 Score: 0.5112\n",
        "accuracy: 0.7672\n",
        "G1 Score: 0.6136\n",
        "Epoch: 12 | Epoch Time: 5m 44s\n",
        "Train Loss:  0.38520427107810973\n",
        "Val. Loss:  0.39930057856771684\n",
        "—------------------------------\n",
        "Precision: 0.5246\n",
        "Recall: 0.5269\n",
        "F1 Score: 0.5269\n",
        "accuracy: 0.7892\n",
        "G1 Score: 0.6319\n",
        "Epoch: 13 | Epoch Time: 5m 44s\n",
        "Train Loss:  0.3744424530863762\n",
        "Val. Loss:  0.40717992848820156\n",
        "—------------------------------\n",
        "Precision: 0.5216\n",
        "Recall: 0.5202\n",
        "F1 Score: 0.5202\n",
        "accuracy: 0.7574\n",
        "G1 Score: 0.6168\n",
        "Epoch: 14 | Epoch Time: 6m 23s\n",
        "Train Loss:  0.37917419930299123\n",
        "Val. Loss:  0.4537353151374393\n",
        "—------------------------------\n",
        "Precision: 0.5235\n",
        "Recall: 0.5238\n",
        "F1 Score: 0.5238\n",
        "accuracy: 0.7715\n",
        "G1 Score: 0.6240\n",
        "Epoch: 15 | Epoch Time: 6m 12s\n",
        "Train Loss:  0.3687762004137039\n",
        "Val. Loss:  0.47608043087853325\n",
        "—------------------------------\n",
        "Precision: 0.5232\n",
        "Recall: 0.5226\n",
        "F1 Score: 0.5226\n",
        "accuracy: 0.7764\n",
        "G1 Score: 0.6247\n",
        "Epoch: 16 | Epoch Time: 6m 24s\n",
        "Train Loss:  0.35695472369591397\n",
        "Val. Loss:  0.44623111022843254\n",
        "—------------------------------\n",
        "Precision: 0.5237\n",
        "Recall: 0.5259\n",
        "F1 Score: 0.5259\n",
        "accuracy: 0.7487\n",
        "G1 Score: 0.6178\n",
        "Epoch: 17 | Epoch Time: 6m 25s\n",
        "Train Loss:  0.35455466926097867\n",
        "Val. Loss:  0.5084982216358185\n",
        "—------------------------------\n",
        "Precision: 0.5204\n",
        "Recall: 0.5193\n",
        "F1 Score: 0.5193\n",
        "accuracy: 0.7063\n",
        "G1 Score: 0.5985\n",
        "Epoch: 18 | Epoch Time: 6m 16s\n",
        "Train Loss:  0.351669171055158\n",
        "Val. Loss:  0.477103806204266\n",
        "—------------------------------\n",
        "Precision: 0.5278\n",
        "Recall: 0.5345\n",
        "F1 Score: 0.5345\n",
        "accuracy: 0.7599\n",
        "G1 Score: 0.6275\n",
        "Epoch: 19 | Epoch Time: 6m 21s\n",
        "Train Loss:  0.3559552330772082\n",
        "Val. Loss:  0.4670061121384303\n",
        "—------------------------------\n",
        "Precision: 0.5225\n",
        "Recall: 0.5232\n",
        "F1 Score: 0.5232\n",
        "accuracy: 0.7229\n",
        "G1 Score: 0.6071\n",
        "Epoch: 20 | Epoch Time: 6m 10s\n",
        "Train Loss:  0.350294684668382\n",
        "Val. Loss:  0.4824233320024278\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIkVeFhS-Pgk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLBPihRkwNjx"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tyJIY3CWoo_"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI2hcn7bWsoC",
        "outputId": "b26b8e0c-5c1e-4296-8443-9b98bd169952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TokenClassifier(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=32, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (3): LeakyReLU(negative_slope=0.01)\n",
            "    (4): Linear(in_features=16, out_features=16, bias=True)\n",
            "    (5): LeakyReLU(negative_slope=0.01)\n",
            "    (6): Dropout(p=0.7, inplace=False)\n",
            "    (7): Linear(in_features=16, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define PyTorch model, with dropout at input\n",
        "class TokenClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "        super(TokenClassifier, self).__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size1),\n",
        "            # nn.BatchNorm1d(hidden_size1, momentum=0.9),\n",
        "            nn.LeakyReLU(),\n",
        "            # self.dropout,\n",
        "\n",
        "            nn.Linear(hidden_size1, hidden_size2),\n",
        "            # nn.BatchNorm1d(hidden_size2, momentum=0.9),\n",
        "            nn.LeakyReLU(),\n",
        "            # self.dropout,\n",
        "\n",
        "            nn.Linear(hidden_size2, hidden_size3),\n",
        "            # # nn.BatchNorm1d(hidden_size3, momentum=0.9),\n",
        "            nn.LeakyReLU(),\n",
        "            self.dropout,\n",
        "\n",
        "            nn.Linear(hidden_size3, output_size)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x = self.flatten(x)\n",
        "        # print(x.shape)\n",
        "        x = self.layers(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# He weight initalizer\n",
        "@torch.no_grad()\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.kaiming_uniform_(m.weight,)\n",
        "\n",
        "input_size = 768  # Total number of features in the flattened input\n",
        "hidden_size1 = 32\n",
        "hidden_size2 = 16\n",
        "hidden_size3 = 16\n",
        "output_size = 2\n",
        "\n",
        "\n",
        "mlp_model = TokenClassifier(input_size, hidden_size1, hidden_size2, hidden_size3, output_size).to(device)\n",
        "mlp_model.apply(init_weights)\n",
        "print(mlp_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRAz7y6dWxXJ"
      },
      "outputs": [],
      "source": [
        "# Define model and parameters\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=-100, weight=weights)\n",
        "optimizer = optim.NAdam(model.parameters(), lr=learning_rate)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
        "\n",
        "n_epochs = 15\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao6sXfoBW0ig"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset) #4476\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "\n",
        "  for i, batch in enumerate(dataloader, 0):\n",
        "      inputs = batch['embedding'].to(device)\n",
        "      labels = batch['aligned_labels'].to(device)\n",
        "\n",
        "\n",
        "      # Compute prediction and loss\n",
        "      logits = model(inputs)\n",
        "\n",
        "      logits = logits.view(-1, logits.shape[-1])\n",
        "      labels = labels.view(-1)\n",
        "\n",
        "      loss =  loss_fn(logits, labels)\n",
        "\n",
        "      # Backpropagation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "\n",
        "      if i % 100 == 0:\n",
        "            loss, current = loss.item(), (i + 1) * len(inputs)\n",
        "            print(f\"train_loss: {round(loss, 4):>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "  return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    size = len(dataloader.dataset) #249 = total number of validation samples\n",
        "    num_batches = len(dataloader)   #9\n",
        "\n",
        "    test_loss = 0.0\n",
        "    # correct =  0\n",
        "\n",
        "    # all_predictions = []\n",
        "    # all_labels = []\n",
        "    acc = 0.0\n",
        "    F1 = 0.0\n",
        "    recall = 0.0\n",
        "    perc = 0.0\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for i, batch in enumerate(dataloader, 0):\n",
        "          inputs = batch['embedding'].to(device)\n",
        "          labels = batch['aligned_labels'].to(device)\n",
        "\n",
        "          # outputs = model(inputs)\n",
        "          logits = model(inputs)\n",
        "\n",
        "          logits = logits.view(-1, logits.shape[-1])\n",
        "          labels = labels.view(-1)\n",
        "\n",
        "          loss =  loss_fn(logits, labels)\n",
        "\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          if i % 100 == 0:\n",
        "            loss, current = loss.item(), (i + 1) * len(inputs)\n",
        "            print(f\"test_loss: {round(loss, 4):>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "          # calculate metrics using ignit\n",
        "          acc += acc_metric(logits, labels)\n",
        "          F1 += F1_metric(logits, labels)\n",
        "          perc += percision_metric(logits, labels)\n",
        "          recall += recall_metric(logits, labels)\n",
        "\n",
        "\n",
        "\n",
        "    precision = perc/num_batches\n",
        "    recall = recall/num_batches\n",
        "    F1 = F1/num_batches\n",
        "    accuracy = acc/num_batches\n",
        "    g1 = (2*(accuracy * recall)) / (accuracy + recall)\n",
        "\n",
        "\n",
        "    # Print or log the evaluation metrics\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {F1:.4f}\")\n",
        "    print(f\"accuracy: {accuracy:.4f}\")\n",
        "    print(f\"G1 Score: {g1:.4f}\")\n",
        "    # print(f\"Precision: {precision:.4f}\")\n",
        "    # print(f\"Recall: {recall:.4f}\")\n",
        "    # print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # correct /= size\n",
        "    avr_test_loss = test_loss / len(dataloader)\n",
        "\n",
        "    print(f\"Avg test_loss: {avr_test_loss:>8f} \\n\")\n",
        "\n",
        "\n",
        "\n",
        "    return avr_test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiINFOpsW6F5",
        "outputId": "c1be40a6-fcab-4634-cb5b-0b4d713ab2b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model structure: TokenClassifier(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=32, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (3): LeakyReLU(negative_slope=0.01)\n",
            "    (4): Linear(in_features=16, out_features=16, bias=True)\n",
            "    (5): LeakyReLU(negative_slope=0.01)\n",
            "    (6): Dropout(p=0.7, inplace=False)\n",
            "    (7): Linear(in_features=16, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: layers.0.weight | Mean: 0.00029602154972963035 | Std: 0.050884976983070374 | Values : tensor([[ 0.0172,  0.0550,  0.0427,  ..., -0.0675,  0.0443, -0.0534],\n",
            "        [-0.0663, -0.0397,  0.0605,  ..., -0.0182,  0.0466, -0.0829]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: layers.2.weight | Mean: -0.01516300905495882 | Std: 0.2435980588197708 | Values : tensor([[ 0.3902,  0.0089,  0.1782, -0.3817, -0.0205, -0.2448, -0.3407,  0.3579,\n",
            "          0.2365,  0.0080, -0.1908,  0.1187,  0.2746,  0.0553, -0.3862,  0.3071,\n",
            "          0.0902,  0.3972, -0.2842,  0.3941,  0.2391, -0.1711,  0.0252,  0.4284,\n",
            "         -0.3768,  0.1245, -0.2289, -0.1921, -0.1886,  0.0361, -0.2511, -0.2174],\n",
            "        [ 0.1827, -0.0987,  0.1596, -0.0401,  0.1951,  0.2474,  0.2596, -0.0733,\n",
            "          0.0737, -0.3897,  0.2013,  0.2296,  0.0482, -0.0847, -0.1787,  0.2951,\n",
            "         -0.2391,  0.0758, -0.3410, -0.2021,  0.3670, -0.0271, -0.3977, -0.3461,\n",
            "          0.1547,  0.4314, -0.2361,  0.0005, -0.1108, -0.1011, -0.0582,  0.1826]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: layers.4.weight | Mean: 0.003616633825004101 | Std: 0.35019350051879883 | Values : tensor([[-0.3909,  0.4895, -0.3885, -0.4441, -0.2010,  0.3486,  0.2640, -0.0694,\n",
            "         -0.3620, -0.2613, -0.0553, -0.0990, -0.5708, -0.0412, -0.2747, -0.5588],\n",
            "        [ 0.1607, -0.3734,  0.5197,  0.1270,  0.0918,  0.6045,  0.3629,  0.2454,\n",
            "         -0.2735, -0.0250,  0.0620,  0.5164,  0.2438, -0.3817, -0.4856, -0.1405]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: layers.7.weight | Mean: -0.07537516206502914 | Std: 0.38540756702423096 | Values : tensor([[-0.4377,  0.2719, -0.3144,  0.3073,  0.2178,  0.5202,  0.2989,  0.5699,\n",
            "          0.0551,  0.5622, -0.4622, -0.4476, -0.2354, -0.4207, -0.3277,  0.2464],\n",
            "        [-0.0964, -0.4469, -0.4198, -0.3092,  0.3866,  0.4727, -0.2001, -0.3042,\n",
            "         -0.4366, -0.4915,  0.5621,  0.0465, -0.1278, -0.4264, -0.4799, -0.5449]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  if 'weight' in name:\n",
        "        print(f'Layer: {name} | Mean: {param.mean().item()} | Std: {param.std().item()} | Values : {param[:2]} \\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4tGEHGOW6sT",
        "outputId": "2191fdd7-5a20-4686-e5ac-8bf23094e117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "train_loss: 0.563700  [   30/ 4476]\n",
            "train_loss: 0.518400  [ 3030/ 4476]\n",
            "test_loss: 0.610800  [   30/  249]\n",
            "Precision: 0.5096\n",
            "Recall: 0.4321\n",
            "F1 Score: 0.4321\n",
            "accuracy: 0.8055\n",
            "G1 Score: 0.5625\n",
            "Avg test_loss: 0.480997 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train_loss: 0.588900  [   30/ 4476]\n",
            "train_loss: 0.801100  [ 3030/ 4476]\n",
            "test_loss: 0.330000  [   30/  249]\n",
            "Precision: 0.5122\n",
            "Recall: 0.4589\n",
            "F1 Score: 0.4589\n",
            "accuracy: 0.8405\n",
            "G1 Score: 0.5937\n",
            "Avg test_loss: 0.369417 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train_loss: 0.464400  [   30/ 4476]\n",
            "train_loss: 0.360600  [ 3030/ 4476]\n",
            "test_loss: 0.291100  [   30/  249]\n",
            "Precision: 0.5122\n",
            "Recall: 0.4601\n",
            "F1 Score: 0.4601\n",
            "accuracy: 0.8477\n",
            "G1 Score: 0.5964\n",
            "Avg test_loss: 0.358399 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train_loss: 0.387100  [   30/ 4476]\n",
            "train_loss: 0.378900  [ 3030/ 4476]\n",
            "test_loss: 0.270300  [   30/  249]\n",
            "Precision: 0.5119\n",
            "Recall: 0.4579\n",
            "F1 Score: 0.4579\n",
            "accuracy: 0.8199\n",
            "G1 Score: 0.5876\n",
            "Avg test_loss: 0.374554 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train_loss: 0.279900  [   30/ 4476]\n",
            "train_loss: 0.259800  [ 3030/ 4476]\n",
            "test_loss: 0.468600  [   30/  249]\n",
            "Precision: 0.5108\n",
            "Recall: 0.4488\n",
            "F1 Score: 0.4488\n",
            "accuracy: 0.8160\n",
            "G1 Score: 0.5791\n",
            "Avg test_loss: 0.365930 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train_loss: 0.377200  [   30/ 4476]\n",
            "train_loss: 0.346900  [ 3030/ 4476]\n",
            "test_loss: 0.269700  [   30/  249]\n",
            "Precision: 0.5140\n",
            "Recall: 0.4715\n",
            "F1 Score: 0.4715\n",
            "accuracy: 0.8502\n",
            "G1 Score: 0.6066\n",
            "Avg test_loss: 0.364748 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train_loss: 0.340700  [   30/ 4476]\n",
            "train_loss: 0.335900  [ 3030/ 4476]\n",
            "test_loss: 0.781400  [   30/  249]\n",
            "Precision: 0.5142\n",
            "Recall: 0.4779\n",
            "F1 Score: 0.4779\n",
            "accuracy: 0.8118\n",
            "G1 Score: 0.6016\n",
            "Avg test_loss: 0.366127 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train_loss: 0.369000  [   30/ 4476]\n",
            "train_loss: 0.797600  [ 3030/ 4476]\n",
            "test_loss: 0.411200  [   30/  249]\n",
            "Precision: 0.5139\n",
            "Recall: 0.4748\n",
            "F1 Score: 0.4748\n",
            "accuracy: 0.8308\n",
            "G1 Score: 0.6043\n",
            "Avg test_loss: 0.377233 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train_loss: 0.302200  [   30/ 4476]\n",
            "train_loss: 0.408600  [ 3030/ 4476]\n",
            "test_loss: 0.397600  [   30/  249]\n",
            "Precision: 0.5179\n",
            "Recall: 0.4951\n",
            "F1 Score: 0.4951\n",
            "accuracy: 0.8585\n",
            "G1 Score: 0.6280\n",
            "Avg test_loss: 0.443481 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train_loss: 0.290700  [   30/ 4476]\n",
            "train_loss: 0.267200  [ 3030/ 4476]\n",
            "test_loss: 0.215600  [   30/  249]\n",
            "Precision: 0.5136\n",
            "Recall: 0.4762\n",
            "F1 Score: 0.4762\n",
            "accuracy: 0.8189\n",
            "G1 Score: 0.6022\n",
            "Avg test_loss: 0.458971 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train_loss: 0.272500  [   30/ 4476]\n",
            "train_loss: 0.310800  [ 3030/ 4476]\n",
            "test_loss: 0.396400  [   30/  249]\n",
            "Precision: 0.5191\n",
            "Recall: 0.4955\n",
            "F1 Score: 0.4955\n",
            "accuracy: 0.8613\n",
            "G1 Score: 0.6291\n",
            "Avg test_loss: 0.431799 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train_loss: 0.253700  [   30/ 4476]\n",
            "train_loss: 0.287100  [ 3030/ 4476]\n",
            "test_loss: 0.421000  [   30/  249]\n",
            "Precision: 0.5145\n",
            "Recall: 0.4646\n",
            "F1 Score: 0.4646\n",
            "accuracy: 0.8397\n",
            "G1 Score: 0.5982\n",
            "Avg test_loss: 0.326477 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train_loss: 0.282400  [   30/ 4476]\n",
            "train_loss: 0.502200  [ 3030/ 4476]\n",
            "test_loss: 0.361100  [   30/  249]\n",
            "Precision: 0.5146\n",
            "Recall: 0.4776\n",
            "F1 Score: 0.4776\n",
            "accuracy: 0.8625\n",
            "G1 Score: 0.6148\n",
            "Avg test_loss: 0.415386 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "train_loss: 0.254100  [   30/ 4476]\n",
            "train_loss: 0.253400  [ 3030/ 4476]\n",
            "test_loss: 0.533400  [   30/  249]\n",
            "Precision: 0.5157\n",
            "Recall: 0.4834\n",
            "F1 Score: 0.4834\n",
            "accuracy: 0.8614\n",
            "G1 Score: 0.6193\n",
            "Avg test_loss: 0.426306 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "train_loss: 0.219000  [   30/ 4476]\n",
            "train_loss: 0.288500  [ 3030/ 4476]\n",
            "test_loss: 0.341100  [   30/  249]\n",
            "Precision: 0.5157\n",
            "Recall: 0.4854\n",
            "F1 Score: 0.4854\n",
            "accuracy: 0.8223\n",
            "G1 Score: 0.6104\n",
            "Avg test_loss: 0.456058 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_losses = []  # List to store training losses\n",
        "val_losses = []    # List to store validation losses\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "\n",
        "    train_loss = train_loop(trainloader, model, loss_fn, optimizer)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    val_loss = test_loop(validationloader, model, loss_fn)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7Mgp0mbYdR1X",
        "outputId": "2b8f2fd7-6653-4e40-cedb-366a76a9b5f3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss_curve(train_losses, val_losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiReDcsgQGcE",
        "outputId": "653b2c21-1d5c-4575-9bb8-ed2dffe19331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([6570, 2]) torch.Size([6570])\n"
          ]
        }
      ],
      "source": [
        "output = torch.randn(30, 219, 2)\n",
        "labels = torch.randn(30, 219)\n",
        "\n",
        "output = output.view(-1, output.shape[-1])\n",
        "labels = labels.view(-1)\n",
        "print(output.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohuS5vbmpi5a"
      },
      "outputs": [],
      "source": [
        "torch.save(model, '/content/drive/MyDrive/modified_MLP_cwi.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4JrEKF0IlgE"
      },
      "source": [
        "# Balance Random Forest and SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lN1KJ_qIyek"
      },
      "source": [
        "prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OStBjQLnbve"
      },
      "outputs": [],
      "source": [
        "X = ds_train['embedding']\n",
        "y = ds_train['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnXohokQxtGY"
      },
      "outputs": [],
      "source": [
        "X_test = ds_test['embedding']\n",
        "y_test = ds_test['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLFho7Kxxjt9"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "# handling Nan in X\n",
        "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp = imp.fit(X)\n",
        "\n",
        "X_train_imp = imp.transform(X)\n",
        "X_test_imp = imp.transform(X_test)\n",
        "\n",
        "# clf = svm.SVC()\n",
        "# clf = clf.fit(X_train_imp, y)\n",
        "# predictions = clf.predict(X_test_imp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcK6-KDI62L"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "ULh0mwfx0o_L",
        "outputId": "acc397bf-9b5b-4ef8-dadd-033a77ba9dac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;linear_svc&#x27;,\n",
              "                 LinearSVC(C=1, class_weight=&#x27;balanced&#x27;, loss=&#x27;hinge&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;linear_svc&#x27;,\n",
              "                 LinearSVC(C=1, class_weight=&#x27;balanced&#x27;, loss=&#x27;hinge&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=1, class_weight=&#x27;balanced&#x27;, loss=&#x27;hinge&#x27;)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('linear_svc',\n",
              "                 LinearSVC(C=1, class_weight='balanced', loss='hinge'))])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm_clf = Pipeline([\n",
        "(\"scaler\", StandardScaler()),\n",
        "(\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", class_weight='balanced')),\n",
        "])\n",
        "svm_clf.fit(X_train_imp, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "eSgfE1kAe7tv",
        "outputId": "5ce000a4-dfbe-4394-9f5e-2c9ab6e5861a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[138  42]\n",
            " [ 45  25]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.77      0.76       180\n",
            "           1       0.37      0.36      0.36        70\n",
            "\n",
            "    accuracy                           0.65       250\n",
            "   macro avg       0.56      0.56      0.56       250\n",
            "weighted avg       0.65      0.65      0.65       250\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrFklEQVR4nO3dd1xT1/sH8E8ChA2KyFIU956oFBdasdiq1daB4gDrrKNW3BO1Klp3XdS6J6C21dZB1ap11Qluse6JioMNgeT8/vBHviJDAgmB8Hm/Xnm1OTn33icXIU/Ofe45EiGEABEREZGekOo6ACIiIiJNYnJDREREeoXJDREREekVJjdERESkV5jcEBERkV5hckNERER6hckNERER6RUmN0RERKRXmNwQERGRXmFyQ0RERHqFyQ0R5WjDhg2QSCSqh6GhIcqUKQM/Pz88efIky22EENi8eTNatmyJEiVKwMzMDHXq1MHMmTORkJCQ7bF+++03fP7557C1tYVMJoOTkxO6d++Ov//+O1exJicnY/HixXBzc4O1tTVMTExQtWpVDB8+HLdu3crT+yeiokfCtaWIKCcbNmxAv379MHPmTFSoUAHJycn4999/sWHDBri4uODq1aswMTFR9VcoFPDx8UFoaChatGiBr7/+GmZmZjh+/Di2bduGmjVr4tChQ7C3t1dtI4TAN998gw0bNqBBgwbo2rUrHBwc8OzZM/z222+4cOECTp48iaZNm2YbZ3R0NNq1a4cLFy6gQ4cO8PT0hIWFBSIjIxEcHIyoqCjI5XKtnisiKiQEEVEO1q9fLwCIc+fOZWgfP368ACBCQkIytM+ZM0cAEGPGjMm0rz179gipVCratWuXoX3+/PkCgPj++++FUqnMtN2mTZvEmTNncoyzffv2QiqVip07d2Z6LTk5WYwePTrH7XMrNTVVpKSkaGRfRKQdTG6IKEfZJTd//vmnACDmzJmjaktMTBQlS5YUVatWFampqVnur1+/fgKAOH36tGobGxsbUb16dZGWlpanGP/9918BQAwcODBX/T08PISHh0emdl9fX1G+fHnV83v37gkAYv78+WLx4sWiYsWKQiqVin///VcYGBiI6dOnZ9rHzZs3BQCxbNkyVdubN2/EyJEjRdmyZYVMJhOVKlUSc+fOFQqFQu33SkQfx5obIsqT+/fvAwBKliypajtx4gTevHkDHx8fGBoaZrld3759AQB//vmnapvXr1/Dx8cHBgYGeYplz549AIA+ffrkafuPWb9+PZYtW4ZBgwZh4cKFcHR0hIeHB0JDQzP1DQkJgYGBAbp16wYASExMhIeHB7Zs2YK+ffvip59+QrNmzTBx4kT4+/trJV6i4i7rvz5ERB+IiYlBdHQ0kpOTcebMGcyYMQPGxsbo0KGDqs/169cBAPXq1ct2P+mv3bhxI8N/69Spk+fYNLGPnDx+/Bi3b99G6dKlVW3e3t4YPHgwrl69itq1a6vaQ0JC4OHhoaopWrRoEe7cuYPw8HBUqVIFADB48GA4OTlh/vz5GD16NJydnbUSN1FxxZEbIsoVT09PlC5dGs7OzujatSvMzc2xZ88elC1bVtUnLi4OAGBpaZntftJfi42NzfDfnLb5GE3sIyddunTJkNgAwNdffw1DQ0OEhISo2q5evYrr16/D29tb1bZjxw60aNECJUuWRHR0tOrh6ekJhUKBf/75RysxExVnHLkholxZsWIFqlatipiYGKxbtw7//PMPjI2NM/RJTy7Sk5ysfJgAWVlZfXSbj3l/HyVKlMjzfrJToUKFTG22trZo06YNQkND8cMPPwB4N2pjaGiIr7/+WtXvv//+w+XLlzMlR+levHih8XiJijsmN0SUK02aNEGjRo0AAJ07d0bz5s3h4+ODyMhIWFhYAABq1KgBALh8+TI6d+6c5X4uX74MAKhZsyYAoHr16gCAK1euZLvNx7y/jxYtWny0v0QigchiFgyFQpFlf1NT0yzbe/TogX79+iEiIgL169dHaGgo2rRpA1tbW1UfpVKJtm3bYty4cVnuo2rVqh+Nl4jUw8tSRKQ2AwMDBAYG4unTp1i+fLmqvXnz5ihRogS2bduWbaKwadMmAFDV6jRv3hwlS5bE9u3bs93mYzp27AgA2LJlS676lyxZEm/fvs3U/uDBA7WO27lzZ8hkMoSEhCAiIgK3bt1Cjx49MvSpVKkS4uPj4enpmeWjXLlyah2TiD6OyQ0R5UmrVq3QpEkTLFmyBMnJyQAAMzMzjBkzBpGRkZg8eXKmbfbu3YsNGzbAy8sLn3zyiWqb8ePH48aNGxg/fnyWIypbtmzB2bNns43F3d0d7dq1w5o1a/D7779nel0ul2PMmDGq55UqVcLNmzfx8uVLVdulS5dw8uTJXL9/AChRogS8vLwQGhqK4OBgyGSyTKNP3bt3x+nTpxEWFpZp+7dv3yItLU2tYxLRx3GGYiLKUfoMxefOnVNdlkq3c+dOdOvWDatWrcKQIUMAvLu04+3tjV27dqFly5bo0qULTE1NceLECWzZsgU1atTA4cOHM8xQrFQq4efnh82bN6Nhw4aqGYqjoqLw+++/4+zZszh16hTc3d2zjfPly5f47LPPcOnSJXTs2BFt2rSBubk5/vvvPwQHB+PZs2dISUkB8O7uqtq1a6NevXro378/Xrx4gaCgINjb2yM2NlZ1m/v9+/dRoUIFzJ8/P0Ny9L6tW7eid+/esLS0RKtWrVS3padLTExEixYtcPnyZfj5+cHV1RUJCQm4cuUKdu7cifv372e4jEVEGqDbaXaIqLDLbhI/IYRQKBSiUqVKolKlShkm4FMoFGL9+vWiWbNmwsrKSpiYmIhatWqJGTNmiPj4+GyPtXPnTvHZZ58JGxsbYWhoKBwdHYW3t7c4evRormJNTEwUCxYsEI0bNxYWFhZCJpOJKlWqiBEjRojbt29n6LtlyxZRsWJFIZPJRP369UVYWFiOk/hlJzY2VpiamgoAYsuWLVn2iYuLExMnThSVK1cWMplM2NraiqZNm4oFCxYIuVyeq/dGRLnHkRsiIiLSK6y5ISIiIr3C5IaIiIj0CpMbIiIi0itMboiIiEivMLkhIiIivcLkhoiIiPRKsVtbSqlU4unTp7C0tIREItF1OERERJQLQgjExcXByckJUmnOYzPFLrl5+vQpnJ2ddR0GERER5cGjR49QtmzZHPsUu+TG0tISwLuTY2VlpeNoiIiIKDdiY2Ph7Oys+hzPSbFLbtIvRVlZWTG5ISIiKmJyU1LCgmIiIiLSK0xuiIiISK8wuSEiIiK9UuxqbnJLoVAgNTVV12EQ6SWZTPbRWzmJiPKKyc0HhBCIiorC27dvdR0Kkd6SSqWoUKECZDKZrkMhIj3E5OYD6YmNnZ0dzMzMONEfkYalT6T57NkzlCtXjr9jRKRxTG7eo1AoVIlNqVKldB0Okd4qXbo0nj59irS0NBgZGek6HCLSM7zo/Z70GhszMzMdR0Kk39IvRykUCh1HQkT6iMlNFjhMTqRd/B0jIm1ickNERER6RafJzT///IOOHTvCyckJEokEv//++0e3OXr0KBo2bAhjY2NUrlwZGzZs0HqcpN8iIyPh4OCAuLg4XYeiNz755BPs2rVL12EQUTGl0+QmISEB9erVw4oVK3LV/969e2jfvj1at26NiIgIfP/99xgwYADCwsK0HGnh5+fnB4lEAolEAiMjI1SoUAHjxo1DcnJypr5//vknPDw8YGlpCTMzMzRu3DjbJHHXrl1o1aoVrK2tYWFhgbp162LmzJl4/fq1lt9RwZk4cSJGjBiR5WJs1atXh7GxMaKiojK95uLigiVLlmRqnz59OurXr5+hLSoqCiNGjEDFihVhbGwMZ2dndOzYEYcPH9bU28jSjh07UL16dZiYmKBOnTrYt29fjv2PHj2q+nf0/uP995+bLyVTpkzBhAkToFQqNf2WiIg+SqfJzeeff45Zs2bhq6++ylX/oKAgVKhQAQsXLkSNGjUwfPhwdO3aFYsXL9ZypEVDu3bt8OzZM9y9exeLFy/Gzz//jICAgAx9li1bhk6dOqFZs2Y4c+YMLl++jB49emDIkCEYM2ZMhr6TJ0+Gt7c3GjdujP379+Pq1atYuHAhLl26hM2bNxfY+5LL5Vrb98OHD/Hnn3/Cz88v02snTpxAUlISunbtio0bN+b5GPfv34erqyv+/vtvzJ8/H1euXMGBAwfQunVrDBs2LB/R5+zUqVPo2bMn+vfvj/DwcHTu3BmdO3fG1atXP7ptZGQknj17pnrY2dmpXsvNl5LPP/8ccXFx2L9/v0beCxHphhACifK0PD2EEDqLu0jdCn769Gl4enpmaPPy8sL333+f7TYpKSlISUlRPY+NjdVWeDpnbGwMBwcHAICzszM8PT1x8OBBzJs3DwDw6NEjjB49Gt9//z3mzJmj2m706NGQyWT47rvv0K1bN7i5ueHs2bOYM2cOlixZgpEjR6r6uri4oG3btjlOcvj48WOMHTsWYWFhSElJQY0aNbBixQq4ubnBz88Pb9++zfBt//vvv0dERASOHj0KAGjVqhVq164NQ0NDbNmyBXXq1IGjoyMUCgVCQkJU26WmpsLR0RGLFi1C3759oVQqMW/ePKxevRpRUVGoWrUqpk6diq5du2Yba2hoKOrVq4cyZcpkem3t2rXw8fGBh4cHRo4cifHjx+d4/rMzdOhQSCQSnD17Fubm5qr2WrVq4ZtvvsnTPnNj6dKlaNeuHcaOHQsA+OGHH3Dw4EEsX74cQUFBOW5rZ2eHEiVKZPna559/js8//zzH7Q0MDPDFF18gODgY7du3z1P8RKRbQgh0DTqNCw/e5Gn76zO9YCbTTZpRpAqKo6KiYG9vn6HN3t4esbGxSEpKynKbwMBAWFtbqx7Ozs5qHTM/WWt+H/nJeq9evYpTp05lmAF2586dSE1NzTRCAwCDBw+GhYUFtm/fDgDYunUrLCwsMHTo0Cz3n90HX3x8PDw8PPDkyRPs2bMHly5dwrhx49S+PLFx40bIZDKcPHkSQUFB6NWrF/744w/Ex8er+oSFhSExMVE18hcYGIhNmzYhKCgI165dw6hRo9C7d28cO3Ys2+McP34cjRo1ytQeFxeHHTt2oHfv3mjbti1iYmJw/Phxtd4DALx+/RoHDhzAsGHDMiQ26bI7j8D/fgY5PXKKKbsvA6dPn/5o3PXr14ejoyPatm2LkydPfrR/Vpo0aZKnc0ZEhUNSqiLXiY0iMQaKhLfaDUgNRWrkJi8mTpwIf39/1fPY2Fi1EpykVAVqTtNNTY+6We+ff/4JCwsLpKWlISUlBVKpFMuXL1e9fuvWLVhbW8PR0THTtjKZDBUrVsStW7cAAP/99x8qVqyo9gRr27Ztw8uXL3Hu3DnY2NgAACpXrqzWPgCgSpUq+PHHH1XPK1WqBHNzc/z222/o06eP6lhffvklLC0tkZKSgjlz5uDQoUNwd3cHAFSsWBEnTpzAzz//DA8PjyyP8+DBgyyTm+DgYFSpUgW1atUCAPTo0QNr165FixYt1Hoft2/fhhAC1atXV2s7APjyyy/h5uaWY5+sRpzSZfdlIKv6oXSOjo4ICgpCo0aNkJKSgjVr1qBVq1Y4c+YMGjZsqFb8Tk5OePToEZRKJdeRIirizk/xhJnMIMvXThw/Dr++g1CtWnXs2bsPBgbv+pkaZd2/IBSp5MbBwQHPnz/P0Pb8+XNYWVnB1NQ0y22MjY1hbGxcEOHpXOvWrbFq1SokJCRg8eLFMDQ0RJcuXfK0r7yOGkVERKBBgwaqxCavXF1dMzw3NDRE9+7dsXXrVvTp0wcJCQnYvXs3goODAbxLIhITE9G2bdsM28nlcjRo0CDb4yQlJcHExCRT+7p169C7d2/V8969e8PDwwPLli3LsvA4O/kZfbO0tFTrWJpQrVo1VKtWTfW8adOmuHPnDhYvXqx2nZWpqSmUSiVSUlKy/f0koqLBTGaQ6cu2UqlEYGAgpk2bBqVSCWsrK8S/fZ3lF+iCVqSSG3d390x3exw8eFD1TV0bTI0McH2ml9b2/7Fjq8Pc3Fw1SrJu3TrUq1cPa9euRf/+/QEAVatWRUxMDJ4+fQonJ6cM28rlcty5cwetW7dW9T1x4gRSU1PVGr352IeYVCrN9IGf1errWV3C6dWrFzw8PPDixQscPHgQpqamaNeuHQCoLlft3bs302hGTsmtra0t3rzJOOx6/fp1/Pvvvzh79myGOhuFQoHg4GAMHDgQAGBlZYWYmJhM+3z79i2sra0BvBuBkkgkuHnzZrYxZGfr1q0YPHhwjn3279+f7WhSdl8G0uuycqtJkyY4ceKEWtsA7y7JmZubM7EhKiKEEEhK/d+s4Yny7GcQf/78Ofr06YODBw8CAPr27YsVK1bAwsJC63Hmhk6Tm/j4eNy+fVv1/N69e4iIiICNjQ3KlSuHiRMn4smTJ9i0aRMAYMiQIVi+fDnGjRuHb775Bn///TdCQ0Oxd+9ercUokUh0VhCVH1KpFJMmTYK/vz98fHxgamqKLl26YPz48Vi4cCEWLlyYoX9QUBASEhLQs2dPAICPjw9++uknrFy5MkNBcbq3b99mWS9St25drFmzBq9fv85y9KZ06dKZ7taJiIjIVQLVtGlTODs7IyQkBPv370e3bt1U29WsWRPGxsZ4+PBhtpegstKgQQNcv349Q9vatWvRsmXLTHcDrV+/HmvXrlUlN9WqVcOFCxcy7fPixYuq0Q8bGxt4eXlhxYoV+O677zIlbdmdRyD/l6Xc3d1x+PDhDAX3efkyEBERkadvYlevXs1x1IyICg91iof//vtv9OrVC1FRUTAzM8PKlSvh6+tbAFGqQejQkSNHBIBMD19fXyGEEL6+vsLDwyPTNvXr1xcymUxUrFhRrF+/Xq1jxsTECAAiJiYm02tJSUni+vXrIikpKY/vSHd8fX1Fp06dMrSlpqaKMmXKiPnz56vaFi9eLKRSqZg0aZK4ceOGuH37tli4cKEwNjYWo0ePzrD9uHHjhIGBgRg7dqw4deqUuH//vjh06JDo2rWrWLJkSZZxpKSkiKpVq4oWLVqIEydOiDt37oidO3eKU6dOCSGEOHDggJBIJGLjxo3i1q1bYtq0acLKyirDz9nDw0OMHDkyy/1PnjxZ1KxZUxgaGorjx49neq1UqVJiw4YN4vbt2+LChQvip59+Ehs2bMj2vO3Zs0fY2dmJtLQ0IYQQcrlclC5dWqxatSpT3+vXrwsA4urVq0IIIU6ePCmkUqmYNWuWuH79urhy5YqYNGmSMDQ0FFeuXFFtd+fOHeHg4CBq1qwpdu7cKW7duiWuX78uli5dKqpXr55tbPl18uRJYWhoKBYsWCBu3LghAgIChJGRUYbYJkyYIPr06aN6vnjxYvH777+L//77T1y5ckWMHDlSSKVScejQIVWfuLg4ER4eLsLDwwUAsWjRIhEeHi4ePHiQ4fgeHh5i5syZWcZWlH/XiPRRQkqqKD/+zywfXVaeFEqlUgjx7nOlRo0aAoCoVauWuHbtWoHFmNPn94d0mtzoQnFKboQQIjAwUJQuXVrEx8er2nbv3i1atGghzM3NhYmJiXB1dRXr1q3Lcr8hISGiZcuWwtLSUpibm4u6deuKmTNnijdv3mQby/3790WXLl2ElZWVMDMzE40aNRJnzpxRvT5t2jRhb28vrK2txahRo8Tw4cNzndykJxjly5dX/bKlUyqVYsmSJaJatWrCyMhIlC5dWnh5eYljx45lG2tqaqpwcnISBw4cEEIIsXPnTiGVSkVUVFSW/WvUqCFGjRqleh4WFiaaNWsmSpYsKUqVKiVatWqV5fGePn0qhg0bJsqXLy9kMpkoU6aM+PLLL8WRI0eyjU0TQkNDRdWqVYVMJhO1atUSe/fuzfD6h18g5s2bJypVqiRMTEyEjY2NaNWqlfj7778zbPOxLyVCCPH48WNhZGQkHj16lGVcRfl3jUgfvZ/cvIxLFgkpqarHh39rIyIixJAhQ0RCQkKBxqhOciMRQoez7OhAbGwsrK2tERMTAysrqwyvJScn4969e6hQoUKWRaakn1asWIE9e/ZwpmsNGj9+PN68eYPVq1dn+Tp/14gKl0R5murO4A/v1P3rr7/w4MED1SV5Xcnp8/tDRa+YhEjDBg8ejLdv3yIuLq7A707SV3Z2dhmmYCCigic+KBDOSVbFw2lpaQgICEBgYCAMDQ3h6uqq9pQQusLkhoo9Q0NDTJ48Wddh6JXRo0frOgSiYk3kc3bhx48fo2fPnqo7Jfv374+aNWtqMkStYnJDRESkZ9SZXfh9jcqXxJGDYfD19cWrV69gaWmJNWvWoHv37lqIUnuY3BAREemxnGYX/tCs6dPQYWggAKBhw4YIDQ1FpUqVtBmeVjC5yUIxq7EmKnD8HSPSrA/ra96voclqduHslCpVCgAwYsQIzJ8/v8jO8M/k5j3pE8IlJiZyVlUiLZLL5QCgWoOGiPIuv/U1CQkJqglG/f394ebmhubNm2syxALH5OY9BgYGKFGiBF68eAEAMDMzg0Qi0XFURPpFqVTi5cuXMDMzg6Eh/wQR5VdO9TWNypfMdikfuVyOcePGISwsDOfOnYOFhQUkEkmRT2wAJjeZpK+7k57gEJHmSaVSlCtXjl8eiDTsw/oaUyODLH/P7t69C29vb5w/fx4A8Mcff6iW39EHTG4+IJFI4OjoCDs7uywXdCSi/JPJZJBKpboOg0jv5Ka+ZteuXfjmm28QGxuLkiVLYuPGjejYsWMBRVgwmNxkw8DAgPUARESkN5KTkzFmzBjVosBNmzbF9u3bUa5cOR1Hpnn86kRERFQMjB07VpXYjB8/HkePHtXLxAZgckNERFQsTJ48GbVr18b+/fsxd+5c1R3C+ojJDRERkR5KSkrCtm3bVM8dHBxw6dIltGvXTodRFQzW3BAREemZmzdvonv37rhy5QoMDQ1VyycUl0J+JjdERESFgDqreL/vwxW9N23ahG+//RaJiYmws7ODjY2NpkIsMpjcEBER6Vh+ZxkGAKU8GUMGDcDmjRsBAJ9++im2bNkCR0dHTYVZZDC5ISIi0rG8ruKdTv7yAeL3z8fmZ/chlUoREBCAyZMnF9spTZjcEBERFSLqrOKdbu8ff6D7uvtwdHTEtm3b0KpVK+0EV0QwuSEiIipEcruKtxBCtbRCty5fYc2aNejYsSPs7Oy0HWKhVzzKpomIiPTIpUuX0Lx5czx69EjV1r9/fyY2/4/JDRERUREhhMDPP/8MNzc3nDp1CqNHj9Z1SIUSL0sREREVAbGxsRg0aBBCQkIAAO3bt8fKlSt1HFXhxJEbIiKiQu7ixYtwdXVFSEgIDA0NMX/+fOzZswe2tra6Dq1Q4sgNERFRIXbkyBG0a9cOcrkc5cqVQ0hICD755BNdh1WoMbkhIiIqxD755BNUq1YNFStWxLp164rljMPqYnJDRERUyFy7dg3Vq1eHgYEBTE1NceTIEdjY2Khu/aacseaGiIiokBBCYNnSJWjQoAECAwNV7aVKlWJiowaO3BARERUCiqQ4vNq3GBNunwUAXL16NcNEfZR7HLkhIiLSESEEEuVpOPrPCTxb/x2Sbp+FTCbDihUrsH37diY2ecSRGyIiIh0QQqDLypM4snMt3h7bBAglDEs64siB3WjapLGuwyvSmNwQERHpQFKqAmcuXcfb41sBoYRZDQ94DpwM98aNdB1akcfkhoiISEeMbMrApu0QTPmiOgYNGggzmSEvRWkAa26IiIgKiFKpxJw5c3D27FlVm2U9LwwePAjmxkZMbDSEIzdERET5IIRAUqrio/2eP3+OAf388PfhQ1i9+hccO3OhAKIrnpjcEBER5ZEQAl2DTuPCgzc59kt6cAmv/lgARcIbSAyNEV+rMzwWny6gKIsfJjdERER5lJSqyDGxEUoFYk4FI+ZkMAABI9tysO00ATLbcqo+jcqXhKmRQQFEW3wwuSEiItKA81M8YSb7X5ISGxsL765f45+TxwAAff38sHDxUpiZmWXYztTIgLU2GsbkhoiISAPMZAYwk/3vY9XEpgQsLSxgbm6OoKAg9O7dW4fRFS9MboiIiDQkLS0NqampMDU1hVQqxcaNGxEdHY1q1arpOrRihbeCExERacCTx4/x6aefYsiQIaq2UqVKMbHRASY3RERE+ZR05xzcmzTC8ePH8dtvv+H+/fu6DqlY42UpIiKiPEpNTcWbI+sQe/ZXAEDDhg0REhICFxcX3QZWzHHkhoiIKA8ePnwIL89PVYnNt0OH4dSpU6hcubKOIyOO3BAREalJqVSiXbt2uHHjBiTG5rD9fCQWLJ4BYxk/VgsDjtwQERGpSSqVYunSpWji5gZHv6Uwq9ZU1yHRe5jcEBER5cLdu3dx8OBB1fO2bdvi8NF/YFTCQYdRUVaY3BAREX3Erl270KBBA3Tt2hV37txRtUul/BgtjPhTISIiykZycjKGDx+Orl27IjY2FrVq1YKRkZGuw6KPYHJDRET0HiEEEuVpuHztBj5xd8eKFSsAAKNGj8H+g4dh6+CERHna/z8UOo6WssKybiIiov8nhEDXoNP4Z//veBW2HEKeBKmpFWzbj8Kvho3x6w9/6zpEygUmN0RERP8vKVWBCw/eIOXZLQh5EozL1oJtx7EwtLLNcbtG5UvC1Mggxz5UcJjcEBER4d2oTbqSrfwwuWdrfDtkMAwNP/5RaWpkAIlEos3wSA2suSEiomJvy5YtaN++PdLS0gAAEgMjjBg+DFZmJjCTGX70wcSmcOHIDRERFVsJCQkYMWIE1q9fDwDYvHEDAGedxkT5x5EbIiIqlq5du4YmTZpg/fr1kEgkmD59Ovr69dN1WKQBOk9uVqxYARcXF5iYmMDNzQ1nz57Nsf+SJUtQrVo1mJqawtnZGaNGjUJycnIBRUtEREWdEALr169H48aNcf36dTg4OODw4cMICAiAgQGLgvWBTpObkJAQ+Pv7IyAgABcvXkS9evXg5eWFFy9eZNl/27ZtmDBhAgICAnDjxg2sXbsWISEhmDRpUgFHTkRERdWMGTPwzTffICkpCW3btsWlS5fQunVrXYdFGqTT5GbRokUYOHAg+vXrh5o1ayIoKAhmZmZYt25dlv1PnTqFZs2awcfHBy4uLvjss8/Qs2fPj472EBERpfP29oaVlRVmz56NAwcOwM7OTtchkYbpLLmRy+W4cOECPD09/xeMVApPT0+cPn06y22aNm2KCxcuqJKZu3fvYt++ffjiiy+yPU5KSgpiY2MzPIiIqPgQQiAiIkL1vEaNGrh37x4mTZrEtaH0lM5+qtHR0VAoFLC3t8/Qbm9vj6ioqCy38fHxwcyZM9G8eXMYGRmhUqVKaNWqVY6XpQIDA2Ftba16ODuzCp6IqLiIjY2Fj48PXF1dcfz4cVW7jY2NDqMibStSKevRo0cxZ84crFy5EhcvXsSvv/6KvXv34ocffsh2m4kTJyImJkb1ePToUQFGTEREuhIeHg5XV1cEBwdDIpHgxo0bug6JCojO5rmxtbWFgYEBnj9/nqH9+fPncHBwyHKbqVOnok+fPhgwYAAAoE6dOkhISMCgQYMwefLkLIcXjY2NYWxsrPk3QEREhZIQAitXroS/vz/kcjnKlSuH4OBguLu76zo0KiA6G7mRyWRwdXXF4cOHVW1KpRKHDx/O9h9gYmJipgQm/ba996fNJiKi4unt27fo1q0bhg8fDrlcji+//BLh4eHZfq6krwDOVb71i05nKPb394evry8aNWqEJk2aYMmSJUhISEC/fu8mUerbty/KlCmDwMBAAEDHjh2xaNEiNGjQAG5ubrh9+zamTp2Kjh07cm4CIiLC77//jl27dsHIyAg//vgjRo4cme3SCOkrgF948KaAoyRt02ly4+3tjZcvX2LatGmIiopC/fr1ceDAAVWR8cOHDzOM1EyZMgUSiQRTpkzBkydPULp0aXTs2BGzZ8/W1VsgIqJCxNfXF5cvX0bPnj3RuHHjHPumrwCeFa7yXbRJRDG7nhMbGwtra2vExMTAyspK1+EQEVE+vH79GlOmTFHdGauORHkaak4LAwCcn+IJM9n/khmu8l34qPP5zYUziYioSDp9+jR69OiBhw8fIiYmBlu3bs3zvsxkBjCT8SNRX/AnSURERYpSqcTChQsxadIkpKWloVKlShg9ejSEEEhKzX1BMIuH9ReTGyIiKjKio6Ph6+uLffv2AXhXu7l69WpYWlqyOJhUmNwQEVGREBERgQ4dOuDJkycwNjbGTz/9hIEDB0IikSBRnpbnxIbFw/qHyQ0RERUJZcuWBQBUq1YNoaGhqFu3bpb9PiwO/hgWD+sfJjdERFRoxcbGqu6MsbW1RVhYGMqXLw8LC4tst2FxMPGnT0REeaZuEa86jh09in6+fTBz1mz07tMXAFChSjUA727jfh+Lg+l9TG6IiChPtDXDr1AqEHMqBDGnggGhxIipczH7VmlIJEVqrWfSISY3RESUJznN8JtXafGv8erPBUh+cBkAYF7HEzaeQ3Kd2LA4mAAmN0REpAHqFvFm5fChQ+jfbwySX7yAubk5lixbDp9evdXaB4uDCWByQ0REGpDfIt67d+/iqy87QKFQoE6dOggNDUX16tU1GCEVJ0xuiIhI5ypWrIjx48fj1atXWLx4MUxNTXUdEhVhTG6IiEgn9u/fj2rVqqFixYoAgFmzZvGSEmkES8+JiKhApaamYty4cfjiiy/Qo0cPyOVyAGBiQxrDkRsiIiowDx8+RI8ePXD69GkAQJMmTSCE0HFUpG+Y3BARUa58OGGfuhPn7dmzB35+fnjz5g2sra2xdu1adOnSRdNhEjG5ISKij8vPhH1yuRwTJkzA4sWLAQCNGzdGcHCwqtaGSNNYc0NERB+V04R9H5s4TwiBf/75BwDw/fff48SJE0xsSKs4ckNERGr5cMK+7CbOE0JAIpHA2NgYoaGhuHLlCjp16lSQoVIxxeSGiIjU8rEJ+1JSUjBmzBiUKFECP/zwA4B389hwtIYKCpMbIiICkPMK37ktHr59+za8vb1x8eJFSKVS+Pr6onLlypoMk+ijmNwQEZFGVvgODQ3FgAEDEBcXh1KlSmHjxo1MbEgnWFBMRES5XuE7q+LhpKQkDBkyBN7e3oiLi0Pz5s0RERGB9u3baytcohxx5IaIiDLIaYXvD4uHhRDw9PTEqVOnIJFIMHHiRMyYMQOGhvx4Id3hvz4iIspAnRW+JRIJBg4ciP/++w9btmzBZ599puXoiD6Ol6WIiIo5IYRasw0nJibixo0bqud+fn6IjIxkYkOFBkduiIiKMXULia9fv47u3bsjJiYGERERKFWqFACgZMmS2gyTSC0cuSEiKsY+LCTOabbhDRs2oFGjRrh27RrS0tJw//79AoqSSD0cuSEiIgDvColLmcsyzTYcHx+PYcOGYdOmTQAAT09PbNmyBfb29roIk+ijOHJDREQA3hUSf5jYXLlyBY0bN8amTZsglUoxa9YshIWFMbGhQo0jN0REei4/Mw/PmzcPN2/ehJOTE7Zv346WLVtqI0QijWJyQ0Skx/I78/CKFStgamqKOXPmoHTp0hqOjkg7eFmKiEiPqTvzcHh4OMaOHQshBADA2toav/zyCxMbKlLyNXKTnJwMExMTTcVCRERalNPMwyaGUqxatQqjRo2CXC5HzZo10a9fvwKOkEgz1B65USqV+OGHH1CmTBlYWFjg7t27AICpU6di7dq1Gg+QiIg0I33m4Q8fqUkJ8Pb2xrBhwyCXy9GxY0d06tRJ1+ES5Znayc2sWbOwYcMG/Pjjj5DJZKr22rVrY82aNRoNjoiItOvcuXNo0KABdu7cCSMjIyxatAi7d++GjY2NrkMjyjO1k5tNmzZh9erV6NWrFwwM/je8Wa9ePdy8eVOjwRERkfasW7cOzZo1w7179+Di4oITJ05g1KhRmW4HJypq1E5unjx5gsqVK2dqVyqVSE1N1UhQRESkfZUrV4ZCocDXX3+N8PBwNGnSRNchEWmE2gXFNWvWxPHjx1G+fPkM7Tt37kSDBg00FhgREWne27dvUaJECQBAy5YtcebMGbi6unK0hvSK2snNtGnT4OvriydPnkCpVOLXX39FZGQkNm3ahD///FMbMRIRUS59OGFf+iR9QiixZNEizJ8XiNOnT6N69eoAgEaNGukkTiJtkoj0yQzUcPz4ccycOROXLl1CfHw8GjZsiGnTphWJ5e5jY2NhbW2NmJgYWFlZ6TocIiKNyW7CPkViDF7tW4KkO+cAAJMmTcLs2bN1ESJRnqnz+Z2neW5atGiBgwcP5ik4IiLSjqwm7Et+fA3Re+ZDERcNY2NjLF26FIMGDdJRhEQFQ+2C4ooVK+LVq1eZ2t++fYuKFStqJCgiIsqfs5M+RT+LCEQHT4IiLhpVq1bFmTNnMHjwYNbXkN5TO7m5f/8+FIrMC62lpKTgyZMnGgmKiIjyZ1fwFkyfOgUKhQK9e/fGhQsXUK9ePV2HRVQgcn1Zas+ePar/DwsLg7W1teq5QqHA4cOH4eLiotHgiIgos+xW+X5/he9evfvgt5070KNHD/Tr14+jNVSs5Dq56dy5MwBAIpHA19c3w2tGRkZwcXHBwoULNRocERFllF3RsFAqEH/5ICzqtIHEwAiGhoYICwtjUkPFUq6TG6VSCQCoUKECzp07B1tbW60FRUREWcuqaFgR/wbRf85H8oPLSH31CJ99Mw6mRgZMbKjYUrvm5t69e0xsiIgKgfNTPLHcwxDynWOQ/OAyzMzMsGhoZ+wY4s7Ehoq1PN0KnpCQgGPHjuHhw4eQy+UZXvvuu+80EhgREWVPKBVYMGcmfpwbCCEE6tSpg9DQUNXkfETFmdrJTXh4OL744gskJiYiISEBNjY2iI6OhpmZGezs7JjcEBFpWVpcNKL/WIB5j64CAAYOHIilS5fC1NRUx5ERFQ5qX5YaNWoUOnbsiDdv3sDU1BT//vsvHjx4AFdXVyxYsEAbMRIR0XtEmhzy53dgYWGBbdu2YfXq1UxsiN6jdnITERGB0aNHQyqVwsDAACkpKXB2dsaPP/6ISZMmaSNGIqJi7/2VcoxKOqF0pwk4+e9Z9OzZU4dRERVOaic3RkZGkErfbWZnZ4eHDx8CAKytrfHo0SPNRkdERHj06BE8PDxw6NAhVZtpRVdUrlJFh1ERFV5q19w0aNAA586dQ5UqVeDh4YFp06YhOjoamzdvRu3atbURIxFRsfXHH3/Az88Pr1+/xrBhw3A+4rKuQyIq9NRObubMmYO4uDgAwOzZs9G3b198++23qFKlCtauXavxAImICqvsZgrWBLlcjmlTJmPZ0iUAgIaurti0ZRtStHM4Ir0iEe9fyC0G1FkynYgoO9nNFKwJaTHP8XL3PMif3QIAWLp+iZKt+kFiaJSh3/WZXjCT5WlGD6IiR53Pb7VrbrJz8eJFdOjQQe3tVqxYARcXF5iYmMDNzQ1nz57Nsf/bt28xbNgwODo6wtjYGFWrVsW+ffvyGjYRUZ5kNVOwJqTFvsSz9d9B/uwWpMbmKP3VZNh4DsqU2DQqXxKmRgYaPz6RPlAr5Q8LC8PBgwchk8kwYMAAVKxYETdv3sSECRPwxx9/wMvLS62Dh4SEwN/fH0FBQXBzc8OSJUvg5eWFyMhI2NnZZeovl8vRtm1b2NnZYefOnShTpgwePHiAEiVKqHVcIiJNOj/FE2YyzSQaQggMjD2EO7dvY+PmrShXvnyW/bi8AlH2cn1Zau3atRg4cCBsbGzw5s0blCpVCosWLcKIESPg7e2NkSNHokaNGmod3M3NDY0bN8by5csBvFu/ytnZGSNGjMCECRMy9Q8KCsL8+fNx8+ZNGBkZZXo9N3hZioiyom79TKJcgUaz3t29lN/LQ3fu3EGJEiVQqlSpd/tOTISRkVGe/84R6SN1Pr9z/du4dOlSzJs3D2PHjsWuXbvQrVs3rFy5EleuXEHZsmXVDlIul+PChQuYOHGiqk0qlcLT0xOnT5/Ocps9e/bA3d0dw4YNw+7du1G6dGn4+Phg/PjxMDDI+ltTSkoKUlJSVM9jY2PVjpWI9Js262c+JjQ0FAMGDECrVq2we/duSCQSmJmZFXgcRPok1zU3d+7cQbdu3QAAX3/9NQwNDTF//vw8JTYAEB0dDYVCAXt7+wzt9vb2iIqKynKbu3fvYufOnVAoFNi3bx+mTp2KhQsXYtasWdkeJzAwENbW1qqHs7NznuIlIv2Vn/qZvNa+JCcn49tvv4W3tzfi4uLw+vVrfvki0pBcj9wkJSWpvk1IJBIYGxvD0dFRa4FlRalUws7ODqtXr4aBgQFcXV3x5MkTzJ8/HwEBAVluM3HiRPj7+6uex8bGMsEhomypWz+Tl9qXW7duoXv37rh06RKAd3+nZs6cCUND3vlEpAlq/SatWbMGFhYWAIC0tDRs2LABtra2GfrkduFMW1tbGBgY4Pnz5xnanz9/DgcHhyy3cXR0hJGRUYZLUDVq1EBUVBTkcjlkMlmmbYyNjWFsbJyrmIiIzGQGWr29euvWrRg8eDASEhJQunRpbN68We2bMYgoZ7n+DS5Xrhx++eUX1XMHBwds3rw5Qx+JRJLr5EYmk8HV1RWHDx9G586dAbwbmTl8+DCGDx+e5TbNmjXDtm3boFQqVUtA3Lp1C46OjlkmNkREhUliYiKmTJmChIQEtGrVClu3boWTk5OuwyLSO7lObu7fv6/xg/v7+8PX1xeNGjVCkyZNsGTJEiQkJKBfv34AgL59+6JMmTIIDAwEAHz77bdYvnw5Ro4ciREjRuC///7DnDlzcp1QERHpkpmZGUJCQlQ1g9ndCEFE+aPTC7ze3t54+fIlpk2bhqioKNSvXx8HDhxQFRk/fPhQNUIDAM7OzggLC8OoUaNQt25dlClTBiNHjsT48eN19RaIiHK0ceNGKBQKfPPNNwCAJk2aoEmTJjqOiki/cfkFIir2EuVpqDktDIDmljSIj4/HsGHDsGnTJhgbG+Py5cuoWrVqvvdLVFxpZZ4bIiLKnStXrqB79+64efMmpFIppkyZgkqVKuk6LKJig8kNERVrQggkyjWz1LYQAmvXrsWIESOQnJwMJycnbNu2DR4eHhrZPxHlDpMbIiq2NDkzsRACvr6+qrtI27Vrh02bNqF06dL53jcRqSdPq4LfuXMHU6ZMQc+ePfHixQsAwP79+3Ht2jWNBkdEpE0fzkycn5W2JRIJqlSpAgMDA8ydOxd79+5lYkOkI2onN8eOHUOdOnVw5swZ/Prrr4iPjwcAXLp0KdtZgomICrvzUzyxY4i7WrMNCyHw5s3/kqNJkybhwoULGD9+fIY7PYmoYKn92zdhwgTMmjULBw8ezDBx3qeffop///1Xo8ERERUUM5l6yyjExMTA29sbrVq1QlJSEgDAwMAA9erV01aIRJRLaic3V65cwVdffZWp3c7ODtHR0RoJioioMDt//jwaNmyIHTt24Pr16zh58qSuQyKi96id3JQoUQLPnj3L1B4eHo4yZcpoJCgiosJICIGffvoJTZs2xd27d1G+fHmcOHECnp6eug6NiN6jdnLTo0cPjB8/HlFRUZBIJFAqlTh58iTGjBmDvn37aiNGIiKde/PmDb7++muMHDkSqamp6Ny5M8LDw+Hm5qbr0IjoA2onN3PmzEH16tXh7OyM+Ph41KxZEy1btkTTpk0xZcoUbcRIRKRzQ4cOxe+//w6ZTIaffvoJv/76K0qWLKnrsIgoC2rPcyOTyfDLL79g6tSpuHr1KuLj49GgQQNUqVJFG/ERERUK8+bNw507d7Bq1Sq4urrqOhwiyoHayc2JEyfQvHlzlCtXDuXKldNGTEREGiOEQFJq1jMQ5zQz8atXr/DHH3/Az88PAFCuXDmcOXNGrTuqiEg31E5uPv30U5QpUwY9e/ZE7969UbNmTW3ERUSUb3mdgfjkyZPo0aMHHj9+jFKlSqFjx44AwMSGqIhQu+bm6dOnGD16NI4dO4batWujfv36mD9/Ph4/fqyN+IiI8uzDGYizkz4zsVKpxNy5c+Hh4YHHjx+jSpUqcHZ2LoBIiUiTJEIIkdeN7927h23btmH79u24efMmWrZsib///luT8WmcOkumE1HRlihPQ81pYQDezUBsJst6aQVTIwO8fPkSffv2RVjYu/4+Pj4ICgqCpaVlgcVLRNlT5/M7XwtnVqhQARMmTEC9evUwdepUHDt2LD+7IyLSmA9X+zaTGcBMlvWfvGPHjqFnz5549uwZTExMsHz5cnzzzTe8DEVUROU5uTl58iS2bt2KnTt3Ijk5GZ06dUJgYKAmYyMiyhN1a22ePXuGZ8+eoUaNGggNDUXt2rW1HCERaZPayc3EiRMRHByMp0+fom3btli6dCk6deoEMzMzbcRHRKS23Kz2LYRQjcz06NEDcrkcXbp0gbm5eYHGSkSap3Zy888//2Ds2LHo3r07bG1ttRETEZHGnJ/iiVLmsgyXmA4fPowxY8Zg//79cHBwAADOsE6kR9RObrhAHBEVJe+v9q1QKDBjxgzMmjULQgjMmDEDq1at0nGERKRpuUpu9uzZg88//xxGRkbYs2dPjn2//PJLjQRGRKRJT58+hY+Pj+rGhwEDBmDhwoU6joqItCFXyU3nzp0RFRUFOzs7dO7cOdt+EokECkX2M34SEelCWFgYevfujejoaFhYWODnn3+Gj4+PrsMiIi3JVXKjVCqz/H8iosLu11070cenJwCgXr16CA0NRdWqVXUcFRFpk9ozFG/atAkpKSmZ2uVyOTZt2qSRoIiINKXtZ16oWrUqhg4din///ZeJDVExoPYMxQYGBnj27Bns7OwytL969Qp2dnaF/rIUZygm0n9Hj5+A759vIZFIcH2mF9KSE/n7TlTEqfP5rfbIzftzQ7zv8ePHsLa2Vnd3REQZvJtZOC1Pj7fxiRg5yh+tW7ZA3Pndqn0ysSEqXnJ9K3iDBg0gkUggkUjQpk0bGBr+b1OFQoF79+6hXbt2WgmSiIqHvK7iDQBpMc/xcvePkD+LBAAo4l5pOjwiKiJyndyk3yUVEREBLy8vWFhYqF6TyWRwcXFBly5dNB4gERUfuV3F+0OJt07j1b4lUKYkQGpsjlJffA+zqu5ZzkxMRPov18lNQEAAAMDFxQXe3t4wMTHRWlBERDmt4p0uJSUFkydOwKrflgMAGjdpgo2bt6K8iwuAd6t9c/FLouJH7RmKfX19tREHEVEGOa3inS7y2hX88nMQAGD06NGYM2cOZDJZQYRHRIVYrpIbGxsb3Lp1C7a2tihZsmSO34Rev36tseCIqPh4V0is3t2WDRo0wLJly1C2bFl06NBBS5ERUVGTq+Rm8eLFsLS0VP0/h3mJSJNyW0icnJyM8ePHo3///qhbty4AYMiQIQURIhEVIblKbt6/FOXn56etWIiomPqwkDirQuBbt26he/fuuHTpEv766y9cuXIlw12bRETp1J7n5uLFi7hy5Yrq+e7du9G5c2dMmjQJcrlco8ERUfFzfoondgxxzzBCvG3bNri6uuLSpUsoXbo0lixZwsSGiLKldnIzePBg3Lp1CwBw9+5deHt7w8zMDDt27MC4ceM0HiARFS9msv/d4ZSYmIiBAweiV69eiI+Ph4eHh2o6CiKi7Kid3Ny6dQv169cHAOzYsQMeHh7Ytm0bNmzYgF27dmk6PiLSY/+bjThzIXFUVBTc3NywZs0aSCQSTJs2DYcOHYKTk5MOIiWiokTtcV0hhGpl8EOHDqnuUHB2dkZ0dLRmoyMivfWxIuLSpUvDzs4O9vb22Lp1K9q0aVPAERJRUaV2ctOoUSPMmjULnp6eOHbsGFatWgUAuHfvHuzt7TUeIBHpp6xmI67vYAKJIhWAIQwMDLB161YAgIODgw4iJKKiSu3LUkuWLMHFixcxfPhwTJ48GZUrVwYA7Ny5E02bNtV4gESk/85P8cQO7zK4tXoE/P39Ve0ODg5MbIhIbRIhhNDEjpKTk2FgYAAjIyNN7E5r1FkynYi0J1GehprTwiCEwISKT+H//UgkJyfDyckJly9fRqlSpXQdIhEVIup8fuf5XsoLFy7gxo0bAICaNWuiYcOGed0VERVTypREvP5rJYZePwoA8PLywubNm5nYEFG+qJ3cvHjxAt7e3jh27BhKlCgBAHj79i1at26N4OBglC5dWtMxEpEeunz5Ep5tGoW0109gYGCAWbNmYdy4cZBK1b5aTkSUgdp/RUaMGIH4+Hhcu3YNr1+/xuvXr3H16lXExsbiu+++00aMRKRnUlJS8HWnL98lNpa2CDt0GBMmTGBiQ0QaofZfkgMHDmDlypWoUaOGqq1mzZpYsWIF9u/fr9HgiEg/GRsbY+lPy2FaqTEc+/0E96bNdB0SEekRtS9LKZXKLIuGjYyMVPPfEBF96MKFC3jz5g08PT0hhEBrry9Q+qwRF+IlIo1Te+Tm008/xciRI/H06VNV25MnTzBq1ChOskVEmQghsGzZMjRt2hTe3t54+PAhugadRqNZh5jYEJFWqJ3cLF++HLGxsXBxcUGlSpVQqVIlVKhQAbGxsVi2bJk2YiSiIurNmzfo0qULvvvuO8jlcrRs2RIGxqYfXQGciCg/1L4s5ezsjIsXL+Lw4cOqW8Fr1KgBT09PjQdHREXXmTNn0KNHD9y/fx8ymQwLFizA8OHDkZT6v3Wkzk/xRClzGUdwiEij1EpuQkJCsGfPHsjlcrRp0wYjRozQVlxEVEQJIbB48WKMHz8eaWlpqFixIkJDQ+Hq6pqp7/srgBMRaUquL0utWrUKPXv2xPnz5/Hff/9h2LBhGDt2rDZjI6IiSCKR4ObNm0hLS0O3bt1w8eLFLBMbIiJtyXVys3z5cgQEBCAyMhIRERHYuHEjVq5cqc3YiKgIef9uyaVLl2LLli0ICQmBtbW1DqMiouIo18nN3bt34evrq3ru4+ODtLQ0PHv2TCuBEVHRoFQqMW/ePHTo0EGV4JiamqJXr1685EREOpHrmpuUlBSYm5urnkulUshkMiQlJWklMCIq/F6+fIm+ffviwIEDAIDdu3fjq6++0nFURFTcqVVQPHXqVJiZmamey+VyzJ49O8Ow86JFizQXHREVWv/88w969uyJp0+fwsTEBMuXL0fnzp11HRYRUe6Tm5YtWyIyMjJDW9OmTXH37l3Vcw5BE+k/hUKBwMBABAQEQKlUokaNGggNDUXt2rWz7C+EyHD7d6JckWU/IiJNyXVyc/ToUS2GQURFxdChQ7F69WoAgJ+fH5YvX57hkvX7hBDoGnQ6w6R9RETaViiW4F2xYgVcXFxgYmICNzc3nD17NlfbBQcHQyKRcCicqAB9++23sLGxwcaNG7F+/fpsExsASEpVZJvYcGZiItIWtWco1rSQkBD4+/sjKCgIbm5uWLJkCby8vBAZGQk7O7tst7t//z7GjBmDFi1aFGC0RMWPQqHA2bNn4e7uDgCoX78+Hjx4AAsLC7X2c36KJ8xk/0tmTI04gR8RaYfOR24WLVqEgQMHol+/fqhZsyaCgoJgZmaGdevWZbuNQqFAr169MGPGDFSsWLEAoyUqXp4+fYo2bdrAw8MD586dU7Wrm9gA72YjNpMZqh5MbIhIW3Sa3Mjlcly4cCHDulRSqRSenp44ffp0ttvNnDkTdnZ26N+/f0GESVQshYWFoX79+jh27BiMjY3x9OnTXG8rhECiPI3Fw0SkEzq9LBUdHQ2FQgF7e/sM7fb29rh582aW25w4cQJr165FREREro6RkpKClJQU1fPY2Ng8x0tUHKSlpWHq1KmYO3cuAKBevXoIDQ1F1apVc7U9i4iJSNfyNHJz/Phx9O7dG+7u7njy5AkAYPPmzThx4oRGg/tQXFwc+vTpg19++QW2tra52iYwMBDW1taqh7Ozs1ZjJCrKHj16hFatWqkSm6FDh+Lff//NdWIDZF1EzOJhIipIao/c7Nq1C3369EGvXr0QHh6uGhWJiYnBnDlzsG/fvlzvy9bWFgYGBnj+/HmG9ufPn8PBwSFT/zt37uD+/fvo2LGjqi19undDQ0NERkaiUqVKGbaZOHEi/P39Vc9jY2OZ4BBl49dff8XJkydhZWWFNWvWoFu3bvnaX3oRMYuHiaggqZ3czJo1C0FBQejbty+Cg4NV7c2aNcOsWbPU2pdMJoOrqysOHz6sup1bqVTi8OHDGD58eKb+1atXx5UrVzK0TZkyBXFxcVi6dGmWSYuxsTGMjY3ViououBoxYgSePn2KQYMGZfii8OFEfDl5v84mvYiYiKggqf1XJzIyEi1btszUbm1tjbdv36odgL+/P3x9fdGoUSM0adIES5YsQUJCAvr16wcA6Nu3L8qUKYPAwECYmJhkmgW1RIkSAJDt7KhElL0HDx5g6tSpWLlyJSwsLCCVSjFv3rwMfVhDQ0RFjdrJjYODA27fvg0XF5cM7SdOnMjTbdne3t54+fIlpk2bhqioKNSvXx8HDhxQFRk/fPgQUqnO71gn0ju7d++Gn58f3r59CwsLC6xcuTLLfjlNxJcT1tkQka6ondwMHDgQI0eOxLp16yCRSPD06VOcPn0aY8aMwdSpU/MUxPDhw7O8DAV8fNmHDRs25OmYRMWVXC7HuHHjsHTpUgBAkyZNMG7cuFxt++FEfDlhnQ0R6Yrayc2ECROgVCrRpk0bJCYmomXLljA2NsaYMWMwYsQIbcRIRBpy9+5deHt74/z58wCA0aNHY86cOZDJZLnanjU0RFQUqP1XSiKRYPLkyRg7dixu376N+Ph41KxZM08zlhJRwTl69Cg6deqE2NhY1dpQHTp0yLZ/ehExJ+IjoqImz1/BZDIZatasqclYiEiLqlWrBhMTE9SpUwfbt2/PcUoEFhETUVGmdnLTunXrHK+j//333/kKiIg0Jzo6WjXhpaOjI44dO4ZKlSrByMgox+04ER8RFWVqJzf169fP8Dw1NRURERG4evUqfH19NRUXEeXT9u3bMXjwYKxbtw5du3YF8G6uKHVxIj4iKmrUTm4WL16cZfv06dMRHx+f74CIKH+SkpIwcuRI/PLLLwCATZs2qZKbvGARMREVNRr7i9W7d280adIECxYs0NQuiQjqzQ4cefMm+vTqiWtXr0IikWD8xEmYOHkKEuVpah2TRcREVJRpLLk5ffo0TExMNLU7IoJ6hb3xVw/j9V8rIVJTIDUvAdsOY7BdUR/bZx4ugEiJiAoPtZObr7/+OsNzIQSePXuG8+fP53kSPyLKWm5nB06Juo1Xe99dMjYpXxe2HcbCwKJkvo/PImIiKorUTm6sra0zPJdKpahWrRpmzpyJzz77TGOBEVFGOc8O7IWJJR/A2toaY8dPgIGBZhISFhETUVGkVnKjUCjQr18/1KlTByVL5v9bIRHl3vuFvUIIbNq0CW3atEHZsmUBAEsXL9JleEREhYZaK1IaGBjgs88+y9Pq30SkHiFEloW9cXFx6NOnD/z8/NCzZ0+kpalXLExEpO/UvixVu3Zt3L17FxUqVNBGPESE7AuJL126hO7du+PWrVswMDBA+/btIZWq9R2FiEjvqf1XcdasWRgzZgz+/PNPPHv2DLGxsRkeRJR/HxYSu5YrgU3r1sDNzQ23bt1C2bJlcezYMUyYMIHJDRHRB3L9V3HmzJlISEjAF198gUuXLuHLL79E2bJlUbJkSZQsWRIlSpRgHQ6RFhwd6QbDYz/h22+/RUpKCjp06ICIiAg0a9ZM16ERERVKub4sNWPGDAwZMgRHjhzRZjxE9AELUxmuX78OQ0NDzJ07F/7+/ryDiYgoB7lOboQQAAAPDw+tBUNU3KXPRpyQkgYhlJBIpDAzM0NoaChiYmLwySef6DpEIqJCT62CYn5bJNKe9CLic5GP8Gr/T5A5VIa1e3cAQI0aNXQcHRFR0aFWclO1atWPJjivX7/OV0BExVVSqgKnTv+Ll3t+hCLmOZLuXkCzL7pxhmAiIjWpldzMmDEj0wzFRJR/QggsW7oEUVsnAso0uFSogM1bt6HZJ24cMSUiUpNayU2PHj1gZ2enrViIiqXXr1/Dz88Pf/zxBwDArFoznDq+G46lS+k4MiKioinXyQ2/PRJpnlwuxyeffIL//vsPMDCCTZuBsKj/OUdIiYjyIdfz3KTfLUVEmiOTyTB0+AgYlnSCY5+FsGzwBRq72LDOhogoH3I9cqNUKrUZB1GxER0djRcvXqBmzZoAgIGDh2DRAydIjUxwfoonSpnLOFJKRJQPnLedqAAdP34c9erVQ8eOHRETEwPg3SVfqZEJgHcrfzOxISLKHyY3RFr0bmXvNMQnyzF95g9o1aoVnj59CiMjGR4+eYZEeVqWK38TEVHeqb0qOBHlTvqkfGev30X0n4uQfD8cAGBeuw0S236LjpvuALij2yCJiPQQkxsiLUlKVeDEP0fx6o8FUCS8gcTIGDZth8KiTpss+zcqX5KFxEREGsDkhkiL4s79DkXCG1SvURNbtm9HjRo1s+1rasR6GyIiTWByQ6RFpb74HrFnduF42HrYlrDSdThERMUCC4qJNOivv/7CmDFjVM8NzKxRsvU3MDMz02FURETFC0duiDQgLS0NAQEBCAwMhBACTZs2RbsOX+o6LCKiYonJDVE+PX78GD4+Pjh+/DgAYMiQIfj888/BOb2JiHSDyQ1RPuzbtw99+/bFq1evYGlpiTVr1qB79+4AgER5mo6jIyIqnlhzQ5RHc+bMQfv27fHq1Su4uroiPDxcldgQEZHuMLkhyiNXV1dIJBKMGDECJ0+eRKVKlQD8b1ZizjxMRKQbvCxFpIYXL17Azs4OAODl5YVr166hRo0aqtfTZyW+8OCNrkIkIir2OHJDlAtyuRyjRo1CtWrVcPfuXVX7+4kN8G5W4g8TG848TERUsDhyQ/QR9+7dg7e3N86dOwcA2L9/P4YNG/bR7c5P8YSZzIAzDxMRFTAmN0Q52LVrF/r374+YmBjY2Nhgw4YN6NixY662NZMZwEzGXzEiooLGv7xE7xFCIClVgeTkZEwaPw4/B60CAHzi7o4Nm7bAuVy5HG/xZhExEZHuMbkh+n/vFwPHnNmJt0c3AACs3LriabPe8FpzA8ANncZIREQfx+SG6P+9Xwxs5doJyQ+uwMq1I0wrNVJ7XywiJiLSHSY3RACSkpKwZOkyCGV1SKQGuDD9c5jN6ZDn/bGImIhId5jcUJGTXhejKZE3b6JPr564dvUqrNy9UbJlHxYDExEVYfzrTUWKpifJi7/6N17/tRIiNRlS8xIwKVdHI/slIiLdYXJDRUpWk+TlhVKejNeHgpBw5RAAwKR8Xdh2GAsDi5KslyEiKuKY3FCRlT5Jnrpu3riB3j174NGN65BKpZg0ZSrGTZgIA4N3+2K9DBFR0cbkhoqsvNbFGBtKcf/+PTg6OmLbtm1o1aqV5oMjIiKdYXJDhU5OBcN5nSRPoVCoRmZq1aqF3377DQ0aNFAtgklERPqDyQ0VKtpYVfvSpUvw8fHBzz//jObNmwN4t6I3ERHpJ64KToVKbguGc1P0K4TAzz//DDc3N1y/fh1jx46FEEJToRIRUSHFkRsqtHIqGP5Y0W9sbCwGDRqEkJAQAMAXX3yBjRs3slCYiKgYYHJDhVZeC4YvXrwIb29v3L59G4aGhggMDIS/vz+kUg5UEhEVB0xuSKPyO3twflfVvnr1Ktzd3SGXy1GuXDkEBwfD3d09X/skIqKihckNaYw2ioHVVatWLXTo0AFpaWlYv349bGxsdBYLERHpRqEYp1+xYgVcXFxgYmICNzc3nD17Ntu+v/zyC1q0aIGSJUuiZMmS8PT0zLE/FRxNzR4MqLeq9vnz5xETEwMAkEgk2LJlC37//XcmNkRExZTOR25CQkLg7++PoKAguLm5YcmSJfDy8kJkZGSWc5AcPXoUPXv2RNOmTWFiYoJ58+bhs88+w7Vr11CmTBkdvAPKSl5nD06Xm1mChRBYsmQJxo8fj6+++grBwcGQSCQwNTXN83GJiKjo0/nIzaJFizBw4ED069cPNWvWRFBQEMzMzLBu3bos+2/duhVDhw5F/fr1Ub16daxZswZKpRKHDx8u4MgpJ+nFwHl9fCyxef36NTp37gx/f3+kpqZCqVRCLpcX0LsjIqLCTKfJjVwux4ULF+Dp6alqk0ql8PT0xOnTp3O1j8TERKSmpvISRDFy+vRp1K9fH3v27IFMJsOKFSsQGhoKY2NjXYdGRESFgE4vS0VHR0OhUMDe3j5Du729PW7evJmrfYwfPx5OTk4ZEqT3paSkICUlRfU8NjY27wGTTimVSixYsACTJk2CQqFA5cqVERoaigYNGug6NCIiKkR0flkqP+bOnYvg4GD89ttvMDExybJPYGAgrK2tVQ9nZ+cCjpI05e3bt1i6dCkUCgV69uyJixcvMrEhIqJMdJrc2NrawsDAAM+fP8/Q/vz5czg4OOS47YIFCzB37lz89ddfqFu3brb9Jk6ciJiYGNXj0aNHGomdCp6NjQ22b9+O1atXY+vWrbC0tNR1SEREVAjpNLmRyWRwdXXNUAycXhyc08RrP/74I3744QccOHAAjRo1yvEYxsbGsLKyyvCgokGpVGL27NnYsmWLqq1ly5YYOHAgl1EgIqJs6fxWcH9/f/j6+qJRo0Zo0qQJlixZgoSEBPTr1w8A0LdvX5QpUwaBgYEAgHnz5mHatGnYtm0bXFxcEBUVBQCwsLCAhYWFzt5HcZY+K3F+Zxd+3/Pnz9GnTx8cPHgQZmZmaN26NW/1JyKiXNF5cuPt7Y2XL19i2rRpiIqKQv369XHgwAFVkfHDhw8zrAm0atUqyOVydO3aNcN+AgICMH369IIMnaCdWYmPHDkCHx8fREVFwdTUFMuXL4eTk5PG9k9ERPpNIoQQug6iIMXGxsLa2hoxMTG8RKUBifI01JwWlqGtUfmS2DHEXe1LRwqFArNmzcLMmTOhVCpRq1YthIaGombNmpoMmYiIiiB1Pr91PnJD+iN9VuLczC78obS0NLRr105Vf9W/f3/89NNPMDMz00aoRESkx4r0reCkW0KIDHU26bMS56XY19DQEI0bN4a5uTm2bNmCNWvWMLEhIqI84cgN5Ykmam3S0tLw5s0blC5dGgAwc+ZMDBgwAJUqVdJUmEREVAxx5Iby5MMVwNVZxRsAHj9+jNatW6N9+/aqNaGMjIyY2BARUb5x5Iby7fwUT5Qyl+X6ctS+ffvQt29fvHr1CpaWlrh69SoaNmyo5SiJiKi44MgN5ZuZLHcFxKmpqRg3bhzat2+PV69eoWHDhrh48SITGyIi0iiO3BCA/03El1vqTtj34MED9OjRA//++y8AYMSIEZg/fz5X8iYiIo1jckNamYjvQwMGDMC///4La2trrFu3Dl9//bXWjkVERMUbL0tRpuJgdeS2kHjVqlXw9PREeHg4ExsiItIqjtxQBukT8eVWdhP23bt3D4cPH8aAAQMAAJUrV8bBgwc1FicREVF2mNxQBukT8eXHrl270L9/f8TGxsLFxQWenp4aio6IiOjjmNwUI9kVDWtqNe/k5GSMGTMGK1asAAC4u7ujSpUqGtk3ERFRbjG5KSa0XTR8+/ZtdO/eHeHh4QCAcePGYdasWTAyMtLK8YiIiLLD5KaYyE3RsLqzDKfbsWMH+vfvj7i4OJQqVQqbNm3CF198kddQiYiI8oXJTTGUXdFwXlbzBoD4+HjExcWhRYsW2LZtG8qWLauJMImIiPKEyU0xpImi4bS0NBgavtuHn58fLCws8NVXX6naiIiIdIXz3OgpIQQS5WnvPTRTNAwAmzdvRt26dfHq1SsAgEQiQbdu3ZjYEBFRocBPIz2kreLhhIQEjBgxAuvXrwcA/PTTT5gxY4ZGj0FERJRfTG70UE7Fw3ktGr527Rq6d++O69evQyKRICAgAFOmTMlvqERERBrH5EbPfVg8rG7RsBACGzZswLBhw5CUlAQHBwds27YNrVu31ka4RERE+cbkRs/lt3h45cqVGD58OACgbdu22Lx5M+zt7TUVHhERkcaxoJhy1KtXL1SuXBmzZ8/GgQMHmNgQEVGhx5EbykAIgUOHDsHT0xMSiQQlSpTAlStXYGJiouvQiIiIcoUjN6QSGxsLHx8ffPbZZ/jll19U7UxsiIioKOHIDQEAwsPD0b17d9y+fRuGhoZISkrSdUhERER5wuRGD3y42rc6E/YJIbBy5Ur4+/tDLpejXLlyCA4Ohru7uzZCJSIi0jomN0Vcfibse/v2LQYMGIBdu3YBAL788kusX78eNjY2mg6TiIiowLDmpojLz4R9V65cwW+//QYjIyMsXrwYv//+OxMbIiIq8jhyo0fUnbCvRYsWWL58ORo1aoTGjRsXRIhERERax5EbPZI+YV/648PE5vXr1/Dx8UFkZKSq7dtvv2ViQ0REeoUjN8XE6dOn0aNHDzx8+BC3b9/GmTNn1FqGgYiIqKjgyI2eUyqVmD9/Plq2bImHDx+iUqVKCAoKYmJDRER6iyM3eiw6Ohq+vr7Yt28fAMDb2xurV6+GlZWVjiMjIiLSHiY3eur27dto1aoVnjx5AhMTEyxduhQDBw7kiA0REek9Jjd6qnz58ihfvjwsLCwQGhqKunXr6jokIiKiAsHkppD5cLbhj3l/NuKXL1/CsXQpyGQyGBkZYefOnbC0tISFhYU2QiUiIiqUmNwUIvmZbTj5wWW4NRqA3r16YcGCBQAAR0dHTYdIRERU6PFuqUIkp9mGsyOUCrw9sQ3PQ6bgeVQUDhw4gMTERC1FSEREVPhx5KaQ+nC24aw8e/YM/f18cezkEQDAN998g2XLlsHMzKwgQiQiIiqUmNwUUumzDWfn4MGD6N27N168eAFzc3OsWrUKffr0KcAIiYiICicmNzr0YfHw+8XBOXn79i26deuGmJgY1KlTB6Ghoahevbq2wiQiIipSmNzoSH6Kh0uUKIGgoCAcOXIES5YsgampqRYiJCIiKpqY3OhITsXDjcqXhKlRxnqb/fv3w8TEBK1btwYA9OjRAz169NB6nEREREUNk5tC4MPiYVMjA9VMwqmpqZgyZQp+/PFH2Nvb49KlS7C3t9dVqERERIUek5tCILvi4YcPH6JHjx44ffo0AKBr166wtrYu6PCIiIiKFCY3BUTd4uE9e/bAz88Pb968gbW1NdauXYsuXbpoO0wiIqIij8lNAVCneFihUGDs2LFYvHgxAKBx48YIDg5GxYoVtR0mERGRXuAMxQVAneJhqVSKFy9eAAC+//57nDhxgokNERGRGjhyU8CyKx5OS0uDoaEhJBIJVq1ahV69euHzzz/XYaRERERFE0dutEwIkaG+Jr14OP0hl8sxYsQIdOnSBUIIAIClpSUTGyIiojziyI0WfazW5vbt2/D29sbFixcBACdOnECLFi0KMkQiIiK9w5EbLfqw1ub9+pqQkBA0bNgQFy9eRKlSpfDnn38ysSEiItIAjtwUkPNTPFHKXIbk5GSMGjUKP//8MwCgefPm2L59O8qWLavjCImIiPQDR24KiJnsXeFwjx498PPPP0MikWDSpEk4cuQIExsiIiIN4siNFqRP2JfVRH2TJk3ChQsXsG7dOnz22Wc6iI6IiEi/MbnRsA+LiJWpyZA/+w+AFwDAzc0Nd+7cgbGxsQ6jJCIi0l+8LKVh7xcRy6MfImqTP17uDMB/N66p+jCxISIi0p5CkdysWLECLi4uMDExgZubG86ePZtj/x07dqB69eowMTFBnTp1sG/fvgKKNHeEEIi/fBBvt41GavRD2JWyQVxcnK7DIiIiKhZ0ntyEhITA398fAQEBuHjxIurVqwcvLy/VEgQfOnXqFHr27In+/fsjPDwcnTt3RufOnXH16tUCjjxr8fHxeLV3EV7tX4qkpCS0bdsWERERaN68ua5DIyIiKhYkIn1aXB1xc3ND48aNsXz5cgCAUqmEs7MzRowYgQkTJmTq7+3tjYSEBPz555+qtk8++QT169dHUFDQR48XGxsLa2trxMTEwMrKSmPvQwiBsxfD0cfHB//digQkUgRMn45pUyZDKtV5DklERFSkqfP5rdNPXblcjgsXLsDT01PVJpVK4enpidOnT2e5zenTpzP0BwAvL69s+6ekpCA2NjbDQxuSUhXw+n4R/rsVCQMLG9j3nINxEyYysSEiIipgOr1bKjo6GgqFAvb29hna7e3tcfPmzSy3iYqKyrJ/VFRUlv0DAwMxY8YMzQT8Edbu3QFFGiwbfQm3Gi4ZVvsmIiKigqH3t4JPnDgR/v7+quexsbFwdnbW+HFMjQxwY9YXAL5QPZdIJBo/DhEREeVMp8mNra0tDAwM8Pz58wztz58/h4ODQ5bbODg4qNXf2Ni4QG69lkgkMJPpfa5IRERU6Om0IEQmk8HV1RWHDx9WtSmVShw+fBju7u5ZbuPu7p6hPwAcPHgw2/5ERERUvOh8qMHf3x++vr5o1KgRmjRpgiVLliAhIQH9+vUDAPTt2xdlypRBYGAgAGDkyJHw8PDAwoUL0b59ewQHB+P8+fNYvXq1Lt8GERERFRI6T268vb3x8uVLTJs2DVFRUahfvz4OHDigKhp++PBhhjuOmjZtim3btmHKlCmYNGkSqlSpgt9//x21a9fW1VsgIiKiQkTn89wUNG3Nc0NERETaU2TmuSEiIiLSNCY3REREpFeY3BAREZFeYXJDREREeoXJDREREekVJjdERESkV5jcEBERkV5hckNERER6hckNERER6RWdL79Q0NInZI6NjdVxJERERJRb6Z/buVlYodglN3FxcQAAZ2dnHUdCRERE6oqLi4O1tXWOfYrd2lJKpRJPnz6FpaUlJBKJRvcdGxsLZ2dnPHr0iOtWaRHPc8HgeS4YPM8Fh+e6YGjrPAshEBcXBycnpwwLamel2I3cSKVSlC1bVqvHsLKy4i9OAeB5Lhg8zwWD57ng8FwXDG2c54+N2KRjQTERERHpFSY3REREpFeY3GiQsbExAgICYGxsrOtQ9BrPc8HgeS4YPM8Fh+e6YBSG81zsCoqJiIhIv3HkhoiIiPQKkxsiIiLSK0xuiIiISK8wuSEiIiK9wuRGTStWrICLiwtMTEzg5uaGs2fP5th/x44dqF69OkxMTFCnTh3s27evgCIt2tQ5z7/88gtatGiBkiVLomTJkvD09Pzoz4XeUfffc7rg4GBIJBJ07txZuwHqCXXP89u3bzFs2DA4OjrC2NgYVatW5d+OXFD3PC9ZsgTVqlWDqakpnJ2dMWrUKCQnJxdQtEXTP//8g44dO8LJyQkSiQS///77R7c5evQoGjZsCGNjY1SuXBkbNmzQepwQlGvBwcFCJpOJdevWiWvXromBAweKEiVKiOfPn2fZ/+TJk8LAwED8+OOP4vr162LKlCnCyMhIXLlypYAjL1rUPc8+Pj5ixYoVIjw8XNy4cUP4+fkJa2tr8fjx4wKOvGhR9zynu3fvnihTpoxo0aKF6NSpU8EEW4Spe55TUlJEo0aNxBdffCFOnDgh7t27J44ePSoiIiIKOPKiRd3zvHXrVmFsbCy2bt0q7t27J8LCwoSjo6MYNWpUAUdetOzbt09MnjxZ/PrrrwKA+O2333Lsf/fuXWFmZib8/f3F9evXxbJly4SBgYE4cOCAVuNkcqOGJk2aiGHDhqmeKxQK4eTkJAIDA7Ps3717d9G+ffsMbW5ubmLw4MFajbOoU/c8fygtLU1YWlqKjRs3aitEvZCX85yWliaaNm0q1qxZI3x9fZnc5IK653nVqlWiYsWKQi6XF1SIekHd8zxs2DDx6aefZmjz9/cXzZo102qc+iQ3yc24ceNErVq1MrR5e3sLLy8vLUYmBC9L5ZJcLseFCxfg6empapNKpfD09MTp06ez3Ob06dMZ+gOAl5dXtv0pb+f5Q4mJiUhNTYWNjY22wizy8nqeZ86cCTs7O/Tv378gwizy8nKe9+zZA3d3dwwbNgz29vaoXbs25syZA4VCUVBhFzl5Oc9NmzbFhQsXVJeu7t69i3379uGLL74okJiLC119Dha7hTPzKjo6GgqFAvb29hna7e3tcfPmzSy3iYqKyrJ/VFSU1uIs6vJynj80fvx4ODk5ZfqFov/Jy3k+ceIE1q5di4iIiAKIUD/k5TzfvXsXf//9N3r16oV9+/bh9u3bGDp0KFJTUxEQEFAQYRc5eTnPPj4+iI6ORvPmzSGEQFpaGoYMGYJJkyYVRMjFRnafg7GxsUhKSoKpqalWjsuRG9Irc+fORXBwMH777TeYmJjoOhy9ERcXhz59+uCXX36Bra2trsPRa0qlEnZ2dli9ejVcXV3h7e2NyZMnIygoSNeh6ZWjR49izpw5WLlyJS5evIhff/0Ve/fuxQ8//KDr0EgDOHKTS7a2tjAwMMDz588ztD9//hwODg5ZbuPg4KBWf8rbeU63YMECzJ07F4cOHULdunW1GWaRp+55vnPnDu7fv4+OHTuq2pRKJQDA0NAQkZGRqFSpknaDLoLy8u/Z0dERRkZGMDAwULXVqFEDUVFRkMvlkMlkWo25KMrLeZ46dSr69OmDAQMGAADq1KmDhIQEDBo0CJMnT4ZUyu/+mpDd56CVlZXWRm0Ajtzkmkwmg6urKw4fPqxqUyqVOHz4MNzd3bPcxt3dPUN/ADh48GC2/Slv5xkAfvzxR/zwww84cOAAGjVqVBChFmnqnufq1avjypUriIiIUD2+/PJLtG7dGhEREXB2di7I8IuMvPx7btasGW7fvq1KHgHg1q1bcHR0ZGKTjbyc58TExEwJTHpCKbjkosbo7HNQq+XKeiY4OFgYGxuLDRs2iOvXr4tBgwaJEiVKiKioKCGEEH369BETJkxQ9T958qQwNDQUCxYsEDdu3BABAQG8FTwX1D3Pc+fOFTKZTOzcuVM8e/ZM9YiLi9PVWygS1D3PH+LdUrmj7nl++PChsLS0FMOHDxeRkZHizz//FHZ2dmLWrFm6egtFgrrnOSAgQFhaWort27eLu3fvir/++ktUqlRJdO/eXVdvoUiIi4sT4eHhIjw8XAAQixYtEuHh4eLBgwdCCCEmTJgg+vTpo+qffiv42LFjxY0bN8SKFSt4K3hhtGzZMlGuXDkhk8lEkyZNxL///qt6zcPDQ/j6+mboHxoaKqpWrSpkMpmoVauW2Lt3bwFHXDSpc57Lly8vAGR6BAQEFHzgRYy6/57fx+Qm99Q9z6dOnRJubm7C2NhYVKxYUcyePVukpaUVcNRFjzrnOTU1VUyfPl1UqlRJmJiYCGdnZzF06FDx5s2bgg+8CDly5EiWf2/Tz62vr6/w8PDItE39+vWFTCYTFStWFOvXr9d6nBIhOP5GRERE+oM1N0RERKRXmNwQERGRXmFyQ0RERHqFyQ0RERHpFSY3REREpFeY3BAREZFeYXJDREREeoXJDRFlsGHDBpQoUULXYeSZRCLB77//nmMfPz8/dO7cuUDiIaKCx+SGSA/5+flBIpFkety+fVvXoWHDhg2qeKRSKcqWLYt+/frhxYsXGtn/s2fP8PnnnwMA7t+/D4lEgoiIiAx9li5dig0bNmjkeNmZPn266n0aGBjA2dkZgwYNwuvXr9XaDxMxIvVxVXAiPdWuXTusX78+Q1vp0qV1FE1GVlZWiIyMhFKpxKVLl9CvXz88ffoUYWFh+d73x1aPBwBra+t8Hyc3atWqhUOHDkGhUODGjRv45ptvEBMTg5CQkAI5PlFxxZEbIj1lbGwMBweHDA8DAwMsWrQIderUgbm5OZydnTF06FDEx8dnu59Lly6hdevWsLS0hJWVFVxdXXH+/HnV6ydOnECLFi1gamoKZ2dnfPfdd0hISMgxNolEAgcHBzg5OeHzzz/Hd999h0OHDiEpKQlKpRIzZ85E2bJlYWxsjPr16+PAgQOqbeVyOYYPHw5HR0eYmJigfPnyCAwMzLDv9MtSFSpUAAA0aNAAEokErVq1ApBxNGT16tVwcnLKsAo3AHTq1AnffPON6vnu3bvRsGFDmJiYoGLFipgxYwbS0tJyfJ+GhoZwcHBAmTJl4OnpiW7duuHgwYOq1xUKBfr3748KFSrA1NQU1apVw9KlS1WvT58+HRs3bsTu3btVo0BHjx4FADx69Ajdu3dHiRIlYGNjg06dOuH+/fs5xkNUXDC5ISpmpFIpfvrpJ1y7dg0bN27E33//jXHjxmXbv1evXihbtizOnTuHCxcuYMKECTAyMgIA3LlzB+3atUOXLl1w+fJlhISE4MSJExg+fLhaMZmamkKpVCItLQ1Lly7FwoULsWDBAly+fBleXl748ssv8d9//wEAfvrpJ+zZswehoaGIjIzE1q1b4eLikuV+z549CwA4dOgQnj17hl9//TVTn27duuHVq1c4cuSIqu3169c4cOAAevXqBQA4fvw4+vbti5EjR+L69ev4+eefsWHDBsyePTvX7/H+/fsICwuDTCZTtSmVSpQtWxY7duzA9evXMW3aNEyaNAmhoaEAgDFjxqB79+5o164dnj17hmfPnqFp06ZITU2Fl5cXLC0tcfz4cZw8eRIWFhZo164d5HJ5rmMi0ltaX5qTiAqcr6+vMDAwEObm5qpH165ds+y7Y8cOUapUKdXz9evXC2tra9VzS0tLsWHDhiy37d+/vxg0aFCGtuPHjwupVCqSkpKy3ObD/d+6dUtUrVpVNGrUSAghhJOTk5g9e3aGbRo3biyGDh0qhBBixIgR4tNPPxVKpTLL/QMQv/32mxBCiHv37gkAIjw8PEOfD1c079Spk/jmm29Uz3/++Wfh5OQkFAqFEEKINm3aiDlz5mTYx+bNm4Wjo2OWMQghREBAgJBKpcLc3FyYmJioVk9etGhRttsIIcSwYcNEly5dso01/djVqlXLcA5SUlKEqampCAsLy3H/RMUBa26I9FTr1q2xatUq1XNzc3MA70YxAgMDcfPmTcTGxiItLQ3JyclITEyEmZlZpv34+/tjwIAB2Lx5s+rSSqVKlQC8u2R1+fJlbN26VdVfCAGlUol79+6hRo0aWcYWExMDCwsLKJVKJCcno3nz5lizZg1iY2Px9OlTNGvWLEP/Zs2a4dKlSwDeXVJq27YtqlWrhnbt2qFDhw747LPP8nWuevXqhYEDB2LlypUwNjbG1q1b0aNHD0ilUtX7PHnyZIaRGoVCkeN5A4Bq1aphz549SE5OxpYtWxAREYERI0Zk6LNixQqsW7cODx8+RFJSEuRyOerXr59jvJcuXcLt27dhaWmZoT05ORl37tzJwxkg0i9Mboj0lLm5OSpXrpyh7f79++jQoQO+/fZbzJ49GzY2Njhx4gT69+8PuVye5Yf09OnT4ePjg71792L//v0ICAhAcHAwvvrqK8THx2Pw4MH47rvvMm1Xrly5bGOztLTExYsXIZVK4ejoCFNTUwBAbGzsR99Xw4YNce/ePezfvx+HDh1C9+7d4enpiZ07d3502+x07NgRQgjs3bsXjRs3xvHjx7F48WLV6/Hx8ZgxYwa+/vrrTNuamJhku1+ZTKb6GcydOxft27fHjBkz8MMPPwAAgoODMWbMGCxcuBDu7u6wtLTE/PnzcebMmRzjjY+Ph6ura4akMl1hKRon0iUmN0TFyIULF6BUKrFw4ULVqER6fUdOqlatiqpVq2LUqFHo2bMn1q9fj6+++goNGzbE9evXMyVRHyOVSrPcxsrKCk5OTjh58iQ8PDxU7SdPnkSTJk0y9PP29oa3tze6du2Kdu3a4fXr17Cxscmwv/T6FoVCkWM8JiYm+Prrr7F161bcvn0b1apVQ8OGDVWvN2zYEJGRkWq/zw9NmTIFn376Kb799lvV+2zatCmGDh2q6vPhyItMJssUf8OGDRESEgI7OztYWVnlKyYifcSCYqJipHLlykhNTcWyZctw9+5dbN68GUFBQdn2T0pKwvDhw3H06FE8ePAAJ0+exLlz51SXm8aPH49Tp05h+PDhiIiIwH///Yfdu3erXVD8vrFjx2LevHkICQlBZGQkJkyYgIiICIwcORIAsGjRImzfvh03b97ErVu3sGPHDjg4OGQ58aCdnR1MTU1x4MABPH/+HDExMdket1evXti7dy/WrVunKiRON23aNGzatAkzZszAtWvXcOPGDQQHB2PKlClqvTd3d3fUrVsXc+bMAQBUqVIF58+fR1hYGG7duoWpU6fi3LlzGbZxcXHB5cuXERkZiejoaKSmpqJXr16wtbVFp06dcPz4cdy7dw9Hjx7Fd999h8ePH6sVE5Fe0nXRDxFpXlZFqOkWLVokHB0dhampqfDy8hKbNm0SAMSbN2+EEBkLflNSUkSPHj2Es7OzkMlkwsnJSQwfPjxDsfDZs2dF27ZthYWFhTA3Nxd169bNVBD8vg8Lij+kUCjE9OnTRZkyZYSRkZGoV6+e2L9/v+r11atXi/r16wtzc3NhZWUl2rRpIy5evKh6He8VFAshxC+//CKcnZ2FVCoVHh4e2Z4fhUIhHB0dBQBx586dTHEdOHBANG3aVJiamgorKyvRpEkTsXr16mzfR0BAgKhXr16m9u3btwtjY2Px8OFDkZycLPz8/IS1tbUoUaKE+Pbbb8WECRMybPfixQvV+QUgjhw5IoQQ4tmzZ6Jv377C1tZWGBsbi4oVK4qBAweKmJiYbGMiKi4kQgih2/SKiIiISHN4WYqIiIj0CpMbIiIi0itMboiIiEivMLkhIiIivcLkhoiIiPQKkxsiIiLSK0xuiIiISK8wuSEiIiK9wuSGiIiI9AqTGyIiItIrTG6IiIhIrzC5ISIiIr3yf8P0nz7dP+c0AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Compute classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Compute ROC curve and AUC score\n",
        "y_scores = svm_clf.decision_function(X_test_imp)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
        "auc = roc_auc_score(y_test, y_scores)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbfG-KbMLFh2"
      },
      "source": [
        "BRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1jg7EtPj3zC"
      },
      "outputs": [],
      "source": [
        "!pip install -U imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaWXwtqzkKrC",
        "outputId": "06ba8bb6-78c6-437c-9f6e-eb8cf624f1e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.77      0.76       180\n",
            "           1       0.37      0.36      0.36        70\n",
            "\n",
            "    accuracy                           0.65       250\n",
            "   macro avg       0.56      0.56      0.56       250\n",
            "weighted avg       0.65      0.65      0.65       250\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming X_train_imp, y_train are your training data\n",
        "# and X_test_imp, y_test are your test data\n",
        "\n",
        "# Define the BalancedRandomForestClassifier\n",
        "brf_clf = BalancedRandomForestClassifier(n_estimators=100, random_state=4, class_weight='balanced')\n",
        "\n",
        "# Fit the model\n",
        "brf_clf.fit(X_train_imp, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = brf_clf.predict(X_test_imp)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A10l56LsJRCy"
      },
      "source": [
        "# complex word identification model by finetunning parsbert\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRwmC1fmZS_9"
      },
      "source": [
        "**prepare data phase 2 (prepare data for transformers, tokenize and allign labels)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihJFs1FZWTi9"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = 'FacebookAI/xlm-roberta-large-finetuned-conll03-english'\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6gPTYna2WLr"
      },
      "outputs": [],
      "source": [
        "# def tokenize_and_align_labels(token, label, model_tokenizer=trial_tokenizer): #batch_data\n",
        "def tokenize_and_align_labels(examples):\n",
        "    max_length = 219\n",
        "    tokenized_inputs = roberta_tokenizer(examples['tokens'], truncation=True, is_split_into_words=True, padding= 'max_length', max_length=max_length,\n",
        "                                   add_special_tokens=True # Add special tokens CLS and SEP)\n",
        "    )\n",
        "\n",
        "    L_dic ={}\n",
        "    # P_dic = {}\n",
        "    # start_end_dic = {}\n",
        "\n",
        "    label_ids = []\n",
        "    # prob_ids = []\n",
        "    # start_end_ids = []\n",
        "\n",
        "    for i, label in enumerate(examples['label']):   #batch_data['label']\n",
        "        word_ids = tokenized_inputs.word_ids()  # Map tokens to their respective word.\n",
        "        previous_word_idx = None\n",
        "        L_dic[i] = label    #key is word_index and value is label of that word_index\n",
        "\n",
        "    # for i, prob in enumerate(example['complex_prob']):\n",
        "    #     P_dic[i] = prob    #key is word_index and value is label of that word_index\n",
        "\n",
        "    # for i, s_e_idx in enumerate(example['start_end']):\n",
        "    #     start_end_dic[i] = s_e_idx    #key is word_index and value is label of that word_index\n",
        "\n",
        "\n",
        "    for word_idx in word_ids:  # Set the special tokens to -100.\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "            # prob_ids.append(-100)\n",
        "            # start_end_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
        "            label_ids.append(L_dic[word_idx])\n",
        "            # prob_ids.append(P_dic[word_idx])\n",
        "            # start_end_ids.append(start_end_dic[word_idx])\n",
        "        else:\n",
        "            label_ids.append(-100)\n",
        "            # prob_ids.append(-100)\n",
        "            # start_end_ids.append(-100)\n",
        "\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    tokenized_inputs[\"aligned_labels\"] = label_ids\n",
        "    # tokenized_inputs[\"c_prob\"] = prob_ids\n",
        "    # tokenized_inputs[\"s_e_idx\"] = start_end_ids\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sax47K6DF8r2"
      },
      "outputs": [],
      "source": [
        "tokenized_data_train = train_test_valid_dataset['train'].map(tokenize_and_align_labels,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0h3Izz56Cx8"
      },
      "outputs": [],
      "source": [
        "tokenized_data_test = train_test_valid_dataset['test'].map(tokenize_and_align_labels,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MdQWEd06EFN"
      },
      "outputs": [],
      "source": [
        "tokenized_data_val = train_test_valid_dataset['valid'].map(tokenize_and_align_labels,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Czxto9sy-j",
        "outputId": "e36e768b-655d-45d6-a1fc-11db06c24cf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'aligned_labels'],\n",
              "    num_rows: 4476\n",
              "})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sWgP_RujdpM"
      },
      "outputs": [],
      "source": [
        "# working with parsbert\n",
        "tensor_train_dataset = tokenized_data_train.with_format(\"torch\")\n",
        "tensor_test_dataset = tokenized_data_test.with_format(\"torch\")\n",
        "tensor_val_dataset = tokenized_data_val.with_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K1V0ghn-k_2"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict, concatenate_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzGc7HNl-ZHJ"
      },
      "outputs": [],
      "source": [
        "concatenated_dataset = concatenate_datasets([tensor_train_dataset, tensor_test_dataset, tensor_test_dataset])\n",
        "# concatenated_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_joA8mfkiShX",
        "outputId": "d31821e3-52b6-4b0c-9607-4666d8c3b11d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'attention_mask', 'aligned_labels'],\n",
              "    num_rows: 4974\n",
              "})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concatenated_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x85DBNaZzbW"
      },
      "source": [
        "**save and retain dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAe78t5FXG2o"
      },
      "outputs": [],
      "source": [
        "bert_path = '/content/drive/MyDrive/bert_tokenized_data'\n",
        "roberta_path = '/content/drive/MyDrive/roberta_tokenized_data'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OutV2Z75KkoP"
      },
      "outputs": [],
      "source": [
        "# load presaved_tokenized + embeddings dataset in tensor format\n",
        "\n",
        "ds_train = load_from_disk(bert_path + '/train')\n",
        "ds_test = load_from_disk(bert_path+ '/test' )\n",
        "ds_val = load_from_disk(bert_path + '/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKs60do1tSvD",
        "outputId": "cfe23742-9071-43a5-877a-1b1be9197868"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'start_end', 'label', 'complex_prob', 'input_ids', 'token_type_ids', 'attention_mask', 'aligned_labels'],\n",
              "    num_rows: 4476\n",
              "})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P-qzIG4DLeN"
      },
      "outputs": [],
      "source": [
        "# rename and remove ds\n",
        "ds_train = ds_train.remove_columns(\"label\")\n",
        "ds_train = ds_train.rename_column(\"aligned_labels\", \"labels\")\n",
        "\n",
        "ds_test = ds_test.remove_columns(\"label\")\n",
        "ds_test = ds_test.rename_column(\"aligned_labels\", \"labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db7OTkvech8T"
      },
      "outputs": [],
      "source": [
        "ds_train2 = ds_train.remove_columns(['id', 'tokens', 'start_end','complex_prob'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF3gytvNpfuh",
        "outputId": "94859fcf-4a38-41a3-8685-c566a2e1546a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 249\n",
              "})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_test2 = ds_test.remove_columns(['id', 'tokens', 'start_end','complex_prob'])\n",
        "ds_test2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AnvFLN99zG1",
        "outputId": "faa01514-5771-4aa5-ac26-ed7041e55504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ 0.50352224, 71.47746698])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calculate class weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "labels = ds_train2['labels']\n",
        "mask = (labels != -100)\n",
        "masked_labels = labels[mask]\n",
        "\n",
        "classes = np.unique(masked_labels)\n",
        "print(classes)\n",
        "weights = compute_class_weight(class_weight=\"balanced\", classes= classes, y= masked_labels.numpy())\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgjUqlfDVOzh"
      },
      "outputs": [],
      "source": [
        "model_checkpoint_R = 'FacebookAI/xlm-roberta-large-finetuned-conll03-english'\n",
        "model_checkpoint_B = 'HooshvareLab/bert-base-parsbert-ner-uncased'\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6QfRhmpLLkc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOuzlQPKPqyW"
      },
      "source": [
        "**finetune**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv2P366xQalX"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=llm_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmfDC6y7PtRG"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    ds_train2,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=30,\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    ds_test2, collate_fn=data_collator, batch_size=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQopx2T_Rt97"
      },
      "outputs": [],
      "source": [
        "id2label={0: 'non_complex', 1: 'complex'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm5JsN3tQrm-"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint_B,\n",
        "    num_labels=2,\n",
        "    ignore_mismatched_sizes=True,\n",
        "    id2label=id2label\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnb0VQcrSJ3D"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch import nn\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.68721065, 1.83539413]).to(device))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW0o0keASQwm"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5uc2D8qSbFy"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_train_epochs = 3\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "print(num_update_steps_per_epoch)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPBwI1-aSxZH"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import Repository, get_full_repo_name\n",
        "\n",
        "model_name = 'cwi_bert_base_ver2'\n",
        "repo_name = get_full_repo_name(model_name)\n",
        "repo_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6lFbMVzI4lc"
      },
      "outputs": [],
      "source": [
        "output_dir = \"/content/Untitled Folder\"\n",
        "repo = Repository(output_dir, clone_from=repo_name)\n",
        "repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyr1v1L2A6hZ"
      },
      "source": [
        "**Training** **loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLvnNMWQDJAI"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "clf_metrics = evaluate.combine([\"precision\", \"recall\"])\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "f1_metric = evaluate.load(\"f1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN2Fye23A8c8"
      },
      "outputs": [],
      "source": [
        "def postprocess(predictions, labels):\n",
        "\n",
        "    predictions = predictions.detach().cpu().clone().numpy()\n",
        "    labels = labels.detach().cpu().clone().numpy()\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "\n",
        "    true_predictions = [\n",
        "    [p for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "    true_labels = [\n",
        "        [l for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    return true_labels, true_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mm42sG2yKXE"
      },
      "outputs": [],
      "source": [
        "weights = torch.tensor([ 0.50352224, 71.47746698])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "09ab1cc782d346fbbd8a855732a9d266",
            "6821b50031db4bb18960aec9052d9a6e",
            "20f97e1a667148d09d1628feb6b09ee3",
            "0138d424483944248960e05b4bc2f3af",
            "7e5e553390c7466b9781a8ef37106afe",
            "4cc169c93b074decb88345e1fc6e5dc9",
            "b37c4f391155427f9ef41dd00497b9aa",
            "842e6f750bde4fd18e3167137f25283b",
            "60f3582a32574f7bb198f402f237f932",
            "b667a22973484594b2274780ae484cb5",
            "f9074bae330a4bcdbcd0bd4a99625609"
          ]
        },
        "id": "1ssIVeBsBut1",
        "outputId": "ddbbf562-9218-4762-cb26-742de7947080"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09ab1cc782d346fbbd8a855732a9d266",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/450 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0: {'precision ': 0.5892857142857143, 'recall': 0.0873015873015873, 'f1': 0.15207373271889402, 'accuracy': 0.964344540257727}\n",
            "epoch 1: {'precision ': 0.5535714285714286, 'recall': 0.09480122324159021, 'f1': 0.16187989556135768, 'accuracy': 0.9688983625617673}\n",
            "epoch 2: {'precision ': 0.44642857142857145, 'recall': 0.11961722488038277, 'f1': 0.18867924528301885, 'accuracy': 0.979168685204922}\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "avr_train_loss = []\n",
        "avr_test_loss = []\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    train_epoch_loss = 0\n",
        "    test_epoch_loss = 0\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "\n",
        "        labels = batch['labels']\n",
        "\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        # compute custom loss\n",
        "        loss_fct = nn.CrossEntropyLoss(ignore_index=-100, weight=weights.to(device))\n",
        "\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        # loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_epoch_loss += loss.item()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    avr_train_loss.append(train_epoch_loss/len(train_dataloader))\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        # calculate test loss\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.CrossEntropyLoss(ignore_index=-100, weight=weights.to(device))\n",
        "\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        test_epoch_loss += loss.item()\n",
        "        # test_epoch_loss  += outputs.loss.item()\n",
        "        # Necessary to pad predictions and labels for being gathered\n",
        "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
        "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
        "\n",
        "        predictions_gathered = accelerator.gather(predictions)\n",
        "        labels_gathered = accelerator.gather(labels)\n",
        "\n",
        "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
        "\n",
        "        for refs, preds in zip( true_labels , true_predictions):\n",
        "\n",
        "          clf_metrics.add_batch(predictions=preds, references=refs)\n",
        "          accuracy_metric.add_batch(predictions=preds, references=refs)\n",
        "          f1_metric.add_batch(predictions=preds, references=refs)\n",
        "\n",
        "    per_rec_results = clf_metrics.compute(zero_division=1)\n",
        "    f1_results = f1_metric.compute()\n",
        "    acc_recults = accuracy_metric.compute()\n",
        "\n",
        "    avr_test_loss.append(test_epoch_loss/len(eval_dataloader))\n",
        "\n",
        "    print(\n",
        "        f\"epoch {epoch}:\",\n",
        "        {\n",
        "            'precision ': per_rec_results['precision'],\n",
        "            'recall': per_rec_results['recall'],\n",
        "            'f1': f1_results['f1'],\n",
        "            'accuracy': acc_recults['accuracy']\n",
        "\n",
        "        },\n",
        "    )\n",
        "\n",
        "\n",
        "    # # Save and upload\n",
        "    # accelerator.wait_for_everyone()\n",
        "    # unwrapped_model = accelerator.unwrap_model(model)\n",
        "    # unwrapped_model.save_pretrained('cwi_vr3_roberta', save_function=accelerator.save)\n",
        "    # if accelerator.is_main_process:\n",
        "    #     tokenizer.save_pretrained('cwi_vr3_roberta')\n",
        "    #     repo.push_to_hub(\n",
        "    #         commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
        "    #     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0bXhaYqKCIa"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/cwi_bert_base_ver2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99ayW8oLUU3p"
      },
      "outputs": [],
      "source": [
        "!pip install safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b87xfKGR3C2"
      },
      "outputs": [],
      "source": [
        "finetuned_cwi = AutoModelForTokenClassification.from_pretrained('/content/drive/MyDrive/cwi_bert_base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-rvhMAd3pXF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curve(train_losses, val_losses):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "vki2qGbL-Nuf",
        "outputId": "3dd554d5-b483-4631-a173-68f5a452eaa4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss_curve(avr_train_loss, avr_test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohsa7OGO_Y2z"
      },
      "source": [
        "# retrive MLP and BiLSTM models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rS8SMOX_dnD"
      },
      "outputs": [],
      "source": [
        "BiLSTM_cwi = torch.load('/content/drive/MyDrive/bilstm_1.pth', map_location=torch.device('cpu'))\n",
        "MLP_cwi = torch.load('/content/drive/MyDrive/modified_MLP_cwi.pth', map_location=torch.device('cpu'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD1tCnOk-m-7"
      },
      "source": [
        "# Simplification:\n",
        "**Sub. Generation (SG)**\n",
        "1. mask predicted complex word\n",
        "2. concatenate masked sentence with original sentence + adding SEP and CLS tokens for roberta maske language model\n",
        "**Sub. Ranking**\n",
        "  3. remove suggestions with zipf value below 3\n",
        "  4. apply 4 critics for SR:\n",
        "    1. calculate zipf for each suggestions\n",
        "    2. rank base on Mask Model prediction order\n",
        "    3. calculate loss for each sequence containing target word\n",
        "    4. calculate cosine similarity base on FastText model\n",
        "    5. avrageing all rankings.\n",
        "    \n",
        "**Sub. Selection**\n",
        "5. choose the highest as the better suggestion and replace it with target word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUOlHFdfp3h8"
      },
      "outputs": [],
      "source": [
        "!pip install wordfreq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Uag98UvpN77"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, RobertaForMaskedLM\n",
        "import torch\n",
        "import copy\n",
        "from wordfreq import zipf_frequency\n",
        "from statistics import mean\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1uNtIuio6oF"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/LSBERT_resources/word2index.json', 'r') as json_file:\n",
        "    new_word2index = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlBYYVtyHMXJ"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\"\"\"\n",
        "this module aim to get word_label_dict (CWI phase) for finetuned CWI base on bert, the model is in classifier variable\n",
        "\n",
        "\"\"\"\n",
        "# classifier = pipeline(\"token-classification\", model=\"zahrainnlp/bert_base_cwi\")\n",
        "\n",
        "def get_word_label_dict(context, cwi_classifier):\n",
        "\n",
        "  # preprocessing:\n",
        "\n",
        "  hazm_normalizer = Normalizer()\n",
        "  hazm_w_tokenizer = WordTokenizer()\n",
        "  context = hazm_normalizer.normalize(context)\n",
        "  context = hazm_normalizer.correct_spacing(context)\n",
        "\n",
        "  result = cwi_classifier(context)\n",
        "  keys = []\n",
        "  values = []\n",
        "\n",
        "  for i in range(len(context.split())):\n",
        "    if result[i]['entity'] == 'non_complex' :\n",
        "      values.append(0)\n",
        "    else:\n",
        "      values.append(1)\n",
        "\n",
        "    keys.append(result[i]['word'])\n",
        "\n",
        "\n",
        "  result_dict = {word: value for word, value in zip(keys, values)}\n",
        "\n",
        "  return result_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPMaqdzqRXYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ebgCXHGPiv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "this module is for cwi models base on SVM and BRF. this module aim to get word label dictionary (cwi phase) from this models specificly\n",
        "\"\"\"\n",
        "\n",
        "normalizer = Normalizer()\n",
        "tokenizer = WordTokenizer()\n",
        "\n",
        "def get_word_label_dict(context, cwi_model, llm_model=R_model, llm_tokenizer=R_tokenizer):\n",
        "\n",
        "  # normalize\n",
        "  context = normalizer.normalize(context)\n",
        "  context = normalizer.correct_spacing(context)\n",
        "  # tokenize\n",
        "  tokens = tokenizer.tokenize(context)\n",
        "\n",
        "\n",
        "  tokenized_inputs = llm_tokenizer(tokens, is_split_into_words=True, add_special_tokens=True, return_tensors='pt').to(device)\n",
        "\n",
        "  llm_model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      hidden_states = llm_model(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'], output_hidden_states=True)['hidden_states']\n",
        "\n",
        "  token_embeddings = torch.stack(hidden_states[-4:], dim=0).squeeze(1).permute(1, 0, 2)\n",
        "  token_vecs_sum = torch.stack([torch.sum(token[-4:], dim=0) for token in token_embeddings])\n",
        "\n",
        "\n",
        "  # cwi Model Inference\n",
        "\n",
        "  input_embeddings = token_vecs_sum\n",
        "\n",
        "  predictions = cwi_model.predict(input_embeddings.cpu())\n",
        "\n",
        "\n",
        "\n",
        "  # turn binary tensor more readble:\n",
        "\n",
        "  tokenized_inputs_without_padding = llm_tokenizer(tokens, is_split_into_words=True, add_special_tokens=True,)\n",
        "  end_idx = (len(tokenized_inputs_without_padding['input_ids']) - 1 )\n",
        "  R_labels_list = predictions.tolist()[1:end_idx]\n",
        "  w_ids = tokenized_inputs_without_padding.word_ids()[1:end_idx]\n",
        "\n",
        "  d = {}\n",
        "  for l, id in zip(R_labels_list, w_ids):\n",
        "    # print(l)\n",
        "    # print(id)\n",
        "    value = tokens[id]\n",
        "    if value in d:\n",
        "      d[value].append(int(l))\n",
        "    else:\n",
        "      d[value] = [int(l)]\n",
        "\n",
        "  for k, v in d.items():\n",
        "    if len(v) > 1 and 1 in v:\n",
        "      d[k] = [1]\n",
        "    elif len(v) > 1 and 1 not in v:\n",
        "      d[k] = [0]\n",
        "\n",
        "  return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hhsr93TqMdh"
      },
      "outputs": [],
      "source": [
        "\"\"\"this module is for LSBERT_cwi, base on glove and BiLSTm\n",
        "\"\"\"\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, weights, hidden_size, num_layers, num_classes, dropout):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights, padding_idx= 0, freeze=True)\n",
        "        self.lstm = nn.LSTM(weights.size(1), hidden_size, num_layers, batch_first=True,\n",
        "                            bidirectional=True, dropout = dropout if num_layers > 1 else 0)\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        logits = self.dropout(self.fc(self.dropout(lstm_out)))\n",
        "\n",
        "        # out = self.fc(lstm_out)\n",
        "        return logits\n",
        "# this module is for LSBERT_cwi, base on glove and BiLSTm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgowX27Pwq9b"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpI15BslqFB7"
      },
      "outputs": [],
      "source": [
        "LSBERT_cwi = torch.load('/content/drive/MyDrive/LSBERT_resources/cwi_LSBERT_1.pth', map_location=device) #LSBERT, cwi base on glove embeddings and BiLSTM\n",
        "# zahra_CWI = torch.load('/content/drive/MyDrive/thesis_resources/bilstm_1.pth', map_location=device) #LSBERT, cwi base on bert embeddings, whole sentence, BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN1cA4BVkb_j"
      },
      "outputs": [],
      "source": [
        "\"\"\"for LSBERT, cwi base on glove embeddings and BiLSTM\"\"\"\n",
        "\n",
        "def get_word_label_dict_LSBERT(context, cwi_model, word2index):\n",
        "  \"\"\"\n",
        "  # for LSBERT, cwi base on glove embeddings and BiLSTM\n",
        "  \"\"\"\n",
        "  # preprocessing:\n",
        "\n",
        "  hazm_normalizer = Normalizer()\n",
        "  hazm_w_tokenizer = WordTokenizer()\n",
        "  context = hazm_normalizer.normalize(context)\n",
        "  context = hazm_normalizer.correct_spacing(context)\n",
        "  all_words = hazm_w_tokenizer.tokenize(context)\n",
        "\n",
        "  numericalized_tokens = [word2index[word] if word in word2index else word2index['-OOV-'] for word in all_words]\n",
        "\n",
        "  token_tensor = torch.LongTensor(numericalized_tokens)\n",
        "\n",
        "  token_tensor = token_tensor.unsqueeze(-1)  #add batch number dimention\n",
        "  token_tensor = token_tensor.to(device)\n",
        "  # get prediction\n",
        "\n",
        "  predictions = cwi_model(token_tensor)\n",
        "\n",
        "  top_predictions = predictions.argmax(-1)\n",
        "\n",
        "  # turn binary tensor more readble:\n",
        "\n",
        "  result = top_predictions.tolist()\n",
        "\n",
        "  result_dict = {word: value for word, value in zip(all_words, result)}\n",
        "\n",
        "  return result_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8NzyU_RiH4F"
      },
      "outputs": [],
      "source": [
        "\"\"\"for LSBERT, cwi base on glove embeddings and BiLSTM\"\"\"\n",
        "\n",
        "def get_word_label_dict_LSBERT(context, cwi_model, word2index):\n",
        "  \"\"\"\n",
        "  # for LSBERT, cwi base on glove embeddings and BiLSTM\n",
        "  \"\"\"\n",
        "  # preprocessing:\n",
        "\n",
        "  hazm_normalizer = Normalizer()\n",
        "  hazm_w_tokenizer = WordTokenizer()\n",
        "  context = hazm_normalizer.normalize(context)\n",
        "  context = hazm_normalizer.correct_spacing(context)\n",
        "  all_words = hazm_w_tokenizer.tokenize(context)\n",
        "\n",
        "  numericalized_tokens = [word2index[word] if word in word2index else word2index['-OOV-'] for word in all_words]\n",
        "\n",
        "  token_tensor = torch.LongTensor(numericalized_tokens)\n",
        "\n",
        "  token_tensor = token_tensor.unsqueeze(-1)  #add batch number dimention\n",
        "  token_tensor = token_tensor.to(device)\n",
        "  # get prediction\n",
        "\n",
        "  predictions = cwi_model(token_tensor)\n",
        "\n",
        "  top_predictions = predictions.argmax(-1)\n",
        "\n",
        "  # turn binary tensor more readble:\n",
        "\n",
        "  result = top_predictions.tolist()\n",
        "\n",
        "  result_dict = {word: value for word, value in zip(all_words, result)}\n",
        "\n",
        "  return result_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXxxXN9U1VQc"
      },
      "outputs": [],
      "source": [
        "\"\"\"this module is for zahra_CWI, base on bert embeddings and BiLSTm\n",
        "\"\"\"\n",
        "class BiLSTMTagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                        ):\n",
        "\n",
        "        super(BiLSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers = n_layers,\n",
        "                            bidirectional = bidirectional,\n",
        "                            dropout = dropout if n_layers > 1 else 0,\n",
        "                            batch_first =True,)\n",
        "\n",
        "        # self.batch_norm = nn.BatchNorm1d(2 * hidden_dim)\n",
        "\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(2*hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, embedded_text):\n",
        "\n",
        "        outputs, _ = self.lstm(embedded_text)\n",
        "\n",
        "        # outputs = self.batch_norm(outputs.permute(0, 2, 1))\n",
        "\n",
        "        # logits = self.dropout(self.fc(self.dropout(outputs.permute(0, 2, 1))))\n",
        "        logits = self.dropout(self.fc(self.dropout(outputs)))\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yisLvkqgCrog"
      },
      "outputs": [],
      "source": [
        "llm_model = AutoModelForTokenClassification.from_pretrained('HooshvareLab/bert-base-parsbert-armanner-uncased')\n",
        "llm_tokenizer =  AutoTokenizer.from_pretrained('HooshvareLab/bert-base-parsbert-armanner-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNo6ARRGRmLR"
      },
      "outputs": [],
      "source": [
        "llm_model = llm_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KtOFB8q2kUT"
      },
      "outputs": [],
      "source": [
        "\"\"\"# for cwi base on bert embeddings\n",
        "\"\"\"\n",
        "normalizer = Normalizer()\n",
        "tokenizer = WordTokenizer()\n",
        "\n",
        "def get_word_label_dict(context, cwi_model, llm_model, llm_tokenizer):\n",
        "  \"\"\"\n",
        "    # for cwi base on bert embeddings\n",
        "\n",
        "  \"\"\"\n",
        "  # preprocessing:\n",
        "\n",
        "  # normalize\n",
        "  context = normalizer.normalize(context)\n",
        "  context = normalizer.correct_spacing(context)\n",
        "  # tokenize\n",
        "  tokens = tokenizer.tokenize(context)\n",
        "  # extract LLM embeddings for each token\n",
        "  # getting input ids and attention mask and embedding\n",
        "  tokenized_inputs = llm_tokenizer(tokens, is_split_into_words=True, add_special_tokens=True, return_tensors='pt', padding= 'max_length', max_length=219,)\n",
        "  tokenized_inputs = tokenized_inputs.to(device)\n",
        "\n",
        "  llm_model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      hidden_states = llm_model(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'], output_hidden_states=True)['hidden_states']\n",
        "\n",
        "  token_embeddings = torch.stack(hidden_states[-4:], dim=0).squeeze(1).permute(1, 0, 2)\n",
        "  token_vecs_sum = torch.stack([torch.sum(token[-4:], dim=0) for token in token_embeddings])\n",
        "\n",
        "\n",
        "  # starting model to predict labels:\n",
        "\n",
        "  # cwi Model Inference\n",
        "  cwi_model.eval()\n",
        "  with torch.no_grad():\n",
        "      # # Reshape the input to match the expected size\n",
        "      input_embeddings = token_vecs_sum\n",
        "\n",
        "      logits = cwi_model(input_embeddings)\n",
        "\n",
        "      predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "  # Post-processing (example: thresholding at 0.5)\n",
        "  binary_predictions = (predictions >= 0.5).int()\n",
        "\n",
        "\n",
        "  # turn binary tensor more readble:\n",
        "\n",
        "  tokenized_inputs_without_padding = llm_tokenizer(tokens, is_split_into_words=True, add_special_tokens=True,)\n",
        "\n",
        "  end_idx = (len(tokenized_inputs_without_padding['input_ids']) - 1 )\n",
        "\n",
        "  R_labels_list = binary_predictions.squeeze(0).tolist()[1:end_idx]\n",
        "  w_ids = tokenized_inputs_without_padding.word_ids()[1:end_idx]\n",
        "\n",
        "  d = {}\n",
        "  for l, id in zip(R_labels_list, w_ids):\n",
        "    value = tokens[id]\n",
        "    if value in d:\n",
        "      d[value].append(int(l))\n",
        "    else:\n",
        "      d[value] = [int(l)]\n",
        "\n",
        "  for k, v in d.items():\n",
        "    if len(v) > 1 and 1 in v:\n",
        "      d[k] = [1]\n",
        "    elif len(v) > 1 and 1 not in v:\n",
        "      d[k] = [0]\n",
        "\n",
        "  return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEVdppP6qDHR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "mask_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "mask_model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cWjyubzk3CT"
      },
      "outputs": [],
      "source": [
        "mask_model.config.vocab_size = mask_tokenizer.vocab_size\n",
        "hazm_normalizer = Normalizer()\n",
        "\n",
        "\n",
        "def get_suggestions(context, word_label_dict, mask_tokenizer, mask_model, predictions_number):\n",
        "  word_subs_dic = {}\n",
        "  context = hazm_normalizer.normalize(context)\n",
        "  for v, k in word_label_dict.items():\n",
        "      # print(v, k)\n",
        "      if 1 in k:\n",
        "        target = v\n",
        "        masked_sent = context.replace(target, '<mask>')\n",
        "\n",
        "        mask_token = ' <mask>'\n",
        "        if mask_token in masked_sent:\n",
        "          masked_text = f'<s> {masked_sent} </s></s> {context} </s> '\n",
        "\n",
        "          encoded_input = mask_tokenizer(masked_text, padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
        "          output = mask_model(**encoded_input)\n",
        "          mask_token = ' <mask>'\n",
        "\n",
        "          mask_index = mask_tokenizer.tokenize(masked_text, padding=True, truncation=True, max_length=512,).index(mask_token) + 1\n",
        "\n",
        "          predictions = output[0][0][mask_index]\n",
        "          predicted_ids = torch.argsort(predictions, descending=True)[:predictions_number]\n",
        "          predicted_tokens = mask_tokenizer.convert_ids_to_tokens(list(predicted_ids))\n",
        "\n",
        "          word_subs_dic[v] = predicted_tokens\n",
        "\n",
        "        else:\n",
        "          word_subs_dic[v] = []\n",
        "\n",
        "      else:\n",
        "        word_subs_dic[v] = []\n",
        "\n",
        "  return word_subs_dic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RzzH2jflVpN"
      },
      "outputs": [],
      "source": [
        "#  step A: remove suggestion with zipf value less than 3\n",
        "\n",
        "\n",
        "def SR_stepA(word_suggestions_dict):\n",
        "    stop_words = stopwords_list()  # Assuming stopwords_list() is defined somewhere!\n",
        "\n",
        "    new_word_sug_dict = {}\n",
        "\n",
        "    for word, sug_list in word_suggestions_dict.items():\n",
        "        new_sug_list = []\n",
        "\n",
        "        if len(sug_list) != 0:\n",
        "            for suggestion in sug_list:\n",
        "                suggestion = re.sub('▁', '', suggestion)\n",
        "                if suggestion not in stop_words:\n",
        "                    suggestion_value = zipf_frequency(suggestion, 'fa')  # Assuming zipf_frequency is defined somewhere\n",
        "                    if suggestion_value > 3:\n",
        "                        new_sug_list.append(suggestion)\n",
        "\n",
        "        new_word_sug_dict[word] = new_sug_list if len(new_sug_list) != 0 else []\n",
        "\n",
        "    return new_word_sug_dict\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H3M_CqbldyG"
      },
      "outputs": [],
      "source": [
        "def SR_bert_score(modified_word_sug_dict):\n",
        "    word_order_score = {}\n",
        "    for word, sug_list in modified_word_sug_dict.items():\n",
        "        order_score = list(range(len(sug_list), 0, -1)) if sug_list else []\n",
        "        word_order_score[word] = list(zip(sug_list, order_score))\n",
        "\n",
        "    return word_order_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKSxf_orl3PO"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import fasttext\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_path = hf_hub_download(repo_id=\"facebook/fasttext-fa-vectors\", filename=\"model.bin\")\n",
        "FastText_model = fasttext.load_model(model_path)\n",
        "\n",
        "def cosine_similarity(word1, word2, model):\n",
        "\n",
        "    return np.dot(model[word1], model[word2]) / (np.linalg.norm(model[word1]) * np.linalg.norm(model[word2]))\n",
        "\n",
        "def SR_similarity_score (modified_word_sug_dict):\n",
        "\n",
        "  word_similarity_score = {}\n",
        "  for word, sug_list in  modified_word_sug_dict.items():\n",
        "    if len(sug_list) != 0 :\n",
        "      sug_list_score = []\n",
        "      for suggestion in sug_list:\n",
        "        cosine_similarity_score = cosine_similarity(word, suggestion, FastText_model)\n",
        "        sug_list_score.append(round(cosine_similarity_score, 2))\n",
        "\n",
        "      word_similarity_score[word] = list(zip(sug_list, sug_list_score))\n",
        "\n",
        "    else:\n",
        "      word_similarity_score[word] = []\n",
        "\n",
        "\n",
        "  # del FastText_model\n",
        "  gc.collect()\n",
        "  return word_similarity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP99_E-rll9D"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, RobertaForMaskedLM\n",
        "import torch\n",
        "import copy\n",
        "\n",
        "# worked:\n",
        "def get_MLM_loss(mask_model, mask_tokenizer, masked_sent, sent):\n",
        "    # Tokenize sentences\n",
        "    inputs = mask_tokenizer(masked_sent, sent, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "    labels = inputs.input_ids.clone()  # Clone the input_ids tensor\n",
        "    # Mask labels of non-<mask> tokens\n",
        "    labels[labels != mask_tokenizer.mask_token_id] = -100\n",
        "    outputs = mask_model(**inputs, labels=labels)\n",
        "\n",
        "    return round(outputs.loss.item(), 2)\n",
        "\n",
        "def get_surrounding_indices(index, length):\n",
        "  left_index = index - 5 if index > 4 else 0\n",
        "  right_index = index + 5 if length - 1 - index > 4 else length - 1\n",
        "  if index - left_index < 5:\n",
        "    right_index += 5 - (index - left_index)\n",
        "  if right_index - index < 5:\n",
        "    left_index -= 5 - (right_index - index)\n",
        "  return (left_index, right_index + 1)\n",
        "\n",
        "def SR_loss_score(modified_word_sug_dict, mask_model, mask_tokenizer):\n",
        "\n",
        "  word_loss_score = {}\n",
        "  for word, sug_list in  modified_word_sug_dict.items():\n",
        "    if len(sug_list) != 0 :\n",
        "      sug_list_score = []\n",
        "\n",
        "      for suggestion in sug_list:\n",
        "        original_sent = ' '.join(list(modified_word_sug_dict.keys()))\n",
        "\n",
        "        W = re.sub(word, suggestion, original_sent)\n",
        "        W_list = W.split()\n",
        "        W_loss_scores = []\n",
        "        target_token_index = W_list.index(suggestion)\n",
        "        W_length = len(W_list)\n",
        "        if W_length > 10:\n",
        "          (minus_fifth_index, plus_fifth_index) = get_surrounding_indices(target_token_index, W_length)\n",
        "          W = W[minus_fifth_index : plus_fifth_index]\n",
        "\n",
        "        for i in range(W_length):\n",
        "          masked_token = W_list[i]\n",
        "          masked_sent = W.replace(masked_token, '<mask>')\n",
        "          loss_score = get_MLM_loss(mask_model, mask_tokenizer, masked_sent, W)\n",
        "          W_loss_scores.append(loss_score)\n",
        "\n",
        "        suggestion_score = mean(W_loss_scores)\n",
        "        sug_list_score.append(round(suggestion_score, 2))\n",
        "\n",
        "      word_loss_score[word] = list(zip(sug_list, sug_list_score))\n",
        "\n",
        "    else:\n",
        "      word_loss_score[word] = []\n",
        "\n",
        "  return word_loss_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wjxw84Fll9xn"
      },
      "outputs": [],
      "source": [
        "def SR_zipf_score (modified_word_sug_dict):\n",
        "  word_zipf_score = {}\n",
        "  for word, sug_list in  modified_word_sug_dict.items():\n",
        "    if len(sug_list) != 0 :\n",
        "      zipf_value = []\n",
        "      for suggestion in sug_list:\n",
        "        zipf_value.append(zipf_frequency(suggestion, 'fa'))\n",
        "\n",
        "      ranked_list = [sorted(zipf_value).index(x) + 1 for x in zipf_value]\n",
        "\n",
        "      word_zipf_score[word] = list(zip(sug_list, ranked_list))\n",
        "\n",
        "    else:\n",
        "      word_zipf_score[word] = []\n",
        "\n",
        "  return word_zipf_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2WCcw7oaF46"
      },
      "outputs": [],
      "source": [
        "def get_ranking(input_dict):\n",
        "  result = {}\n",
        "  for word, subs_list in input_dict.items():\n",
        "    if len(subs_list) != 0:\n",
        "      sorted_subs_list = sorted(subs_list, key=lambda x: x[1], reverse=True)\n",
        "      n = len(subs_list)\n",
        "      ranked_subs_list = [(t[0], n - i) for i, t in enumerate(sorted_subs_list)]\n",
        "\n",
        "      result[word] = ranked_subs_list\n",
        "    else:\n",
        "      result[word] = []\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def get_loss_ranking(loss_score_dict):\n",
        "  result = {}\n",
        "  for word, subs_list in loss_score_dict.items():\n",
        "    if len(subs_list) != 0:\n",
        "      sorted_subs_list = sorted(subs_list, key=lambda x: (x[1], subs_list.index(x)))\n",
        "      n = len(subs_list)\n",
        "      ranked_subs_list = [(t[0], n - i) for i, t in enumerate(sorted_subs_list)]\n",
        "\n",
        "      result[word] = ranked_subs_list\n",
        "    else:\n",
        "      result[word] = []\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6cDn9xlCRgB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_tuple_by_name(arr, name):\n",
        "  for tup in arr:\n",
        "    if tup[0] == name:\n",
        "      return tup\n",
        "\n",
        "def merge_values(temp_list, value):\n",
        "  arr = []\n",
        "  for tup in value:\n",
        "    temp_tup = get_tuple_by_name(temp_list, tup[0])\n",
        "    arr.append((tup[0], (tup[1] + temp_tup[1])/ 2))\n",
        "  return arr\n",
        "\n",
        "def round_tuples(temp):\n",
        "  final_result = {}\n",
        "  for var in temp:\n",
        "    final_result[var] = []\n",
        "    if len(temp[var]) > 0:\n",
        "      for tup in temp[var]:\n",
        "        value = (tup[0], round(tup[1], 2))\n",
        "        final_result[var].append(value)\n",
        "  return final_result\n",
        "\n",
        "def get_final_score(*args):\n",
        "  temp = {}\n",
        "  for dic in args:\n",
        "    for var in dic:\n",
        "      temp_list = temp.get(var, [])\n",
        "      current_list = dic[var]\n",
        "      if len(current_list) > 0 and len(temp_list) > 0:\n",
        "        current_list = merge_values(temp_list, current_list)\n",
        "      temp[var] = current_list\n",
        "  temp = round_tuples(temp)\n",
        "\n",
        "  return temp\n",
        "\n",
        "\n",
        "def get_highest_score(arr, word):\n",
        "  highest = 0\n",
        "  highest_tup = None\n",
        "  for tup in arr:\n",
        "    if tup[1] > highest and tup[0] != word:\n",
        "      highest = tup[1]\n",
        "      highest_tup = tup\n",
        "  return highest_tup\n",
        "\n",
        "def get_highest_score_in_dic(dic):\n",
        "  temp = {}\n",
        "  for var in dic:\n",
        "    x = get_highest_score(dic[var], var)\n",
        "    temp[var] = x\n",
        "  return temp\n",
        "\n",
        "def get_final_string(dic):\n",
        "  x = get_highest_score_in_dic(dic)\n",
        "  sentence = ''\n",
        "  for var in x:\n",
        "    sentence += ' '\n",
        "    if x[var] != None:\n",
        "      sentence +=  x[var][0]\n",
        "    else:\n",
        "      sentence += var\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMfPCUwuVR-i"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# for cwi base on glove embeddings\n",
        "def simplification_alg_LSBERT(row, mask_tokenizer=mask_tokenizer, mask_model=mask_model, cwi_model=LSBERT_cwi, suggestions_count=10, stop_words = stopwords_list(), word2index=new_word2index):\n",
        "  first_start = time.time()\n",
        "  print(row.name)\n",
        "  text = row['sentence']\n",
        "  # text = context\n",
        "\n",
        "  \"\"\" step1: prepare word_label_dict word as key and binary label as value (CWI)\"\"\"\n",
        "  cwi_dict = get_word_label_dict_LSBERT(text, cwi_model, word2index)\n",
        "  # print(cwi_dict)\n",
        "  \"\"\" step2: prepare suggestions as a dictionary. key: word value: list of suggestions (SG)\"\"\"\n",
        "  # first_start = time.time()\n",
        "  word_suggestions_dict = get_suggestions(text, cwi_dict, mask_tokenizer, mask_model, suggestions_count)\n",
        "  # print(word_suggestions_dict)\n",
        "\n",
        "  \"\"\" step3: Substitudes Ranking\"\"\"\n",
        "  \"\"\"  step A: remove suggestion with zipf value less than 3 \"\"\"\n",
        "\n",
        "  modified_word_suggestion_dict = SR_stepA(word_suggestions_dict)\n",
        "  # print(modified_word_suggestion_dict)\n",
        "  \"\"\"  step B: calculate 4 criteria to score each substitude for each complex word \"\"\"\n",
        "  \"\"\"  B-1: BERT prediction order criteria \"\"\"\n",
        "\n",
        "  # BERT_score_dict = SR_bert_score(modified_word_suggestion_dict)\n",
        "  # # print(BERT_score_dict)\n",
        "  \"\"\"  B-2: mask model loss criteria \"\"\"\n",
        "\n",
        "  loss_score_dict = SR_loss_score(modified_word_suggestion_dict, mask_model, mask_tokenizer)\n",
        "  loss_score_dict = get_loss_ranking(loss_score_dict)\n",
        "  # print(loss_score_dict)\n",
        "  \"\"\"  B-3: cosine similarity between target word and sub word criteria \"\"\"\n",
        "\n",
        "  # similarity_score_dict = SR_similarity_score(modified_word_suggestion_dict)\n",
        "  # similarity_score_dict = get_ranking(similarity_score_dict)\n",
        "  # print(similarity_score_dict)\n",
        "  \"\"\"  B-4: zipf value criteria \"\"\"\n",
        "\n",
        "  # zipf_score_dict = SR_zipf_score(modified_word_suggestion_dict)\n",
        "  # # print(zipf_score_dict)\n",
        "  \"\"\"  step C: calculate all criterias for each \"\"\"\n",
        "\n",
        "  final_score = get_final_score(loss_score_dict)#loss_score_dict, similarity_score_dict, zipf_score_dict, BERT_score_dict,\n",
        "  # print(final_score)\n",
        "  \"\"\"  SS, select best and return string \"\"\"\n",
        "\n",
        "  final_string = get_final_string(final_score)\n",
        "  # first_end = time.time()\n",
        "  # print(first_end - first_start)\n",
        "  return final_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QupNRtWj_y81"
      },
      "outputs": [],
      "source": [
        "# # # for cwi base on bert embeddings\n",
        "\n",
        "import time\n",
        "\n",
        "def simplification_alg(row, mask_tokenizer=mask_tokenizer, mask_model=mask_model, cwi_model=zahra_CWI, llm_model=llm_model, llm_tokenizer=llm_tokenizer, suggestions_count=10, stop_words = stopwords_list(),):\n",
        "  # ll_model and llm_tokenizer are bert models thatwere initialy used to make cwi base on bert embeddings\n",
        "  # first_start = time.time()\n",
        "  print(row.name)\n",
        "  text = row['sentence']\n",
        "\n",
        "  \"\"\" step1: prepare word_label_dict word as key and binary label as value (CWI)\"\"\"\n",
        "  cwi_dict = get_word_label_dict(text, cwi_model, llm_model, llm_tokenizer)\n",
        "\n",
        "  \"\"\" step2: prepare suggestions as a dictionary. key: word value: list of suggestions (SG)\"\"\"\n",
        "  # first_start = time.time()\n",
        "  word_suggestions_dict = get_suggestions(text, cwi_dict, mask_tokenizer, mask_model, suggestions_count)\n",
        "\n",
        "\n",
        "  \"\"\" step3: Substitudes Ranking\"\"\"\n",
        "  \"\"\"  step A: remove suggestion with zipf value less than 3 \"\"\"\n",
        "\n",
        "  modified_word_suggestion_dict = SR_stepA(word_suggestions_dict)\n",
        "\n",
        "  \"\"\"  step B: calculate 4 criteria to score each substitude for each complex word \"\"\"\n",
        "  \"\"\"  B-1: BERT prediction order criteria \"\"\"\n",
        "\n",
        "  # BERT_score_dict = SR_bert_score(modified_word_suggestion_dict)\n",
        "\n",
        "  \"\"\"  B-2: mask model loss criteria \"\"\"\n",
        "\n",
        "  loss_score_dict = SR_loss_score(modified_word_suggestion_dict, mask_model, mask_tokenizer)\n",
        "  loss_score_dict = get_loss_ranking(loss_score_dict)\n",
        "\n",
        "  \"\"\"  B-3: cosine similarity between target word and sub word criteria \"\"\"\n",
        "\n",
        "  # similarity_score_dict = SR_similarity_score(modified_word_suggestion_dict)\n",
        "  # similarity_score_dict = get_ranking(similarity_score_dict)\n",
        "  \"\"\"  B-4: zipf value criteria \"\"\"\n",
        "\n",
        "  # zipf_score_dict = SR_zipf_score(modified_word_suggestion_dict)\n",
        "\n",
        "  \"\"\"  step C: calculate all criterias for each \"\"\"\n",
        "\n",
        "  final_score = get_final_score(loss_score_dict)#loss_score_dict, similarity_score_dict, zipf_score_dict, BERT_score_dict,\n",
        "\n",
        "  \"\"\"  SS, select best and return string \"\"\"\n",
        "\n",
        "  final_string = get_final_string(final_score)\n",
        "  # first_end = time.time()\n",
        "  # print(first_end - first_start)\n",
        "  return final_string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrBLpQSdTj4W"
      },
      "outputs": [],
      "source": [
        "samples_df = pd.read_csv('/content/drive/MyDrive/LSBERT_resources/evaluation_samples_500_modified.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2mBRjwXDDaLH"
      },
      "outputs": [],
      "source": [
        "samples_df['model_simplified'] = samples_df.apply(simplification_alg_LSBERT,\n",
        "                                                   axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpr0fJxiAnK4"
      },
      "source": [
        "# calculate SARI and BLEU to evaluate simplification process for each model output base on 492 extractes phrases for this evaluation purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VH69Y9tPsORk",
        "outputId": "ecbd7895-3ca4-497a-ffde-bbd0a2d8b6d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"eval_df\",\n  \"rows\": 491,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627\",\n          \"\\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646\",\n          \"\\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0627\\u0632 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u06cc\\u06a9 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u0648\\u0628\\u0631 \\u062f\\u0631 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u06a9\\u0631\\u062f\\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0645\\u0648\\u0642\\u062a\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 \\u06a9\\u0631\\u062f.\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647 \\u0628\\u0627\\u0634\\u062f \\u0648 \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u06cc\\u0627 \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f.\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u062f\\u0631 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0628\\u0647 \\u062b\\u0628\\u062a \\u0631\\u0633\\u06cc\\u062f\\u0647 \\u0627\\u0633\\u062a \\u0648 \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647\\u060c \\u0634\\u0631\\u06a9\\u062a \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0648 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0628\\u0647 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc\\u060c \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0648 \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0648 \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0648 \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ref_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0627\\u0632 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u06cc\\u06a9 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u0648\\u0628\\u0631 \\u062f\\u0631 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u06a9\\u0631\\u062f\\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0645\\u0648\\u0642\\u062a\\u0627 \\u0645\\u062a\\u0648\\u0642\\u0641 \\u06a9\\u0631\\u062f.\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647 \\u0628\\u0627\\u0634\\u062f \\u0648 \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u062c\\u0644\\u0648\\u06af\\u06cc\\u0631\\u06cc \\u06cc\\u0627 \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f.\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u062f\\u0631 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0628\\u0647 \\u062b\\u0628\\u062a \\u0631\\u0633\\u06cc\\u062f\\u0647 \\u0627\\u0633\\u062a \\u0648 \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647\\u060c \\u0634\\u0631\\u06a9\\u062a \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0648 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0628\\u0647 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc\\u060c \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0648 \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0648 \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0648 \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0634\\u0631\\u0648\\u0639 \\u06a9\\u0631\\u062f.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ref_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 490,\n        \"samples\": [\n          \"\\u0627\\u0648 \\u062f\\u0631 \\u0627\\u0633\\u062a\\u0639\\u0641\\u0627\\u0646\\u0627\\u0645\\u0647 \\u062e\\u0648\\u062f \\u0622\\u0648\\u0631\\u062f\\u0647\\u200c\\u0627\\u0633\\u062a \\u06a9\\u0647 \\u06af\\u0648\\u06cc\\u0627 \\u0628\\u0631\\u062e\\u06cc \\u0627\\u0632 \\u0627\\u0639\\u0636\\u0627\\u06cc \\u062d\\u0648\\u0632\\u0647 \\u06cc\\u0648\\u0631\\u0648 \\u0648 \\u0634\\u0631\\u06a9\\u0627\\u06cc \\u06af\\u0648\\u0646\\u0627\\u06af\\u0648\\u0646 \\u062a\\u0631\\u062c\\u06cc\\u062d\\u0634\\u0627\\u0646 \\u0628\\u0631 \\u0639\\u062f\\u0645 \\u062d\\u0636\\u0648\\u0631 \\u0645\\u0646 \\u062f\\u0631 \\u0646\\u0634\\u0633\\u062a\\u200c\\u0647\\u0627\\u0633\\u062a\\u060c \\u0627\\u06cc\\u062f\\u0647\\u200c\\u0627\\u06cc \\u06a9\\u0647 \\u0646\\u062e\\u0633\\u062a\\u200c\\u0648\\u0632\\u06cc\\u0631 \\u06cc\\u0648\\u0646\\u0627\\u0646 \\u0631\\u0627 \\u0628\\u0647 \\u0627\\u06cc\\u0646 \\u0628\\u0627\\u0648\\u0631 \\u0631\\u0633\\u0627\\u0646\\u062f\\u0647\\u200c\\u0627\\u0633\\u062a \\u06a9\\u0647 \\u0639\\u062f\\u0645 \\u062d\\u0636\\u0648\\u0631 \\u0645\\u0646 \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0631\\u0627\\u06cc \\u062f\\u0633\\u062a\\u06cc\\u0627\\u0628\\u06cc \\u0628\\u0647 \\u06cc\\u06a9 \\u062a\\u0648\\u0627\\u0641\\u0642 \\u0645\\u0641\\u06cc\\u062f \\u0628\\u0627\\u0634\\u062f.\",\n          \"\\u062f\\u0631 \\u0648\\u0627\\u0642\\u0639 \\u0639\\u0627\\u06cc\\u0642 \\u06a9\\u0627\\u0645\\u0644 \\u0648\\u062c\\u0648\\u062f \\u0646\\u062f\\u0627\\u0631\\u062f\\u060c \\u0628\\u0646\\u0627\\u0628\\u0631\\u0627\\u06cc\\u0646 \\u0645\\u0648\\u0627\\u062f \\u062f\\u06cc\\u200c\\u0627\\u0644\\u06a9\\u062a\\u0631\\u06cc\\u06a9 \\u0628\\u0627 \\u062b\\u0627\\u0628\\u062a \\u062f\\u06cc\\u200c\\u0627\\u0644\\u06a9\\u062a\\u0631\\u06cc\\u06a9 \\u0628\\u0627\\u0644\\u0627 \\u0631\\u0627 \\u0639\\u0627\\u06cc\\u0642 \\u0627\\u0644\\u06a9\\u062a\\u0631\\u06cc\\u06a9\\u06cc \\u0645\\u06cc\\u200c\\u0646\\u0627\\u0645\\u0646\\u062f.\",\n          \"\\u062e\\u0628\\u0631\\u0647\\u0627\\u06cc \\u0645\\u0631\\u0632\\u0646\\u0634\\u06cc\\u0646 \\u062e\\u0631\\u0627\\u0633\\u0627\\u0646 \\u0634\\u0645\\u0627\\u0644\\u06cc \\u0646\\u0645\\u0627\\u06cc\\u0634\\u06af\\u0627\\u0647\\u06cc \\u06a9\\u0647 \\u0647\\u0645\\u0647 \\u0627\\u06cc\\u0631\\u0627\\u0646\\u06cc\\u200c\\u0647\\u0627 \\u062f\\u0639\\u0648\\u062a \\u0647\\u0633\\u062a\\u0646\\u062f \\u062a\\u0633\\u0646\\u06cc\\u0645 \\u062f\\u06cc\\u0631\\u0648\\u0632 \\u0628\\u0647\\u200c\\u06af\\u0632\\u0627\\u0631\\u0634 \\u06af\\u0631\\u0648\\u0647 \\u0627\\u062c\\u062a\\u0645\\u0627\\u0639\\u06cc \\u062e\\u0628\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u062a\\u0633\\u0646\\u06cc\\u0645\\u060c \\u0628\\u0647\\u0645\\u0646 \\u0646\\u0627\\u0645\\u0648\\u0631\\u200c\\u0645\\u0637\\u0644\\u0642 \\u062f\\u0631 \\u0646\\u0634\\u0633\\u062a \\u062e\\u0628\\u0631\\u06cc \\u0628\\u06cc\\u0633\\u062a\\u200c\\u0648\\u200c\\u0647\\u0634\\u062a\\u0645\\u06cc\\u0646 \\u0646\\u0645\\u0627\\u06cc\\u0634\\u06af\\u0627\\u0647 \\u0645\\u0644\\u06cc \\u0635\\u0646\\u0627\\u06cc\\u0639\\u200c\\u062f\\u0633\\u062a\\u06cc\\u060c \\u0628\\u0627 \\u0628\\u06cc\\u0627\\u0646 \\u0627\\u06cc\\u0646 \\u0645\\u0637\\u0644\\u0628\\u060c \\u0627\\u0639\\u0644\\u0627\\u0645 \\u062f\\u0627\\u0634\\u062a: \\u062f\\u0631 \\u0633\\u0627\\u0644\\u200c\\u0647\\u0627\\u06cc \\u06af\\u0630\\u0634\\u062a\\u0647 \\u0634\\u0627\\u0647\\u062f \\u062c\\u0631\\u06cc\\u0627\\u0646 \\u0631\\u0648\\u0628\\u0647\\u200c\\u0631\\u0634\\u062f \\u0648\\u0636\\u0639\\u06cc\\u062a \\u0646\\u0645\\u0627\\u06cc\\u0634\\u06af\\u0627\\u0647\\u200c\\u0647\\u0627 \\u0628\\u0648\\u062f\\u0647\\u200c\\u0627\\u06cc\\u0645 \\u0648 \\u062c\\u0631\\u06cc\\u0627\\u0646 \\u0628\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0646\\u0645\\u0627\\u06cc\\u0634\\u06af\\u0627\\u0647\\u200c\\u0647\\u0627 \\u062f\\u0631\\u062d\\u0627\\u0644 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0627\\u0633\\u062a \\u0648 \\u062e\\u0648\\u0634\\u0628\\u062e\\u062a\\u0627\\u0646\\u0647  \\u0628\\u06cc\\u0633\\u062a\\u200c\\u0648\\u200c\\u0647\\u0634\\u062a\\u0645\\u06cc\\u0646 \\u0646\\u0645\\u0627\\u06cc\\u0634\\u06af\\u0627\\u0647 \\u0645\\u0644\\u06cc \\u0635\\u0646\\u0627\\u06cc\\u0639\\u200c\\u062f\\u0633\\u062a\\u06cc\\u060c \\u0647\\u0631 \\u0631\\u0648\\u0632 \\u0645\\u06cc\\u0632\\u0628\\u0627\\u0646 \\u0633\\u0647 \\u0631\\u0648\\u06cc\\u062f\\u0627\\u062f \\u0648\\u06cc\\u0698\\u0647 \\u0622\\u0646\\u0627 \\u062f\\u06cc\\u0631\\u0648\\u0632 \\u0645\\u0639\\u0627\\u0648\\u0646 \\u0635\\u0646\\u0627\\u06cc\\u0639\\u200c\\u062f\\u0633\\u062a\\u06cc \\u06a9\\u0634\\u0648\\u0631\\u060c \\u0628\\u0627 \\u0628\\u06cc\\u0627\\u0646 \\u0627\\u06cc\\u0646\\u06a9\\u0647 \\u0628\\u06cc\\u0633\\u062a\\u200c\\u0648\\u200c\\u0647\\u0634\\u062a\\u0645\\u06cc\\u0646 \\u0646\\u0645\\u0627\\u06cc\\u0634\\u06af\\u0627\\u0647 \\u0645\\u0644\\u06cc \\u0635\\u0646\\u0627\\u06cc\\u0639\\u200c\\u062f\\u0633\\u062a\\u06cc \\u06f1 \\u062a\\u0627 \\u06f7 \\u0634\\u0647\\u0631\\u06cc\\u0648\\u0631 \\u062f\\u0631 \\u062a\\u0647\\u0631\\u0627\\u0646 \\u0628\\u0631\\u06af\\u0632\\u0627\\u0631 \\u0645\\u06cc\\u200c\\u0634\\u0648\\u062f\\u060c \\u06af\\u0641\\u062a: \\u0646\\u0645\\u0627\\u06cc\\u0634\\u06af\\u0627\\u0647\\u200c\\u0647\\u0627 \\u062f\\u0631 \\u062d\\u0642\\u06cc\\u0642\\u062a \\u0645\\u0639\\u062f\\u0644\\u200c\\u06af\\u06cc\\u0631\\u06cc \\u0635\\u0646\\u0627\\u06cc\\u0639\\u200c\\u062f\\u0633\\u062a\\u06cc \\u0627\\u0633\\u062a\\u061b \\u0686\\u0631\\u0627\\u06a9\\u0647 \\u062f\\u0631 \\u0627\\u06cc\\u0646 \\u0646\\u0645\\u0627\\u06cc\\u0634\\u06af\\u0627\\u0647 \\u062c\\u062f\\u06cc\\u062f\\u200c\\u062a\\u0631\\u06cc\\u0646 \\u0645\\u062d\\u0635\\u0648\\u0644\\u0627\\u062a \\u0627\\u0631\\u0627\\u0626\\u0647 \\u0645\\u06cc\\u200c\\u0634\\u0648\\u062f.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LSBERT_simpl\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u0648\\u0642\\u062a\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ziph_simpl\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0648\\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0627\\u0646 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0641\\u0639\\u0644\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc \\u0645\\u0634\\u06a9\\u0644 \\u062e\\u0627\\u0635\\u06cc \\u0627\\u0633\\u062a\\u0641\\u0627\\u062f\\u0647 \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0645\\u0633\\u0627\\u0626\\u0644 \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u06a9\\u0646\\u062a\\u0631\\u0644 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u0647\\u0627\\u06cc \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0633\\u0627\\u0644 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0634\\u0631\\u06a9\\u062a \\u0647\\u0627 \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u062e\\u0648\\u0627\\u0647\\u062f \\u0628\\u0627 \\u06af\\u0631\\u0641\\u062a\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0628\\u0627\\u0632\\u0627\\u0631 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0641\\u0631\\u0648\\u0634 \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity_simpl\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0648\\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u06af\\u0630\\u0634\\u062a \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u062c\\u062f\\u062f\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u064a\\u0627 \\u0628\\u064a\\u0645\\u0627\\u0631\\u064a \\u062e\\u0627\\u0635\\u06cc \\u06af\\u0641\\u062a\\u06af\\u0648 \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0634\\u06cc\\u0648\\u0647 \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646\\u06cc \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u06af\\u0633\\u062a\\u0631\\u0634 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0635\\u0641\\u062d\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0628\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u0643\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632 \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0633\\u0647\\u0627\\u0645 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0627\\u062a \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BERT_simpl\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0648\\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0627\\u0646 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u0648\\u0642\\u062a \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u064a\\u0627 \\u0628\\u064a\\u0645\\u0627\\u0631\\u064a \\u062e\\u0627\\u0635\\u06cc \\u0628\\u062d\\u062b \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0637\\u0631\\u0642 \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646\\u06cc \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u06af\\u0633\\u062a\\u0631\\u0634 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u06a9\\u062f \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0645\\u06cc\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u0627\\u062e\\u0630 \\u0645\\u062c\\u0648\\u0632 \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0627\\u062c\\u0627\\u0631\\u0647 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647 \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss_simpl\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u0648\\u0642\\u062a\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z_LSBERT_all\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u0648\\u0642\\u062a\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z_LSBERT_zipf\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u0648\\u0642\\u062a\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z_LSBERT_sim\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u0648\\u0642\\u062a\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z_LSBERT_bert\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u0648\\u0642\\u062a\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z_LSBERT_loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 491,\n        \"samples\": [\n          \"\\u0622\\u0631\\u0634\\u06cc\\u0648 \\u0627\\u0648\\u0628\\u0631 \\u0628\\u0639\\u062f \\u0627\\u0632 \\u06cc\\u06a9 \\u062a\\u0635\\u0627\\u062f\\u0641 \\u062f\\u0631 \\u0622\\u0631\\u06cc\\u0632\\u0648\\u0646\\u0627 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0631\\u0627 \\u0641\\u0631\\u0627\\u062e\\u0648\\u0627\\u0646\\u062f \\u0639\\u0635\\u0631 \\u062e\\u0648\\u062f\\u0631\\u0648 \\u067e\\u0633 \\u0622\\u0646\\u200c\\u06a9\\u0647 \\u062e\\u0648\\u062f\\u0631\\u0627\\u0646 \\u0627\\u06cc\\u0627\\u0644\\u062a \\u06a9\\u0631\\u062f \\u060c \\u0627\\u06cc\\u0646 \\u0634\\u0631\\u06a9\\u062a \\u062a\\u0627\\u06a9\\u0633\\u06cc\\u0631\\u0627\\u0646\\u06cc \\u062a\\u0631\\u062f\\u062f \\u0645\\u0648\\u0642\\u062a\\u0627 \\u062a\\u0639\\u0644\\u06cc\\u0642 .\",\n          \"\\u062e\\u06cc\\u0644\\u06cc \\u06a9\\u0645 \\u067e\\u06cc\\u0634 \\u0645\\u06cc\\u200c\\u0622\\u06cc\\u062f \\u062f\\u0631 \\u0645\\u0648\\u0631\\u062f \\u0645\\u0633\\u0626\\u0644\\u0647 \\u06cc\\u0627 \\u0628\\u06cc\\u0645\\u0627\\u0631\\u06cc \\u062e\\u0627\\u0635\\u06cc \\u0635\\u062d\\u0628\\u062a \\u06a9\\u0646\\u06cc\\u0645 \\u0648 \\u0627\\u06cc\\u0646 \\u062f\\u0648\\u0633\\u062a\\u0645\\u0627\\u0646 \\u0622\\u0646 \\u0627\\u0637\\u0644\\u0627\\u0639\\u0627\\u062a \\u0646\\u062f\\u0627\\u0634\\u062a\\u0647_\\u0628\\u0627\\u0634\\u062f \\u0631\\u0648\\u0634\\u200c\\u0647\\u0627\\u06cc \\u067e\\u06cc\\u0634\\u06af\\u06cc\\u0631\\u06cc \\u062f\\u0631\\u0645\\u0627\\u0646 \\u0631\\u0627 \\u0646\\u062f\\u0627\\u0646\\u062f .\",\n          \"\\u0634\\u0631\\u06a9\\u062a \\u06a9\\u0627\\u0631\\u06af\\u0632\\u0627\\u0631\\u06cc \\u0628\\u0627\\u0646\\u06a9 \\u062a\\u0648\\u0633\\u0639\\u0647 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u062f\\u0631 \\u0633\\u0627\\u0644 \\u06f1\\u06f3\\u06f7\\u06f6 \\u0648 \\u0628\\u0647 \\u0634\\u0645\\u0627\\u0631\\u0647 \\u062b\\u0628\\u062a \\u06f1\\u06f3\\u06f2\\u06f3\\u06f9\\u06f9 \\u0627\\u062f\\u0627\\u0631\\u0647 \\u0634\\u0631\\u06a9\\u062a\\u0647\\u0627 \\u0631\\u0633\\u06cc\\u062f\\u0647_\\u0627\\u0633\\u062a \\u0628\\u0631 \\u0627\\u0633\\u0627\\u0633 \\u0627\\u0633\\u0627\\u0633\\u0646\\u0627\\u0645\\u0647 \\u060c \\u0645\\u06cc\\u200c\\u062a\\u0648\\u0627\\u0646\\u062f \\u0628\\u0627 \\u06a9\\u0633\\u0628 \\u0645\\u062c\\u0648\\u0632\\u0647\\u0627\\u06cc \\u0645\\u0648\\u0631\\u062f \\u0646\\u06cc\\u0627\\u0632 \\u0627\\u0632 \\u0633\\u0627\\u0632\\u0645\\u0627\\u0646 \\u0628\\u0648\\u0631\\u0633 \\u0627\\u0648\\u0631\\u0627\\u0642 \\u0628\\u0647\\u0627\\u062f\\u0627\\u0631 \\u0641\\u0639\\u0627\\u0644\\u06cc\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0645\\u0639\\u0627\\u0645\\u0644\\u0647\\u200c\\u06af\\u0631\\u06cc \\u0628\\u0627\\u0632\\u0627\\u0631\\u06af\\u0631\\u062f\\u0627\\u0646\\u06cc \\u0647\\u0645\\u0686\\u0646\\u06cc\\u0646 \\u062e\\u062f\\u0645\\u0627\\u062a\\u0646 \\u0645\\u0627\\u0644\\u06cc \\u0645\\u0634\\u0627\\u0648\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0645\\u0628\\u0627\\u062f\\u0631\\u062a \\u0648\\u0631\\u0632\\u062f .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "eval_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c74164a8-8aa4-406f-b42a-20b748ae99af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>original_sentence</th>\n",
              "      <th>ref_1</th>\n",
              "      <th>ref_2</th>\n",
              "      <th>LSBERT_simpl</th>\n",
              "      <th>ziph_simpl</th>\n",
              "      <th>similarity_simpl</th>\n",
              "      <th>BERT_simpl</th>\n",
              "      <th>loss_simpl</th>\n",
              "      <th>z_LSBERT_all</th>\n",
              "      <th>z_LSBERT_zipf</th>\n",
              "      <th>z_LSBERT_sim</th>\n",
              "      <th>z_LSBERT_bert</th>\n",
              "      <th>z_LSBERT_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ضدکشتی</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه:  ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نمونه‌های مخصوص ارتش روسیه:  ۳ ام ۵۴: ن...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه:  ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: سر...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "      <td>مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>دشتبان</td>\n",
              "      <td>به گزارش صبحانه، متهم ۳۸ ساله این پرونده که در...</td>\n",
              "      <td>به گزارش صبحانه، متهم ۳۸ ساله این پرونده که در...</td>\n",
              "      <td>به گزارش صبحانه، متهم ۳۸ ساله این پرونده که در...</td>\n",
              "      <td>به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...</td>\n",
              "      <td>به همراه صبحانه ، مرد ۸ سال این پرونده که در پ...</td>\n",
              "      <td>به خبرگزاری صبحانه ، محکوم ۲۲ ماهه این پرونده ...</td>\n",
              "      <td>به خبرنگار صبحانه ، فعال 38 سال این پرونده که ...</td>\n",
              "      <td>به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...</td>\n",
              "      <td>به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...</td>\n",
              "      <td>به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...</td>\n",
              "      <td>به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...</td>\n",
              "      <td>به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...</td>\n",
              "      <td>به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>باز‌کردن</td>\n",
              "      <td>اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...</td>\n",
              "      <td>اگر دوباره اقدام به باز‌کردن نرم‌افزار اشاره‌ش...</td>\n",
              "      <td>اگر دوباره اقدام به باز‌کردن برنامه اشاره‌شده ...</td>\n",
              "      <td>اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...</td>\n",
              "      <td>اگر مجددا دست به باز‌کردن نرم‌افزار اشاره بکنی...</td>\n",
              "      <td>اگر مجددا عمل به باز‌کردن نرم‌افزار اشاره بکنی...</td>\n",
              "      <td>اگر مجددا تصمیم به باز‌کردن نرم‌افزار اشاره بک...</td>\n",
              "      <td>اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...</td>\n",
              "      <td>اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...</td>\n",
              "      <td>اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...</td>\n",
              "      <td>اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...</td>\n",
              "      <td>اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...</td>\n",
              "      <td>اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>استفسار</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...</td>\n",
              "      <td>وقتی روبه‌رو ایستگاه اتومبیل‌های حاج در این بی...</td>\n",
              "      <td>وقتی روبروی ایستگاه اتومبیل‌های حاج در این بیا...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های آقا در این بیاب...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های آقا در این بیاب...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حج در این بیابا...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...</td>\n",
              "      <td>وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>عمومی‌شان</td>\n",
              "      <td>هابرماس معتقد است، عرصه عمومی زمانی پدید می‌آی...</td>\n",
              "      <td>هابرماس معتقد است، مکان عمومی زمانی به وجود می...</td>\n",
              "      <td>هابرماس معتقد است، عرصه عمومی زمانی بوجود می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، بازار عمومی زمانی پدید می‌...</td>\n",
              "      <td>هابرماس معتقد است ، حوزه عمومی زمانی پدید می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، فضای عمومی زمانی پدید می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...</td>\n",
              "      <td>هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>سالیانه</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگه هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگه هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگه هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "      <td>براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>برنمی‌دارند</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند و ...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند و ...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تشویش برنمی‌دارند و ...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...</td>\n",
              "      <td>افسران ارتش و پلیس سر از کار برنمی‌دارند منتظر...</td>\n",
              "      <td>افسران ارتش و پلیس چشم از سرکوب برنمی‌دارند من...</td>\n",
              "      <td>افسران ارتش و پلیس دستی از فعالیت برنمی‌دارند ...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...</td>\n",
              "      <td>افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>کراس‌اور</td>\n",
              "      <td>ولوو اکس‌سی ۴۰  یک خودروی کراس‌اور لوکس است که...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰  یک خودروی کراس‌اور لوکس است که...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰  یک خودروی کراس‌اور مجلل است که...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...</td>\n",
              "      <td>ولوو اس ۴۰ یک ماشین کراس‌اور لوکس است که توسط ...</td>\n",
              "      <td>ولوو اکس ۴۰ یک خودروهای کراس‌اور لوکس است که ت...</td>\n",
              "      <td>ولوو اکس ۴۰ یک خودرو کراس‌اور لوکس است که توسط...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...</td>\n",
              "      <td>ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>قطعه‌ساز</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...</td>\n",
              "      <td>از بخشش و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز...</td>\n",
              "      <td>از کرم و بخشش‌های وزیر قبلی تا ظهور قطعه‌ساز ن...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا تولید ماشین ها...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ورود خودرو نما...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا حضور خودرو نما...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...</td>\n",
              "      <td>از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>تصورند</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "      <td>بیشتر مردم بر این تصورند که همه آب‌های عرضه‌شد...</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "      <td>اغلب جامعه بر این تصورند که همه آب‌های عرضه‌شد...</td>\n",
              "      <td>اغلب شهروندان بر این تصورند که همه آب‌های عرضه...</td>\n",
              "      <td>اغلب مردمی بر این تصورند که همه آب‌های عرضه‌شد...</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "      <td>اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>491 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c74164a8-8aa4-406f-b42a-20b748ae99af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c74164a8-8aa4-406f-b42a-20b748ae99af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c74164a8-8aa4-406f-b42a-20b748ae99af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2078d59c-87fa-44d8-955f-ca327c27fc42\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2078d59c-87fa-44d8-955f-ca327c27fc42')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2078d59c-87fa-44d8-955f-ca327c27fc42 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          target                                  original_sentence  \\\n",
              "0         ضدکشتی  مدل‌ها نسخه‌های مخصوص ارتش روسیه:  ۳ ام ۵۴: نس...   \n",
              "1         دشتبان  به گزارش صبحانه، متهم ۳۸ ساله این پرونده که در...   \n",
              "2       باز‌کردن  اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...   \n",
              "3        استفسار  وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...   \n",
              "4      عمومی‌شان  هابرماس معتقد است، عرصه عمومی زمانی پدید می‌آی...   \n",
              "..           ...                                                ...   \n",
              "486      سالیانه  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  برنمی‌دارند  افسران ارتش و پلیس دست از تحریک برنمی‌دارند و ...   \n",
              "488     کراس‌اور  ولوو اکس‌سی ۴۰  یک خودروی کراس‌اور لوکس است که...   \n",
              "489     قطعه‌ساز  از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...   \n",
              "490       تصورند  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...   \n",
              "\n",
              "                                                 ref_1  \\\n",
              "0    مدل‌ها نمونه‌های مخصوص ارتش روسیه:  ۳ ام ۵۴: ن...   \n",
              "1    به گزارش صبحانه، متهم ۳۸ ساله این پرونده که در...   \n",
              "2    اگر دوباره اقدام به باز‌کردن نرم‌افزار اشاره‌ش...   \n",
              "3    وقتی روبه‌رو ایستگاه اتومبیل‌های حاج در این بی...   \n",
              "4    هابرماس معتقد است، مکان عمومی زمانی به وجود می...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دست از تحریک برنمی‌دارند و ...   \n",
              "488  ولوو اکس‌سی ۴۰  یک خودروی کراس‌اور لوکس است که...   \n",
              "489  از بخشش و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز...   \n",
              "490  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...   \n",
              "\n",
              "                                                 ref_2  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه:  ۳ ام ۵۴: نس...   \n",
              "1    به گزارش صبحانه، متهم ۳۸ ساله این پرونده که در...   \n",
              "2    اگر دوباره اقدام به باز‌کردن برنامه اشاره‌شده ...   \n",
              "3    وقتی روبروی ایستگاه اتومبیل‌های حاج در این بیا...   \n",
              "4    هابرماس معتقد است، عرصه عمومی زمانی بوجود می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دست از تشویش برنمی‌دارند و ...   \n",
              "488  ولوو اکس‌سی ۴۰  یک خودروی کراس‌اور مجلل است که...   \n",
              "489  از کرم و بخشش‌های وزیر قبلی تا ظهور قطعه‌ساز ن...   \n",
              "490  بیشتر مردم بر این تصورند که همه آب‌های عرضه‌شد...   \n",
              "\n",
              "                                          LSBERT_simpl  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...   \n",
              "1    به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...   \n",
              "2    اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...   \n",
              "4    هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...   \n",
              "488  ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...   \n",
              "490  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...   \n",
              "\n",
              "                                            ziph_simpl  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: سر...   \n",
              "1    به همراه صبحانه ، مرد ۸ سال این پرونده که در پ...   \n",
              "2    اگر مجددا دست به باز‌کردن نرم‌افزار اشاره بکنی...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های آقا در این بیاب...   \n",
              "4    هابرماس معتقد است ، بازار عمومی زمانی پدید می‌...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگه هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس سر از کار برنمی‌دارند منتظر...   \n",
              "488  ولوو اس ۴۰ یک ماشین کراس‌اور لوکس است که توسط ...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا تولید ماشین ها...   \n",
              "490  اغلب جامعه بر این تصورند که همه آب‌های عرضه‌شد...   \n",
              "\n",
              "                                      similarity_simpl  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...   \n",
              "1    به خبرگزاری صبحانه ، محکوم ۲۲ ماهه این پرونده ...   \n",
              "2    اگر مجددا عمل به باز‌کردن نرم‌افزار اشاره بکنی...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های آقا در این بیاب...   \n",
              "4    هابرماس معتقد است ، حوزه عمومی زمانی پدید می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگه هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس چشم از سرکوب برنمی‌دارند من...   \n",
              "488  ولوو اکس ۴۰ یک خودروهای کراس‌اور لوکس است که ت...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا ورود خودرو نما...   \n",
              "490  اغلب شهروندان بر این تصورند که همه آب‌های عرضه...   \n",
              "\n",
              "                                            BERT_simpl  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...   \n",
              "1    به خبرنگار صبحانه ، فعال 38 سال این پرونده که ...   \n",
              "2    اگر مجددا تصمیم به باز‌کردن نرم‌افزار اشاره بک...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های حج در این بیابا...   \n",
              "4    هابرماس معتقد است ، فضای عمومی زمانی پدید می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگه هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دستی از فعالیت برنمی‌دارند ...   \n",
              "488  ولوو اکس ۴۰ یک خودرو کراس‌اور لوکس است که توسط...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا حضور خودرو نما...   \n",
              "490  اغلب مردمی بر این تصورند که همه آب‌های عرضه‌شد...   \n",
              "\n",
              "                                            loss_simpl  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...   \n",
              "1    به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...   \n",
              "2    اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...   \n",
              "4    هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...   \n",
              "488  ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...   \n",
              "490  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...   \n",
              "\n",
              "                                          z_LSBERT_all  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...   \n",
              "1    به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...   \n",
              "2    اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...   \n",
              "4    هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...   \n",
              "488  ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...   \n",
              "490  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...   \n",
              "\n",
              "                                         z_LSBERT_zipf  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...   \n",
              "1    به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...   \n",
              "2    اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...   \n",
              "4    هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...   \n",
              "488  ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...   \n",
              "490  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...   \n",
              "\n",
              "                                          z_LSBERT_sim  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...   \n",
              "1    به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...   \n",
              "2    اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...   \n",
              "4    هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...   \n",
              "488  ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...   \n",
              "490  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...   \n",
              "\n",
              "                                         z_LSBERT_bert  \\\n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...   \n",
              "1    به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...   \n",
              "2    اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...   \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...   \n",
              "4    هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...   \n",
              "..                                                 ...   \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...   \n",
              "487  افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...   \n",
              "488  ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...   \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...   \n",
              "490  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...   \n",
              "\n",
              "                                         z_LSBERT_loss  \n",
              "0    مدل‌ها نسخه‌های مخصوص ارتش روسیه : ۳ ام ۵۴: نس...  \n",
              "1    به گزارش صبحانه ، متهم ۳۸ ساله این پرونده که د...  \n",
              "2    اگر مجددا اقدام به باز‌کردن نرم‌افزار اشاره‌شد...  \n",
              "3    وقتی محاذی ایستگاه اتومبیل‌های حاج در این بیاب...  \n",
              "4    هابرماس معتقد است ، عرصه عمومی زمانی پدید می‌آ...  \n",
              "..                                                 ...  \n",
              "486  براین اساس اگر هفته‌ای ۱۰ درصد ارزش افزوده تول...  \n",
              "487  افسران ارتش و پلیس دست از تحریک برنمی‌دارند من...  \n",
              "488  ولوو اکس‌سی ۴۰ یک خودروی کراس‌اور لوکس است که ...  \n",
              "489  از بذل و بخشش‌های وزیر پیشین تا ظهور قطعه‌ساز ...  \n",
              "490  اغلب مردم بر این تصورند که همه آب‌های عرضه‌شده...  \n",
              "\n",
              "[491 rows x 14 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_df = pd.read_csv('/content/drive/MyDrive/simplification_evaluation_resources/simplified_samples_4_Eval_492.csv')\n",
        "eval_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo5b8GJ4vAUe"
      },
      "outputs": [],
      "source": [
        "# hazm_normalizer = Normalizer()\n",
        "\n",
        "hazm_w_tokenizer = WordTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_dAKUkhtn0g"
      },
      "outputs": [],
      "source": [
        "\n",
        "original_sents = eval_df['original_sentence']\n",
        "ref1 = eval_df['ref_1']\n",
        "ref2 = eval_df['ref_2']\n",
        "\n",
        "LSBERT = eval_df['z_LSBERT_all']\n",
        "ziph = eval_df['z_LSBERT_zipf']\n",
        "bert = eval_df['z_LSBERT_bert']\n",
        "similarity = eval_df['z_LSBERT_sim']\n",
        "loss = eval_df['z_LSBERT_loss']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmNYTDt1sZTM"
      },
      "source": [
        "**BLEU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "901065470ad04aebba6a8d4badb799ce",
            "81bc215f69c2452097f3b8b1dda1568c",
            "3500e460a6f944f2a6feaf26cb96ed97"
          ]
        },
        "id": "PYJjwFmDq8-a",
        "outputId": "4f30881b-0fca-4bc2-c5d7-5262855cf471"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "901065470ad04aebba6a8d4badb799ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81bc215f69c2452097f3b8b1dda1568c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3500e460a6f944f2a6feaf26cb96ed97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "bleu = evaluate.load(\"bleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2fzKDmxtz4f"
      },
      "outputs": [],
      "source": [
        "sources = original_sents.tolist()\n",
        "\n",
        "total_pred = LSBERT.tolist()\n",
        "ziph_pred = ziph.tolist()\n",
        "similarity_prd = similarity.tolist()\n",
        "bert_predi = bert.tolist()\n",
        "loss_pred = loss.tolist()\n",
        "\n",
        "\n",
        "references_1 = [[ref] for ref in ref1.tolist()]\n",
        "references_2 = [[ref] for ref in ref2.tolist()]\n",
        "\n",
        "both_refrences = [[ref_1, ref_2] for ref_1, ref_2 in zip(ref1.tolist(), ref2.tolist())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_HHTclx95KB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "bleu_only_Ref1 = bleu.compute(predictions=similarity_prd, references=references_1, tokenizer=hazm_w_tokenizer.tokenize)\n",
        "bleu_only_Ref2 = bleu.compute(predictions=similarity_prd, references=references_2, tokenizer=hazm_w_tokenizer.tokenize)\n",
        "bleu_both_refs = bleu.compute(predictions=similarity_prd, references=both_refrences, tokenizer=hazm_w_tokenizer.tokenize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG7Jvvkl-TaY",
        "outputId": "57cb055b-5391-439c-f20b-1b558d778501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bleu_only_Ref1:  {'bleu': 0.5813672763634791, 'precisions': [0.9652068126520681, 0.7880117875728886, 0.6528011385690258, 0.5481392396605866], 'brevity_penalty': 0.8049045096356285, 'length_ratio': 0.821671331467413, 'translation_length': 16440, 'reference_length': 20008} \n",
            " bleu_only_Ref2:  {'bleu': 0.5707704391140918, 'precisions': [0.9566301703163017, 0.7749702175684996, 0.6367576659334973, 0.530700875258903], 'brevity_penalty': 0.8067671463649692, 'length_ratio': 0.8232348522784176, 'translation_length': 16440, 'reference_length': 19970} \n",
            " bleu_both_refs:  {'bleu': 0.6092582503630647, 'precisions': [0.9842457420924574, 0.8167283215248605, 0.686764135075689, 0.5841518006280484], 'brevity_penalty': 0.8084865459354519, 'length_ratio': 0.8246802106847254, 'translation_length': 16440, 'reference_length': 19935}\n"
          ]
        }
      ],
      "source": [
        "print('bleu_only_Ref1: ', bleu_only_Ref1, '\\n','bleu_only_Ref2: ' ,bleu_only_Ref2, '\\n', 'bleu_both_refs: ',bleu_both_refs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILsb8yNHsOjP"
      },
      "source": [
        "**sari**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFjjfbJQxnoi",
        "outputId": "fc84ded4-5faf-459c-e420-e06eb969914a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.12.25)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.2)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.24.3)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: sacremoses, portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.1 sacremoses-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sacremoses sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "339f1d3f63a04d9ca147d354c3250bcb"
          ]
        },
        "id": "cXcSmLXSsQQw",
        "outputId": "1584ac76-e29a-4157-eec2-ff2e49db30e8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "339f1d3f63a04d9ca147d354c3250bcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from evaluate import load\n",
        "sari = load(\"sari\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRoEUw6xzuNM"
      },
      "outputs": [],
      "source": [
        "sari_only_Ref1 = sari.compute(sources=sources, predictions=total_pred, references=references_1)\n",
        "sari_only_Ref2 = sari.compute(sources=sources, predictions=total_pred, references=references_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KN0VCU-u3Mwu"
      },
      "outputs": [],
      "source": [
        "sari_total = sari.compute(sources=sources, predictions=total_pred, references=both_refrences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Sz0uY64S3n",
        "outputId": "8323947b-ef6a-45a5-ec78-39e663958275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sari_only_Ref1:  {'sari': 35.782177352294845} \n",
            " sari_only_Ref2:  {'sari': 35.48318124698324} \n",
            " sari_total {'sari': 34.93180092486218}\n"
          ]
        }
      ],
      "source": [
        "print('sari_only_Ref1: ', sari_only_Ref1, '\\n', 'sari_only_Ref2: ',sari_only_Ref2, '\\n', 'sari_total', sari_total)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
